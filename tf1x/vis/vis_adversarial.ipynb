{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~SAE untargeted Marzi attack~~\n",
    "\n",
    "~~latent marzi attack~~\n",
    "\n",
    "~~deep net RAE attack~~\n",
    "\n",
    "deep net RAE iso-contours\n",
    "\n",
    "denoising VAE preprocessor + MLP vs LCA + MLP vs dRAE + MLP\n",
    "\n",
    "dRAE+MLP; lca+mlp iso-contours\n",
    "\n",
    "----------------------------\n",
    "*network marzi attack*:\n",
    "* Orthogonal to Marzi Untargeted should be the best iso-response direction\n",
    "  * measure the curvature for all neurons in this direction\n",
    "  * give avg for the marzi untargeted orthogonal direction vs random directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "if root_path not in sys.path: sys.path.append(root_path)\n",
    "\n",
    "from DeepSparseCoding.tf1x.data.dataset import Dataset\n",
    "import DeepSparseCoding.tf1x.data.data_selector as ds\n",
    "import DeepSparseCoding.tf1x.utils.data_processing as dp\n",
    "import DeepSparseCoding.tf1x.utils.plot_functions as pf\n",
    "import DeepSparseCoding.tf1x.analysis.analysis_picker as ap\n",
    "#from DeepSparseCoding.tf1x.modules.recon_adversarial_module import ReconAdversarialModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_deep_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_deep_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "params_list = [lca_params(), ae_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.setup_model(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_type = \"train\"\n",
    "data = ds.get_data(analyzer_list[0].model_params)\n",
    "data = analyzer_list[0].model.preprocess_dataset(data, analyzer.model_params)\n",
    "data = analyzer_list[0].model.reshape_dataset(data, analyzer.model_params)\n",
    "data_min = data[dataset_type].images.min()\n",
    "data_max = data[dataset_type].images.max()\n",
    "dataset_size = data[dataset_type].images.shape[0]\n",
    "print(\"NUM DATA\", dataset_size, 'DATA MIN', data_min, 'DATA MAX', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = 5\n",
    "adv_id = 1\n",
    "\n",
    "all_adv_inputs = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == input_id])\n",
    "              \n",
    "all_adv_targets = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == adv_id])\n",
    "\n",
    "if all_adv_inputs.shape[0] > all_adv_targets.shape[0]:\n",
    "  all_adv_inputs = all_adv_inputs[:all_adv_targets.shape[0],...]\n",
    "else:\n",
    "  all_adv_targets = all_adv_targets[:all_adv_inputs.shape[0],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "adv_inputs = all_adv_inputs[img_id,...][None,...]\n",
    "adv_targets = all_adv_targets[img_id,...][None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(adv_inputs.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax = pf.clear_axis(axes[1])\n",
    "ax.imshow(adv_targets.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Adv target image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carlini_adv_loss =  input_pert_loss + recon_mult * adv_recon_loss\n",
    "neuron_idx = 0 # 17, 11\n",
    "\n",
    "for params in params_list:\n",
    "  params.adversarial_num_steps = int(1e5)\n",
    "  params.adversarial_attack_method = \"carlini_targeted\"#\"marzi_latent\"\n",
    "  params.adversarial_step_size = 1e-5\n",
    "  params.adversarial_max_change = None#0.8\n",
    "  params.adversarial_clip = True\n",
    "  params.adversarial_clip_range = [0.0, 1.0]\n",
    "  params.carlini_recon_mult = 200.0\n",
    "  params.carlini_change_variable = True\n",
    "  params.adv_optimizer = \"sgd\"\n",
    "  params.adversarial_save_int = 100\n",
    "  #TODO: compute num_latent in the model, get access in analyzer\n",
    "  params.selection_vector = np.zeros(768)#1/np.sqrt(768) * np.ones(768)\n",
    "  params.selection_vector[neuron_idx] = 1\n",
    "\n",
    "#LCA\n",
    "#params_list[1].adversarial_num_steps = params_list[0].adversarial_num_steps\n",
    "#params_list[1].adversarial_attack_method = params_list[0].adversarial_attack_method\n",
    "#params_list[1].adversarial_step_size = params_list[0].adversarial_step_size#1e-3\n",
    "#params_list[1].adversarial_max_change = params_list[0].adversarial_max_change\n",
    "#params_list[1].adversarial_clip = params_list[0].adversarial_clip\n",
    "#params_list[1].adversarial_clip_range = params_list[0].adversarial_clip_range\n",
    "#params_list[1].carlini_recon_mult = params_list[0].carlini_recon_mult\n",
    "#params_list[1].carlini_change_variable = params_list[0].carlini_change_variable\n",
    "#params_list[1].optimizer = params_list[0].optimizer\n",
    "#params_list[1].adversarial_save_int = params_list[0].adversarial_save_int\n",
    "#params_list[1].selection_vector = np.zeros(768)\n",
    "#params_list[1].selection_vector[neuron_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(4,4))\n",
    "ax = pf.clear_axis(ax)\n",
    "ax.imshow(analyzer_list[0].bf_stats[\"basis_functions\"][neuron_idx].reshape(28,28), cmap=\"Greys_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.analysis_params.adversarial_num_steps = params.adversarial_num_steps\n",
    "  analyzer.analysis_params.adversarial_attack_method = params.adversarial_attack_method\n",
    "  analyzer.analysis_params.adversarial_step_size = params.adversarial_step_size\n",
    "  analyzer.analysis_params.adversarial_max_change = params.adversarial_max_change\n",
    "  analyzer.analysis_params.adversarial_clip = params.adversarial_clip\n",
    "  analyzer.analysis_params.adversarial_clip_range = params.adversarial_clip_range\n",
    "  analyzer.analysis_params.carlini_recon_mult = params.carlini_recon_mult\n",
    "  analyzer.analysis_params.carlini_change_variable = params.carlini_change_variable\n",
    "  analyzer.analysis_params.adv_optimizer = params.adv_optimizer\n",
    "  analyzer.analysis_params.adversarial_save_int = params.adversarial_save_int\n",
    "  analyzer.analysis_params.selection_vector = params.selection_vector\n",
    "\n",
    "  analyzer.model.reset_graph()\n",
    "  analyzer.setup_model(analyzer.model_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_adversarial_images is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "all_recons is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "\"\"\"\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.steps, analyzer.all_adversarial_images, analyzer.all_recons, analyzer.distances = \\\n",
    "    analyzer.construct_recon_adversarial_stimulus(adv_inputs, adv_targets)\n",
    "  analyzer.all_adversarial_perturbations = []\n",
    "  for recon_mult_idx, adv_image_list in enumerate(analyzer.all_adversarial_images):\n",
    "    analyzer.all_adversarial_perturbations.append([])\n",
    "    for step_idx, adv_images in enumerate(adv_image_list):\n",
    "      analyzer.all_adversarial_perturbations[recon_mult_idx].append(adv_images - adv_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer_idx = 0\n",
    "batch_idx = 0\n",
    "step_idx = -1\n",
    "recon_idx = 0\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20,4))\n",
    "\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][0][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\ninput image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[1])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_recons[0][0][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\nrecon image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[2])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_perturbations[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\nperturbation image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[3])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\ninput image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[4])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_recons[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\nrecon image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These mses are in shape [num_recon_mults, num_iterations, num_batch]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "offset = 0\n",
    "steps = analyzer_list[analyzer_idx].steps[offset:]\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_adv_mses\"])[recon_idx, offset:, batch_idx],\n",
    "  label='input to perturbed', color='r')\n",
    "\n",
    "#ax[0].plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"target_adv_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='target to perturbed', color='b')\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"target_recon_mses\"])[recon_idx, offset:, batch_idx],\n",
    "  label='target to recon', color='g')\n",
    "\n",
    "#ax[0].plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"adv_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='perturbed to recon', color='k')\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "  label='input to recon', color='c')\n",
    "\n",
    "ax[1].plot(steps, analyzer_list[analyzer_idx].distances[\"adv_loss\"][recon_idx][offset:], label=\"Adversarial Loss\")\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.845, 0.855))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.compat.v1.Session(config=config, graph=analyzer.model.graph) as sess:\n",
    "  feed_dict = analyzer.model.get_feed_dict(adv_inputs)\n",
    "  sess.run(analyzer.model.init_op, feed_dict)\n",
    "  analyzer.model.load_full_model(sess, analyzer.analysis_params.cp_loc)\n",
    "  sess.run(analyzer.recon_adv_module.reset, feed_dict)\n",
    "  orig_activity = sess.run(analyzer.recon_adv_module.latent_activities, feed_dict)\n",
    "  feed_dict[analyzer.recon_adv_module.orig_latent_activities] = orig_activity\n",
    "  feed_dict[analyzer.recon_adv_module.selection_vector] = 1/np.sqrt(768) * np.ones_like(analyzer.analysis_params.selection_vector[:,None])\n",
    "  selected_orig_activity = sess.run(analyzer.recon_adv_module.selected_orig_activities, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = similarities[1] - similarities[0]\n",
    "\n",
    "bins = np.linspace(np.min(diff_list), np.max(diff_list), num_bins)\n",
    "dist_hist, bin_edges = np.histogram(diff_list, bins=bins)\n",
    "dist_hist = dist_hist / np.max(dist_hist)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "ax.bar(bin_centers, dist_hist, width=bin_right-bin_left, edgecolor='k')\n",
    "ax.set_xlabel(\"\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  \n",
    "title = (\"Difference between Cosine Similarity Between Target Image and Perturbation\")\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity Difference\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...] == 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
