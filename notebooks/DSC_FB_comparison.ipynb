{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Union, Any, Optional, Callable, Tuple\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if ROOT_DIR not in sys.path: sys.path.append(ROOT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proplot as plot\n",
    "import eagerpy as ep\n",
    "import torch\n",
    "\n",
    "from DeepSparseCoding.tf1x.utils.logger import Logger as tfLogger\n",
    "import DeepSparseCoding.tf1x.analysis.analysis_picker as ap\n",
    "from DeepSparseCoding.tf1x.data.dataset import Dataset\n",
    "import DeepSparseCoding.tf1x.utils.data_processing as tfdp\n",
    "\n",
    "from DeepSparseCoding.utils.file_utils import Logger\n",
    "import DeepSparseCoding.utils.dataset_utils as dataset_utils\n",
    "import DeepSparseCoding.utils.loaders as loaders\n",
    "import DeepSparseCoding.utils.plot_functions as pf\n",
    "\n",
    "from foolbox import PyTorchModel, accuracy\n",
    "from foolbox.attacks.projected_gradient_descent import LinfProjectedGradientDescentAttack\n",
    "from foolbox.types import Bounds\n",
    "from foolbox.models.base import Model\n",
    "from foolbox.attacks.base import T\n",
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.attacks.base import raise_if_kwargs\n",
    "from foolbox.attacks.base import get_criterion\n",
    "\n",
    "rand_state = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Foolbox Pytorch models & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_dsc(log_file, cp_file):\n",
    "    logger = Logger(log_file, overwrite=False)\n",
    "    log_text = logger.load_file()\n",
    "    params = logger.read_params(log_text)[-1]\n",
    "    params.cp_latest_filename = cp_file\n",
    "    params.standardize_data = False\n",
    "    params.rescale_data_to_one = True\n",
    "    params.shuffle_data = False\n",
    "    train_loader, val_loader, test_loader, data_params = dataset_utils.load_dataset(params)\n",
    "    for key, value in data_params.items():\n",
    "        setattr(params, key, value)\n",
    "    model = loaders.load_model(params.model_type)\n",
    "    model.setup(params, logger)\n",
    "    model.params.analysis_out_dir = os.path.join(\n",
    "        *[model.params.model_out_dir, 'analysis', model.params.version])\n",
    "    model.params.analysis_save_dir = os.path.join(model.params.analysis_out_dir, 'savefiles')\n",
    "    if not os.path.exists(model.params.analysis_save_dir):\n",
    "        os.makedirs(model.params.analysis_save_dir)\n",
    "    model.to(params.device)\n",
    "    model.load_checkpoint()\n",
    "    fmodel = PyTorchModel(model.eval(), bounds=(0, 1))\n",
    "    return fmodel, model, test_loader, model.params.batch_size, model.params.device\n",
    "\n",
    "log_files = [\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'mlp_768_mnist', 'logfiles', 'mlp_768_mnist_v0.log']),\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'lca_768_mlp_mnist', 'logfiles', 'lca_768_mlp_mnist_v0.log'])\n",
    "]\n",
    "\n",
    "cp_latest_filenames = [\n",
    "    os.path.join(*[ROOT_DIR,'Torch_projects', 'mlp_768_mnist', 'checkpoints', 'mlp_768_mnist_latest_checkpoint_v0.pt']),\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'lca_768_mlp_mnist', 'checkpoints', 'lca_768_mlp_mnist_latest_checkpoint_v0.pt'])\n",
    "]\n",
    "\n",
    "fmodel_mlp, dsc_model_mlp, test_loader, batch_size, device = create_mnist_dsc(log_files[0], cp_latest_filenames[0])\n",
    "fmodel_mlp.model_type = 'MLP'\n",
    "\n",
    "fmodel_lca, dsc_model_lca = create_mnist_dsc(log_files[1], cp_latest_filenames[1])[:2]\n",
    "fmodel_lca.model_type = 'LCA'\n",
    "\n",
    "fmodels = [fmodel_mlp, fmodel_lca]\n",
    "\n",
    "fb_image_batch, fb_label_batch = next(iter(test_loader))\n",
    "fb_image_batch = fb_image_batch.reshape((batch_size, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DeepSparseCoding Tensorflow models & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "  def __init__(self):\n",
    "    self.device = \"/gpu:0\"\n",
    "    self.analysis_dataset = \"test\"\n",
    "    self.save_info = \"analysis_\" + self.analysis_dataset\n",
    "    self.overwrite_analysis_log = False\n",
    "    self.do_class_adversaries = True\n",
    "    self.do_run_analysis = False\n",
    "    self.do_evals = False\n",
    "    self.do_basis_analysis = False\n",
    "    self.do_inference = False\n",
    "    self.do_atas = False \n",
    "    self.do_recon_adversaries = False\n",
    "    self.do_neuron_visualization = False\n",
    "    self.do_full_recon = False\n",
    "    self.do_orientation_analysis = False \n",
    "    self.do_group_recons = False\n",
    "    \n",
    "    #Adversarial params\n",
    "    self.adversarial_attack_method = \"kurakin_untargeted\"\n",
    "    self.adversarial_step_size = 0.005 # learning rate for optimizer\n",
    "    self.adversarial_num_steps = 500 # Number of iterations adversarial attacks\n",
    "    self.confidence_threshold = 0.9\n",
    "    self.adversarial_max_change = 1.0 # maximum size of adversarial perturation (epsilon)\n",
    "    self.carlini_change_variable = False # whether to use the change of variable trick from carlini et al\n",
    "    self.adv_optimizer = \"sgd\" # attack optimizer\n",
    "    self.adversarial_target_method = \"random\" # Not used if attack_method is untargeted#TODO support specified\n",
    "    self.adversarial_clip = True # whether or not to clip the final perturbed image\n",
    "    self.adversarial_clip_range = [0.0, 1.0] # Maximum range of image values\n",
    "    #self.carlini_recon_mult = 0.1#list(np.arange(.5, 1, .1))\n",
    "    self.adversarial_save_int = 1 # Interval at which to save adv examples to the npz file\n",
    "    self.eval_batch_size = 50 # batch size for computing adv examples\n",
    "    self.adversarial_input_id = np.arange(self.eval_batch_size, dtype=np.int32) # Which adv images to use; None to use all\n",
    "    self.adversarial_target_labels = None # Parameter for \"specified\" target_method. Only for class attacks. Needs to be a list or numpy array of size [adv_batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_params = params()\n",
    "analysis_params.projects_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "#model_names = ['mlp_lca_768_latent_75_steps_mnist', 'slp_lca_768_latent_75_steps_mnist']\n",
    "model_names = ['mlp_cosyne_mnist', 'slp_lca_768_latent_75_steps_mnist']\n",
    "model_types = ['MLP', 'LCA']\n",
    "analyzers = []\n",
    "for model_type, model_name in zip(model_types, model_names):\n",
    "    analysis_params.model_name = model_name\n",
    "    analysis_params.version = '0.0'\n",
    "    analysis_params.model_dir = analysis_params.projects_dir+analysis_params.model_name\n",
    "    model_log_file = (analysis_params.model_dir+\"/logfiles/\"+analysis_params.model_name\n",
    "      +\"_v\"+analysis_params.version+\".log\")\n",
    "    model_logger = tfLogger(model_log_file, overwrite=False)\n",
    "    model_log_text = model_logger.load_file()\n",
    "    model_params = model_logger.read_params(model_log_text)[-1]\n",
    "    analysis_params.model_type = model_params.model_type\n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analysis_params.save_info = \"analysis_test_\" + analysis_params.analysis_dataset\n",
    "    analysis_params.save_info += (\n",
    "        \"_linf_\"+str(analysis_params.adversarial_max_change)\n",
    "        +\"_ss_\"+str(analysis_params.adversarial_step_size)\n",
    "        +\"_ns_\"+str(analysis_params.adversarial_num_steps)\n",
    "        +\"_pgd_untargeted\"\n",
    "    )\n",
    "    analyzer.setup(analysis_params)\n",
    "    analyzer.model_type = model_type\n",
    "    analyzer.confidence_threshold = analysis_params.confidence_threshold\n",
    "    analyzers.append(analyzer)\n",
    "\n",
    "mnist_data = test_loader.dataset.data.numpy().astype(np.float32)\n",
    "mnist_data /= 255\n",
    "dsc_data = {\n",
    "    'test':Dataset(\n",
    "        np.expand_dims(mnist_data, axis=-1),\n",
    "        tfdp.dense_to_one_hot(test_loader.dataset.targets.numpy(), 10),\n",
    "        None,\n",
    "        rand_state\n",
    "    )\n",
    "}\n",
    "dsc_data = analyzers[0].model.reshape_dataset(dsc_data, analyzer.model_params)\n",
    "for analyzer in analyzers:\n",
    "    analyzer.model_params.data_shape = list(dsc_data[\"test\"].shape[1:])\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "dsc_image_batch, dsc_label_batch, _ = dsc_data['test'].next_batch(batch_size, shuffle_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DeepSparseCoding & Foolbox data & logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_idx = np.random.randint(batch_size)\n",
    "fig, axs = plot.subplots(ncols=3)\n",
    "im = axs[0].imshow(fb_image_batch.numpy()[img_idx,...].reshape(28, 28), cmap='grays_r')\n",
    "axs[0].format(title=f'PyTorch loader digit class {fb_label_batch[img_idx]}')\n",
    "axs[0].colorbar(im)\n",
    "im = axs[1].imshow(dsc_image_batch[img_idx,...].reshape(28, 28), cmap='grays_r')\n",
    "axs[1].format(title=f'DSC dataset digit class {tfdp.one_hot_to_dense(dsc_label_batch)[img_idx]}')\n",
    "axs[1].colorbar(im)\n",
    "diff_img = np.abs(dsc_image_batch[img_idx,...].reshape(28, 28) - fb_image_batch.numpy()[img_idx,...].reshape(28, 28))\n",
    "im = axs[2].imshow(diff_img, cmap='grays_r')\n",
    "axs[2].format(title=f'Difference image')\n",
    "axs[2].colorbar(im)\n",
    "pf.clear_axes(axs)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_test_image = dsc_image_batch[img_idx, ...][None, :]\n",
    "fb_test_image = fb_image_batch[img_idx, ...][None, :]\n",
    "dsc_forward = [np.squeeze(analyzer.compute_activations(dsc_test_image,\n",
    "    activation_operation=analyzer.model.get_logits))\n",
    "    for analyzer in analyzers]\n",
    "fb_forward = [fmodel(fb_test_image.to(device)).cpu().numpy() for fmodel in fmodels]\n",
    "fig, axs = plot.subplots(ncols=2, nrows=2)\n",
    "axs[0,0].bar(np.squeeze(dsc_forward[0]))\n",
    "axs[0,0].format(title=f'DSC_{analyzers[0].model_type}')\n",
    "axs[0,1].bar(np.squeeze(dsc_forward[1]))\n",
    "axs[0,1].format(title=f'DSC_{analyzers[1].model_type}')\n",
    "axs[1,0].bar(np.squeeze(fb_forward[0]))\n",
    "axs[1,0].format(title=f'FB_{fmodels[0].model_type}')\n",
    "axs[1,1].bar(np.squeeze(fb_forward[1]))\n",
    "axs[1,1].format(title=f'FB_{fmodels[1].model_type}')\n",
    "axs.format(xminorlocator='null', xlocator=('linear', 10)) # TODO: Broken?\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_test_image = dsc_image_batch#[img_idx, ...][None, :]\n",
    "fb_test_image = fb_image_batch#[img_idx, ...][None, :]\n",
    "\n",
    "dsc_forward = [np.squeeze(analyzer.compute_activations(dsc_test_image,\n",
    "    activation_operation=analyzer.model.get_label_est))\n",
    "    for analyzer in analyzers]\n",
    "dsc_forward = np.stack(dsc_forward, axis=0)\n",
    "\n",
    "fb_forward = [torch.nn.functional.softmax(fmodel(fb_test_image.to(device)), dim=-1).cpu().numpy() for fmodel in fmodels]\n",
    "fb_forward = np.stack(fb_forward, axis=0)\n",
    "\n",
    "all_results = np.concatenate((dsc_forward.reshape( 2, -1), fb_forward.reshape(2, -1)), axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(ncols=2, nrows=2)\n",
    "axs[0,0].bar(np.squeeze(dsc_forward[0, img_idx]))\n",
    "axs[0,0].format(title=f'DSC_{analyzers[0].model_type}')\n",
    "axs[0,1].bar(np.squeeze(dsc_forward[1, img_idx]))\n",
    "axs[0,1].format(title=f'DSC_{analyzers[1].model_type}')\n",
    "axs[1,0].bar(np.squeeze(fb_forward[0, img_idx]))\n",
    "axs[1,0].format(title=f'FB_{fmodels[0].model_type}')\n",
    "axs[1,1].bar(np.squeeze(fb_forward[1, img_idx]))\n",
    "axs[1,1].format(title=f'FB_{fmodels[1].model_type}')\n",
    "axs.format(suptitle='Softmax Confidence', xminorlocator='null', xlocator=('linear', 10), ylim=[0, 1])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['DSC_MLP', 'DSC_LCA', 'FB_MLP', 'FB_LCA']\n",
    "data = pd.DataFrame(\n",
    "    all_results,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "\n",
    "fig, ax = plot.subplots(ncols=1, axwidth=2.5, share=0)\n",
    "ax.format(grid=False, suptitle='L infinity Attack Mean Squared Distances')\n",
    "obj1 = ax.boxplot(\n",
    "    data, linewidth=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax.format(title='Test set confidences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DeepSparseCoding adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keep_and_confidence_indices(softmax_conf, all_kept_indices, confidence_threshold, num_images, labels):\n",
    "    softmax_conf[np.arange(num_images, dtype=np.int32), labels] = 0 # zero confidence at true label\n",
    "    confidence_indices = np.max(softmax_conf, axis=-1) # highest non-true label confidence\n",
    "    all_above_thresh = np.nonzero(np.squeeze(confidence_indices>confidence_threshold))[0]\n",
    "    keep_indices = np.array([], dtype=np.int32)\n",
    "    for adv_index in all_above_thresh:\n",
    "        if adv_index not in set(all_kept_indices):\n",
    "            keep_indices = np.append(keep_indices, adv_index)\n",
    "    return keep_indices, confidence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    analyzer.class_adversary_analysis(dsc_image_batch,\n",
    "        dsc_label_batch,\n",
    "        batch_size=analyzer.analysis_params.eval_batch_size,\n",
    "        input_id=analyzer.analysis_params.adversarial_input_id,\n",
    "        target_method = analyzer.analysis_params.adversarial_target_method,\n",
    "        target_labels = analyzer.analysis_params.adversarial_target_labels,\n",
    "        save_info=analyzer.analysis_params.save_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dsc_image_batch\n",
    "labels = tfdp.one_hot_to_dense(dsc_label_batch.astype(np.int32))\n",
    "for analyzer in analyzers:\n",
    "    store_data = np.zeros_like(data)\n",
    "    store_time_step = -1*np.ones(data.shape[0], dtype=np.int32)\n",
    "    store_confidence = np.zeros(data.shape[0], dtype=np.float32)\n",
    "    store_mses = np.zeros(data.shape[0], dtype=np.float32)\n",
    "    all_kept_indices = []\n",
    "    for adv_step in range(1, analyzer.analysis_params.adversarial_num_steps+1): # first one is original\n",
    "        keep_indices, confidence_indices = get_keep_and_confidence_indices(\n",
    "            analyzer.adversarial_outputs[0, adv_step, ...],\n",
    "            all_kept_indices,\n",
    "            analyzer.confidence_threshold,\n",
    "            data.shape[0],\n",
    "            labels)\n",
    "        if keep_indices.size > 0:\n",
    "            all_kept_indices.extend(keep_indices)\n",
    "            store_data[keep_indices, ...] = analyzer.adversarial_images[0, adv_step, keep_indices, ...]\n",
    "            store_time_step[keep_indices] = adv_step\n",
    "            store_confidence[keep_indices] = confidence_indices[keep_indices]\n",
    "            store_mses[keep_indices] = analyzer.adversarial_input_adv_mses[0, adv_step, keep_indices]\n",
    "    batch_indices = np.arange(data.shape[0], dtype=np.int32)[:,None]\n",
    "    failed_indices = np.array([val for val in batch_indices if val not in all_kept_indices])\n",
    "    if len(failed_indices) > 0:\n",
    "        store_confidence[failed_indices] = confidence_indices[failed_indices]\n",
    "        store_data[failed_indices, ...] = data[failed_indices, ...]\n",
    "        store_mses[failed_indices] = analyzer.adversarial_input_adv_mses[0, -1, failed_indices]\n",
    "    analyzer.adversarial_images = store_data\n",
    "    analyzer.adversarial_time_step = store_time_step\n",
    "    analyzer.adversarial_confidence = store_confidence\n",
    "    analyzer.failed_indices = failed_indices\n",
    "    analyzer.success_indices = list(set(all_kept_indices))\n",
    "    analyzer.mean_squared_distances = store_mses\n",
    "    analyzer.num_failed = data.shape[0] - len(set(all_kept_indices))\n",
    "    print(f'model {analyzer.model_type} had {analyzer.num_failed} failed indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Foolbox adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinfProjectedGradientDescentAttackWithStopping(LinfProjectedGradientDescentAttack):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        rel_stepsize: float = 0.025,\n",
    "        abs_stepsize: Optional[float] = None,\n",
    "        steps: int = 50,\n",
    "        random_start: bool = True,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            rel_stepsize=rel_stepsize,\n",
    "            abs_stepsize=abs_stepsize,\n",
    "            steps=steps,\n",
    "            random_start=random_start,\n",
    "        )\n",
    "        \n",
    "    #def project(self, x: ep.Tensor, x0: ep.Tensor, epsilon: float) -> ep.Tensor:\n",
    "    #    return x0 + ep.clip(x - x0, -epsilon, epsilon)\n",
    "    \n",
    "    def normalize(\n",
    "        self, gradients: ep.Tensor, *, x: ep.Tensor, bounds: Bounds\n",
    "    ) -> ep.Tensor:\n",
    "        return gradients.sign()\n",
    "        \n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        epsilon: float,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x0, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        if not isinstance(criterion_, Misclassification):\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        labels = criterion_.labels\n",
    "        loss_fn = self.get_loss_fn(model, labels)\n",
    "\n",
    "        if self.abs_stepsize is None:\n",
    "            stepsize = self.rel_stepsize * epsilon\n",
    "        else:\n",
    "            stepsize = self.abs_stepsize\n",
    "\n",
    "        orig_x = x0.numpy().copy()\n",
    "        x = x0\n",
    "\n",
    "        if self.random_start:\n",
    "            x = self.get_random_start(x0, epsilon)\n",
    "            x = ep.clip(x, *model.bounds)\n",
    "        else:\n",
    "            x = x0\n",
    "        store_x = np.zeros_like(x)\n",
    "        store_time_step = -1*np.ones(x.shape[0], dtype=np.int32)\n",
    "        store_confidence = np.zeros(x.shape[0], dtype=np.float32)\n",
    "        all_kept_indices = []\n",
    "        time_step = 0\n",
    "        num_failed = 0\n",
    "        while len(set(all_kept_indices)) < x.shape[0]:\n",
    "            loss, gradients = self.value_and_grad(loss_fn, x)\n",
    "            gradients = self.normalize(gradients=gradients, x=x, bounds=model.bounds)\n",
    "            x = x + stepsize * gradients\n",
    "            x = self.project(x, x0, epsilon)\n",
    "            x = ep.clip(x, *model.bounds)\n",
    "            \n",
    "            keep_indices, confidence_indices = get_keep_and_confidence_indices(\n",
    "                ep.softmax(model(x)).numpy().copy(),\n",
    "                all_kept_indices,\n",
    "                model.confidence_threshold,\n",
    "                x.shape[0],\n",
    "                labels.numpy())\n",
    "            if keep_indices.size > 0:\n",
    "                all_kept_indices.extend(keep_indices)\n",
    "                store_x[keep_indices, ...] = x.numpy()[keep_indices, ...]\n",
    "                store_time_step[keep_indices] = time_step\n",
    "                store_confidence[keep_indices] = confidence_indices[keep_indices]\n",
    "            time_step += 1\n",
    "            if time_step == self.steps-1:\n",
    "                num_failed = x.shape[0] - len(set(all_kept_indices))\n",
    "                print(f'Max steps = {self.steps} reached for model {model.model_type}, {num_failed} images did not achieve adversarial confidence threshold of {model.confidence_threshold}')\n",
    "                break\n",
    "        batch_indices = np.arange(x.shape[0], dtype=np.int32)[:,None]\n",
    "        failed_indices = np.array([val for val in batch_indices if val not in all_kept_indices])\n",
    "        if len(failed_indices) > 0:\n",
    "            store_confidence[failed_indices] = confidence_indices[failed_indices]\n",
    "            store_x[failed_indices, ...] = x[failed_indices, ...]\n",
    "        reduc_dim = tuple(range(1, len(orig_x.shape)))\n",
    "        msd = np.mean((store_x - orig_x)**2, axis=reduc_dim)\n",
    "        model.adversarial_images.append(store_x)\n",
    "        model.adversarial_time_step.append(store_time_step)\n",
    "        model.adversarial_confidence.append(store_confidence)\n",
    "        model.success_indices.append(np.array(all_kept_indices, dtype=np.int32))\n",
    "        model.failed_indices.append(failed_indices)\n",
    "        model.mean_squared_distances.append(msd)\n",
    "        model.num_failed.append(len(failed_indices))\n",
    "        return restore_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attack_params = {\n",
    "    'LinfPGD': {\n",
    "        'random_start':False,\n",
    "        'abs_stepsize':analysis_params.adversarial_step_size,\n",
    "        'steps':analysis_params.adversarial_num_steps # maximum number of steps\n",
    "    }\n",
    "}\n",
    "epsilons = [analysis_params.adversarial_max_change]\n",
    "attack = LinfProjectedGradientDescentAttackWithStopping(**attack_params['LinfPGD'])\n",
    "\n",
    "for fmodel in fmodels:\n",
    "    fmodel.confidence_threshold = analysis_params.confidence_threshold\n",
    "    fmodel.adversarial_images = []\n",
    "    fmodel.adversarial_time_step = []\n",
    "    fmodel.adversarial_confidence = []\n",
    "    fmodel.failed_indices = []\n",
    "    fmodel.mean_squared_distances = []\n",
    "    fmodel.num_failed = []\n",
    "    fmodel.success_indices = []\n",
    "    fmodel.success = []\n",
    "    advs, _, success = attack(\n",
    "        fmodel,\n",
    "        fb_image_batch.to(device),\n",
    "        fb_label_batch.to(device),\n",
    "        epsilons=epsilons\n",
    "    )\n",
    "    fmodel.success.append(success.type(torch.float32).cpu().numpy())\n",
    "    print(f'model {fmodel.model_type} had {fmodel.num_failed} failed indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DeepSparseCoding & Foolbox adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    analyzer.confidence = analyzer.adversarial_outputs[0, 0, ...]\n",
    "    analyzer.accuracy = analyzer.adversarial_clean_accuracy.item()\n",
    "    print(f'DSC {analyzer.model_type} clean accuracy = {analyzer.accuracy} and adv accuracy = {analyzer.adversarial_adv_accuracy}')\n",
    "    \n",
    "for fmodel in fmodels:\n",
    "    logits = fmodel(fb_image_batch.to(device))\n",
    "    confidence = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    fmodel.confidence = confidence.cpu().numpy()\n",
    "    fmodel.accuracy = accuracy(fmodel, fb_image_batch.to(device), fb_label_batch.to(device))\n",
    "    print(f'FB {fmodel.model_type} clean accuracy = {fmodel.accuracy} and adv accuracy = {1.0 - fmodel.success[0].mean(axis=-1).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "fig, axs = plot.subplots(ncols=2, nrows=2)\n",
    "for ax, model, atk_type in zip(axs, analyzers+fmodels, ['DSC', 'DSC', 'FB', 'FB']):\n",
    "    max_confidence = np.max(model.confidence, axis=1) # max is across categories, per image\n",
    "    bins = np.linspace(0, 1, num_bins)\n",
    "    count, bin_edges = np.histogram(max_confidence, bins)\n",
    "    bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "    bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "    ax.bar(bin_centers, count, width=1, color='k')\n",
    "    mean_confidence = np.mean(max_confidence)\n",
    "    mean_idx = np.abs(bin_edges - mean_confidence).argmin()\n",
    "    mean_conf_bin = bin_edges[mean_idx]\n",
    "    ax.axvline(mean_conf_bin, lw=2, ls='-', color='r')\n",
    "    ax.format(\n",
    "        title=f'{atk_type}_{model.model_type}\\nMean confidence = {mean_conf_bin}',\n",
    "        xlim=[0, 1.0]\n",
    "    )\n",
    "axs.format(\n",
    "    suptitle='Softmax confidence on clean images',\n",
    "    ylabel='Count',\n",
    "    xlabel='Confidence'\n",
    ")\n",
    "\n",
    "# TODO: What's up with this plot? shouldn't have a plateu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_bins = 50\n",
    "bins = np.linspace(0, analysis_params.adversarial_num_steps, num_bins)\n",
    "\n",
    "fig, axs = plot.subplots(ncols=2, nrows=2)\n",
    "for ax, model, atk_type in zip(axs, analyzers+fmodels, ['DSC', 'DSC', 'FB', 'FB']):\n",
    "    count, bin_edges = np.histogram(model.success_indices, bins)\n",
    "    bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "    bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "    ax.bar(bin_centers, count, width=1, color='k')\n",
    "    mean_idx = np.mean(model.success_indices)\n",
    "    mean_success_idx = np.abs(model.success_indices - mean_idx).argmin()\n",
    "    mean_bin_idx = np.abs(bin_edges - mean_idx).argmin()\n",
    "    mean_success_bin = bin_edges[mean_bin_idx]\n",
    "    ax.axvline(mean_success_bin, lw=1, ls='-', color='r')\n",
    "    ax.format(title=f'{atk_type}_{model.model_type}\\nMean success timestep = {mean_success_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['MLP 2L;768N','LCA 2L;768N']\n",
    "\n",
    "fb_all_success_indices = np.intersect1d(*[fmodel.success_indices[0] for fmodel in fmodels])\n",
    "fb_adv_results_list = [np.array(fmodel.mean_squared_distances[0])[fb_all_success_indices] for fmodel in fmodels]\n",
    "fb_all_results = np.stack(fb_adv_results_list, axis=-1).squeeze()\n",
    "fb_data = pd.DataFrame(\n",
    "    fb_all_results,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "\n",
    "dsc_all_success_indices = np.intersect1d(*[analyzer.success_indices for analyzer in analyzers])\n",
    "dsc_adv_results_list = [analyzer.mean_squared_distances[dsc_all_success_indices] for analyzer in analyzers]\n",
    "dsc_all_results = np.stack(dsc_adv_results_list, axis=-1).squeeze()\n",
    "dsc_data = pd.DataFrame(\n",
    "    dsc_all_results,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "\n",
    "fig, axs = plot.subplots(ncols=2, axwidth=2.5, share=0)\n",
    "axs.format(grid=False, suptitle='L infinity Attack Mean Squared Distances')\n",
    "ax = axs[0]\n",
    "obj1 = ax.boxplot(\n",
    "    fb_data, linewidth=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax.format(title='Foolbox')\n",
    "\n",
    "ax = axs[1]\n",
    "obj2 = ax.boxplot(\n",
    "    dsc_data, linewidth=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax.format(title='Deep Sparse Coding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attack images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
