{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#from typing import Union, Any, Optional, Callable, Tuple\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if ROOT_DIR not in sys.path: sys.path.append(ROOT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import proplot as plot\n",
    "#from scipy.stats import pearsonr as linear_correlation\n",
    "import tensorflow as tf\n",
    "#import eagerpy as ep\n",
    "#import torch\n",
    "#from torch import nn, optim\n",
    "#from torch.nn import functional as F\n",
    "\n",
    "#from DeepSparseCoding.tf1x.utils.logger import Logger as tfLogger\n",
    "import DeepSparseCoding.tf1x.analysis.analysis_picker as ap\n",
    "#from DeepSparseCoding.tf1x.data.dataset import Dataset\n",
    "import DeepSparseCoding.tf1x.data.data_selector as ds\n",
    "#import DeepSparseCoding.tf1x.utils.data_processing as tfdp\n",
    "import DeepSparseCoding.tf1x.params.param_picker as pp\n",
    "import DeepSparseCoding.tf1x.models.model_picker as mp\n",
    "\n",
    "#from DeepSparseCoding.utils.file_utils import Logger\n",
    "#import DeepSparseCoding.utils.dataset_utils as dataset_utils\n",
    "#import DeepSparseCoding.utils.loaders as loaders\n",
    "import DeepSparseCoding.utils.plot_functions as pf\n",
    "\n",
    "#import foolbox\n",
    "#from foolbox import PyTorchModel\n",
    "#from foolbox.attacks.projected_gradient_descent import LinfProjectedGradientDescentAttack\n",
    "#from foolbox.types import Bounds\n",
    "#from foolbox.models.base import Model\n",
    "#from foolbox.attacks.base import T\n",
    "#from foolbox.criteria import Misclassification\n",
    "#from foolbox.attacks.base import raise_if_kwargs\n",
    "#from foolbox.attacks.base import get_criterion\n",
    "\n",
    "rand_seed = 123\n",
    "rand_state = np.random.RandomState(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DeepSparseCoding analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "  def __init__(self):\n",
    "    self.device = \"/gpu:0\"\n",
    "    self.analysis_dataset = \"test\"\n",
    "    self.save_info = \"analysis_\" + self.analysis_dataset\n",
    "    self.overwrite_analysis_log = False\n",
    "    self.do_class_adversaries = False\n",
    "    self.do_run_analysis = False\n",
    "    self.do_evals = False\n",
    "    self.do_basis_analysis = False\n",
    "    self.do_inference = False\n",
    "    self.do_atas = False \n",
    "    self.do_recon_adversaries = False\n",
    "    self.do_neuron_visualization = False\n",
    "    self.do_full_recon = False\n",
    "    self.do_orientation_analysis = False \n",
    "    self.do_group_recons = False\n",
    "    \n",
    "    self.data_dir = os.path.join(ROOT_DIR, 'Datasets')\n",
    "    self.data_type = 'vanhateren'\n",
    "    self.vectorize_data = True\n",
    "    self.rescale_data = False\n",
    "    self.standardize_data = False\n",
    "    self.contrast_normalize = False\n",
    "    self.whiten_data = True\n",
    "    self.whiten_method = \"FT\"\n",
    "    self.whiten_batch_size = 2\n",
    "    self.extract_patches = True\n",
    "    self.num_patches = 1e4\n",
    "    self.patch_edge_size = 16\n",
    "    self.overlapping_patches = True\n",
    "    self.randomize_patches = True\n",
    "    self.patch_variance_threshold = 0.0\n",
    "    self.lpf_data = False # whitening automatically includes lpf\n",
    "    self.lpf_cutoff = 0.7\n",
    "    self.batch_size = 100\n",
    "    self.random_seed = rand_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_params = params()\n",
    "analysis_params.projects_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "model_names = ['lca_512_vh', 'lca_1024_vh', 'lca_2560_vh']#, 'sae_768_vh', 'rica_768_vh']\n",
    "model_types = ['LCA', 'LCA', 'LCA']#, 'SAE', 'ICA']\n",
    "model_labels = ['2x', '4x', '10x']#, 'Sparse Autoencoder', 'Linear Autoencoder']\n",
    "analyzers = []\n",
    "for model_type, model_name, model_label in zip(model_types, model_names, model_labels):\n",
    "    analysis_params.model_name = model_name\n",
    "    analysis_params.version = '0.0'\n",
    "    analysis_params.model_dir = analysis_params.projects_dir+analysis_params.model_name\n",
    "    model_log_file = (analysis_params.model_dir+\"/logfiles/\"+analysis_params.model_name\n",
    "      +\"_v\"+analysis_params.version+\".log\")\n",
    "    analysis_params.model_type = model_type\n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analysis_params.save_info = \"analysis_selectivity\"\n",
    "    analyzer.setup(analysis_params)\n",
    "    analyzer.model_label = model_label\n",
    "    analyzer.model_type = model_type\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.get_data(analysis_params)\n",
    "data = analyzers[0].model.preprocess_dataset(data, analysis_params)\n",
    "data = analyzers[0].model.reshape_dataset(data, analysis_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VH data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_imgs = 6\n",
    "img_idx = np.random.randint(analysis_params.batch_size)\n",
    "fig, axs = plot.subplots(ncols=6)\n",
    "for inc_img in range(num_imgs):\n",
    "    im = axs[inc_img].imshow(data['train'].images[img_idx+inc_img,...].reshape(16, 16), cmap='greys_r')\n",
    "axs.format(suptitle=f'DSC van hateren example')\n",
    "pf.clear_axes(axs)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [np.squeeze(analyzer.eval_analysis(data['train'].images[0,...][None,...], ['lca/weights/w:0'], analyzer.analysis_params.save_info)['lca/weights/w:0']) for analyzer in analyzers if analyzer.model_type=='LCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [np.squeeze(analyzer.compute_activations(data['train'].images[0:100,...],\n",
    "    activation_operation=analyzer.model.get_encodings))\n",
    "    for analyzer in analyzers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def compute_lambda_activations(images, model, weights, batch_size=None, activation_operation=None):\n",
    "    \"\"\"\n",
    "    Computes the output code for a set of images.\n",
    "    Outputs:\n",
    "      evaluated activation_operation on the input images\n",
    "    Inputs:\n",
    "      images [np.ndarray] of shape (num_imgs, num_img_pixels)\n",
    "      batch_size [int] how many inputs to use in a batch\n",
    "      activation_operation [tf operation] that produces the output activation\n",
    "        if None then it defaults to `model.get_encodings()`\n",
    "    \"\"\"\n",
    "    if activation_operation is None:\n",
    "        activation_operation = model.get_encodings\n",
    "    images_shape = list(images.shape)\n",
    "    num_images = images_shape[0]\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.compat.v1.Session(config=config, graph=model.graph) as sess:\n",
    "        if batch_size is not None and batch_size < num_images:\n",
    "            assert num_images % batch_size == 0, (\n",
    "                \"batch_size=%g must divide evenly into num_images=%g\"%(batch_size, num_images))\n",
    "            num_batches = int(np.ceil(num_images / batch_size))\n",
    "            batch_image_shape = [batch_size] + images_shape[1:]\n",
    "            sess.run(model.init_op, {model.input_placeholder:np.zeros(batch_image_shape)})\n",
    "            activations = []\n",
    "            for batch_idx in range(num_batches):\n",
    "                im_batch_start_idx = int(batch_idx * batch_size)\n",
    "                im_batch_end_idx = int(np.min([im_batch_start_idx + batch_size, num_images]))\n",
    "                batch_images = images[im_batch_start_idx:im_batch_end_idx, ...]\n",
    "                feed_dict = model.get_feed_dict(batch_images, is_test=True)\n",
    "                feed_dict[model.weight_placeholder] = weights\n",
    "                outputs = sess.run(activation_operation(), feed_dict)\n",
    "                activations.append(outputs.copy())\n",
    "            activations = np.stack(activations, axis=0)\n",
    "            num_batches, batch_size, num_outputs = activations.shape\n",
    "            activations = activations.reshape((num_batches*batch_size, num_outputs))\n",
    "        else:\n",
    "            feed_dict = model.get_feed_dict(images, is_test=True)\n",
    "            feed_dict[model.weight_placeholder] = weights\n",
    "            sess.run(model.init_op, feed_dict)\n",
    "            activations = sess.run(activation_operation(), feed_dict)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb_activation = lambda x : tf.identity(x) # linear\n",
    "lambda_params = pp.get_params(\"lambda\")\n",
    "lambda_params.set_data_params(\"vanhateren\")\n",
    "lambda_params.batch_size = 100\n",
    "lambda_params.data_shape = [analysis_params.patch_edge_size**2] # assumes vector inputs (i.e. not convoultional)\n",
    "lambda_params.activation_function = lamb_activation\n",
    "num_neurons_list = [analyzer.model_params.num_neurons for analyzer in analyzers]\n",
    "for num_neurons, lca_weights in zip(num_neurons_list, weights):\n",
    "    lambda_params.num_neurons = num_neurons\n",
    "    lambda_model = mp.get_model(\"lambda\")\n",
    "    lambda_model.setup(lambda_params)\n",
    "    lambda_activations = compute_lambda_activations(\n",
    "        data['train'].images[0:100, ...],\n",
    "        lambda_model,\n",
    "        lca_weights,\n",
    "        batch_size=10\n",
    "    )\n",
    "    activations.append(lambda_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(vector):\n",
    "    \"\"\"\n",
    "    ensure input is a vector, and then divide it by its l2 norm.\n",
    "    Parameters:\n",
    "        vector [ np.ndarray] vector with shape [vector_length,].\n",
    "            It can also be a square image, which will first be vectorized\n",
    "    Outputs:\n",
    "        vector [np.ndarray] vector with shape [vector_length,] and l2-norm = 1\n",
    "    \"\"\"\n",
    "    vector = vector.reshape(vector.size)\n",
    "    vector = vector / np.linalg.norm(vector)\n",
    "    return vector\n",
    "\n",
    "def get_paired_vector_angles(vec_list_a, vec_list_b):\n",
    "    \"\"\"\n",
    "    Compute the angle in degrees between all pairs of vectors\n",
    "    Parameters:\n",
    "        vec_list_a [list] list of vectors (e.g. images) to compute the angle bewteen\n",
    "        vec_list_b [list] list of vectors (e.g. images) to compute the angle bewteen\n",
    "    Outputs:\n",
    "        angle_matrix [np.ndarray] of shape [num_vectors, num_vectors] with all angles between\n",
    "            basis functions in the lower triangle and upper triangle is set to -1\n",
    "    \"\"\"\n",
    "    num_vecs_a = len(vec_list_a)\n",
    "    num_vecs_b = len(vec_list_b)\n",
    "    vec_length = vec_list_a[0].size\n",
    "    assert vec_list_a[0].size == vec_length, (\"vector lengths must be equal\")\n",
    "    angle_matrix = np.zeros((num_vecs_a, num_vecs_b))\n",
    "    for a_idx in range(num_vecs_a):\n",
    "        for b_idx in range(num_vecs_b):\n",
    "            vec0 = normalize_vector(vec_list_a[a_idx]).reshape((vec_length, 1))\n",
    "            vec1 = normalize_vector(vec_list_b[b_idx]).reshape((vec_length, 1))\n",
    "            inner_products = np.dot(vec0.T, vec1)\n",
    "            inner_products = np.clip(inner_products, -1.0, 1.0)\n",
    "            angle = np.arccos(inner_products)\n",
    "            angle_matrix[a_idx, b_idx] = angle * (180 / np.pi)\n",
    "    return angle_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [data['train'].images[idx, ...].reshape((analysis_params.patch_edge_size**2, 1))\n",
    "    for idx in range(100)]\n",
    "weight_lists = [[lca_weights[:, idx].reshape((analysis_params.patch_edge_size**2, 1))\n",
    "    for idx in range(lca_weights.shape[1])]\n",
    "    for lca_weights in weights]\n",
    "angle_matrix_list = [get_paired_vector_angles(image_list, weight_list) for weight_list in weight_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(ncols=len(angle_matrix_list))\n",
    "for idx in range(len(angle_matrix_list)):\n",
    "    im = axs[idx].imshow(angle_matrix_list[idx], vmin=0, vmax=180)\n",
    "    axs[idx].format(title=analyzers[idx].model_label)\n",
    "axs[-1].colorbar(im, ticks=[0, 90, 180])\n",
    "axs.format(suptitle='Weight-to-Image Angles')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 0 #TODO: repeat this for all neurons\n",
    "interesting_images = []\n",
    "for activity in activations:\n",
    "    interesting_images.append(np.nonzeros(activity[:, neuron_idx] > activity[:, neuron_idx].max()/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
