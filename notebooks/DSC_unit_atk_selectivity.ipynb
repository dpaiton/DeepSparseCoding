{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if ROOT_DIR not in sys.path: sys.path.append(ROOT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import proplot as plot\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import DeepSparseCoding.tf1x.analysis.analysis_picker as ap\n",
    "import DeepSparseCoding.tf1x.data.data_selector as ds\n",
    "import DeepSparseCoding.tf1x.params.param_picker as pp\n",
    "import DeepSparseCoding.tf1x.models.model_picker as mp\n",
    "import DeepSparseCoding.utils.plot_functions as pf\n",
    "\n",
    "rand_seed = 123\n",
    "rand_state = np.random.RandomState(rand_seed)\n",
    "\n",
    "color_vals = dict(zip([\"blk\", \"lt_green\", \"md_green\", \"dk_green\", \"lt_blue\", \"md_blue\", \"dk_blue\", \"lt_red\", \"md_red\", \"dk_red\"],\n",
    "  [\"#000000\", \"#A9DFBF\", \"#196F3D\", \"#27AE60\", \"#AED6F1\", \"#3498DB\", \"#21618C\", \"#F5B7B1\", \"#E74C3C\", \"#943126\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DeepSparseCoding analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "  def __init__(self):\n",
    "    #self.device = \"/cpu\"\n",
    "    self.device = \"/gpu:0\"\n",
    "    self.analysis_dataset = \"test\"\n",
    "    self.save_info = \"analysis_\" + self.analysis_dataset\n",
    "    self.overwrite_analysis_log = False\n",
    "    self.do_class_adversaries = False\n",
    "    self.do_run_analysis = False\n",
    "    self.do_evals = False\n",
    "    self.do_basis_analysis = False\n",
    "    self.do_inference = False\n",
    "    self.do_atas = False \n",
    "    self.do_recon_adversaries = False\n",
    "    self.do_neuron_visualization = False\n",
    "    self.do_full_recon = False\n",
    "    self.do_orientation_analysis = False \n",
    "    self.do_group_recons = False\n",
    "    \n",
    "    self.data_dir = os.path.join(ROOT_DIR, 'Datasets')\n",
    "    self.data_type = 'vanhateren'\n",
    "    self.vectorize_data = True\n",
    "    self.rescale_data = False\n",
    "    self.standardize_data = False\n",
    "    self.contrast_normalize = False\n",
    "    self.whiten_data = True\n",
    "    self.whiten_method = \"FT\"\n",
    "    self.whiten_batch_size = 2\n",
    "    self.extract_patches = True\n",
    "    self.num_patches = 1e5\n",
    "    self.patch_edge_size = 16\n",
    "    self.overlapping_patches = True\n",
    "    self.randomize_patches = True\n",
    "    self.patch_variance_threshold = 0.0\n",
    "    self.lpf_data = False # whitening automatically includes lpf\n",
    "    self.lpf_cutoff = 0.7\n",
    "    self.batch_size = 100\n",
    "    self.rand_seed = rand_seed\n",
    "    self.rand_state = rand_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_params = params()\n",
    "#analysis_params.projects_dir = os.path.expanduser(\"~\")+\"/Redwood/JOV_Paper/Projects_New/\"\n",
    "analysis_params.projects_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "model_names = ['lca_512_vh', 'lca_1024_vh', 'lca_2560_vh']#, 'sae_768_vh', 'rica_768_vh']\n",
    "model_types = ['LCA', 'LCA', 'LCA']#, 'SAE', 'ICA']\n",
    "model_labels = ['2x', '4x', '10x']#, 'Sparse Autoencoder', 'Linear Autoencoder']\n",
    "analyzers = []\n",
    "for model_type, model_name, model_label in zip(model_types, model_names, model_labels):\n",
    "    analysis_params.model_name = model_name\n",
    "    analysis_params.version = '0.0'\n",
    "    analysis_params.model_dir = analysis_params.projects_dir+analysis_params.model_name\n",
    "    model_log_file = (analysis_params.model_dir+\"/logfiles/\"+analysis_params.model_name\n",
    "      +\"_v\"+analysis_params.version+\".log\")\n",
    "    analysis_params.model_type = model_type\n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analysis_params.save_info = \"analysis_selectivity\"\n",
    "    analyzer.setup(analysis_params)\n",
    "    analyzer.model_label = model_label\n",
    "    analyzer.model_type = model_type\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "    analyzer.load_analysis(save_info=\"analysis_train_kurakin_targeted\")\n",
    "    analyzer.nat_selectivity = {}\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, weights, and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.get_data(analysis_params)\n",
    "data = analyzers[0].model.preprocess_dataset(data, analysis_params)\n",
    "data = analyzers[0].model.reshape_dataset(data, analysis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = int(analysis_params.num_patches)\n",
    "#num_imgs = int(analysis_params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_imgs_test = 6\n",
    "img_idx = np.random.randint(num_imgs-num_imgs_test)\n",
    "fig, axs = plot.subplots(ncols=num_imgs_test)\n",
    "for inc_img in range(num_imgs_test):\n",
    "    im = axs[inc_img].imshow(data['train'].images[img_idx+inc_img,...].reshape(16, 16), cmap='greys_r')\n",
    "axs.format(suptitle=f'DSC van hateren example images')\n",
    "pf.clear_axes(axs)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "for analyzer in analyzers:\n",
    "    if analyzer.model_type == 'LCA':\n",
    "        print(f'Loading {analyzer.analysis_params.cp_loc} from {analyzer.model_label}')\n",
    "        weights.append(np.squeeze(analyzer.eval_analysis(data['train'].images[0,...][None,...],\n",
    "            ['lca/weights/w:0'], analyzer.analysis_params.save_info)['lca/weights/w:0']))\n",
    "#weights = [np.squeeze(analyzer.eval_analysis(data['train'].images[0,...][None,...], ['lca/weights/w:0'], analyzer.analysis_params.save_info)['lca/weights/w:0']) for analyzer in analyzers if analyzer.model_type=='LCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_plots_per_model = 6\n",
    "fig, axs = plot.subplots(ncols=num_plots_per_model, nrows=len(analyzers))\n",
    "for analyzer_idx, analyzer in enumerate(analyzers):\n",
    "    ax_row = analyzer_idx\n",
    "    weight_indices = np.random.randint(0, analyzer.model_params.num_neurons, num_plots_per_model)\n",
    "    for ax_col, weight_idx in enumerate(weight_indices):\n",
    "        im = axs[ax_row, ax_col].imshow(weights[analyzer_idx][:, weight_idx].reshape(16, 16), cmap='greys_r')\n",
    "        axs[ax_row, 0].format(title=f'{analyzer.model_label} overcomplete')\n",
    "    axs.format(suptitle=f'Model weights')\n",
    "    pf.clear_axes(axs)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(low=0, high=analyzers[0].model.params.num_neurons, size=3)\n",
    "fig, axs = plot.subplots(ncols=3, nrows=2)\n",
    "for fig_idx, neuron_idx in enumerate(indices):\n",
    "    axs[0, fig_idx].imshow(analyzers[0].bf_stats['basis_functions'][neuron_idx], cmap='greys_r')\n",
    "    axs[0, fig_idx].format(title=f'Diameter = {analyzers[0].bf_stats[\"diameters\"][neuron_idx]:.2f}')\n",
    "    axs[1, fig_idx].imshow(analyzers[0].bf_stats['envelopes'][neuron_idx], cmap='greys_r')\n",
    "pf.clear_axes(axs)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lca_activations = [np.squeeze(analyzer.compute_activations(data['train'].images[0:num_imgs,...],\n",
    "    activation_operation=analyzer.model.get_encodings))\n",
    "    for analyzer in analyzers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def compute_lambda_activations(images, model, weights, batch_size=None, activation_operation=None):\n",
    "    \"\"\"\n",
    "    Computes the output code for a set of images.\n",
    "    Outputs:\n",
    "      evaluated activation_operation on the input images\n",
    "    Inputs:\n",
    "      images [np.ndarray] of shape (num_imgs, num_img_pixels)\n",
    "      batch_size [int] how many inputs to use in a batch\n",
    "      activation_operation [tf operation] that produces the output activation\n",
    "        if None then it defaults to `model.get_encodings()`\n",
    "    \"\"\"\n",
    "    if activation_operation is None:\n",
    "        activation_operation = model.get_encodings\n",
    "    images_shape = list(images.shape)\n",
    "    num_images = images_shape[0]\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.compat.v1.Session(config=config, graph=model.graph) as sess:\n",
    "        if batch_size is not None and batch_size < num_images:\n",
    "            assert num_images % batch_size == 0, (\n",
    "                \"batch_size=%g must divide evenly into num_images=%g\"%(batch_size, num_images))\n",
    "            num_batches = int(np.ceil(num_images / batch_size))\n",
    "            batch_image_shape = [batch_size] + images_shape[1:]\n",
    "            sess.run(model.init_op, {model.input_placeholder:np.zeros(batch_image_shape)})\n",
    "            activations = []\n",
    "            for batch_idx in range(num_batches):\n",
    "                im_batch_start_idx = int(batch_idx * batch_size)\n",
    "                im_batch_end_idx = int(np.min([im_batch_start_idx + batch_size, num_images]))\n",
    "                batch_images = images[im_batch_start_idx:im_batch_end_idx, ...]\n",
    "                feed_dict = model.get_feed_dict(batch_images, is_test=True)\n",
    "                feed_dict[model.weight_placeholder] = weights\n",
    "                outputs = sess.run(activation_operation(), feed_dict)\n",
    "                activations.append(outputs.copy())\n",
    "            activations = np.stack(activations, axis=0)\n",
    "            num_batches, batch_size, num_outputs = activations.shape\n",
    "            activations = activations.reshape((num_batches*batch_size, num_outputs))\n",
    "        else:\n",
    "            feed_dict = model.get_feed_dict(images, is_test=True)\n",
    "            feed_dict[model.weight_placeholder] = weights\n",
    "            sess.run(model.init_op, feed_dict)\n",
    "            activations = sess.run(activation_operation(), feed_dict)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb_activation = lambda x : tf.identity(x) # linear\n",
    "lambda_params = pp.get_params(\"lambda\")\n",
    "lambda_params.set_data_params(\"vanhateren\")\n",
    "lambda_params.batch_size = analysis_params.batch_size\n",
    "lambda_params.data_shape = [analysis_params.patch_edge_size**2] # assumes vector inputs (i.e. not convoultional)\n",
    "lambda_params.activation_function = lamb_activation\n",
    "num_neurons_list = [analyzer.model_params.num_neurons for analyzer in analyzers]\n",
    "linear_activations = []\n",
    "for num_neurons, lca_weights in zip(num_neurons_list, weights):\n",
    "    lambda_params.num_neurons = num_neurons\n",
    "    lambda_model = mp.get_model(\"lambda\")\n",
    "    lambda_model.setup(lambda_params)\n",
    "    lambda_activations = compute_lambda_activations(\n",
    "        data['train'].images[0:num_imgs, ...],\n",
    "        lambda_model,\n",
    "        lca_weights,\n",
    "        batch_size=lambda_params.batch_size\n",
    "    )\n",
    "    linear_activations.append(lambda_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_then_normalize(vector, mask, mask_threshold):\n",
    "    \"\"\"\n",
    "    ensure input is a vector, and then divide it by its l2 norm.\n",
    "    Parameters:\n",
    "        mask [np.ndarray] mask to zero out vector values with shape [vector_rows, vector_cols] or [vector_length,]\n",
    "        vector [np.ndarray] vector with shape [vector_rows, vector_cols] or [vector_length,].\n",
    "    Outputs:\n",
    "        vector [np.ndarray] masked vector with shape [vector_length,] and l2-norm = 1\n",
    "    \"\"\"\n",
    "    mask = mask.flatten()\n",
    "    vector = vector.flatten()\n",
    "    assert mask.size == vector.size, (\n",
    "        f'mask size = {mask.size} must equal vector size = {vector.size}')\n",
    "    mask /= mask.max()\n",
    "    mask[mask<mask_threshold] = 0\n",
    "    mask[mask>0] = 1\n",
    "    vector = np.multiply(mask, vector)\n",
    "    vector = vector / np.linalg.norm(vector)\n",
    "    return vector\n",
    "\n",
    "def angle_between_vectors(vec_a, vec_b):\n",
    "    \"\"\"\n",
    "    Returns the cosine angle between two vectors\n",
    "    Parameters:\n",
    "        vec_a [np.ndarray] l2 normalized vector with shape [vector_length, 1]\n",
    "        vec_b [np.ndarray] l2 normalized vector with shape [vector_length, 1]\n",
    "    Outputs:\n",
    "        angle [float] angle between the two vectors, in  degrees\n",
    "    \"\"\"\n",
    "    inner_products = np.dot(vec_a.T, vec_b)\n",
    "    inner_products = np.clip(inner_products, -1.0, 1.0)\n",
    "    angle = np.arccos(inner_products) * (180 / np.pi)\n",
    "    return angle\n",
    "\n",
    "def one_to_many_angles(vec_a, vec_list_b):\n",
    "    \"\"\"\n",
    "    Returns cosine angle from one vector to a list of vectors\n",
    "    Parameters:\n",
    "        vec_a [np.ndarray] l2 normalized vector with shape [vector_length,]\n",
    "        vec_list_b [list of np.ndarray] list of l2 normalized vectors with shape [num_vectors][vector_length,]\n",
    "    Outputs:\n",
    "        angles [list of floats] angle between vec_a and each of the vectors in vec_list_b, in degrees\n",
    "    \"\"\"\n",
    "    angles = []\n",
    "    for vec_b in vec_list_b:\n",
    "        angles.append(angle_between_vectors(vec_a, vec_b))\n",
    "    return angles\n",
    "\n",
    "def masked_weight_to_image_angles(weight, mask, image_list, mask_threshold):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_images = len(image_list)\n",
    "    vec0 = mask_then_normalize(weight, mask, mask_threshold)\n",
    "    vec1_list = []\n",
    "    for image in image_list:\n",
    "        assert image.size == vec0.size, (\n",
    "          f'Each image size = {image.size} must equal the weight size = {vec0.size}')\n",
    "        vec1_list.append(mask_then_normalize(image, mask, mask_threshold))\n",
    "    angles = one_to_many_angles(vec0, vec1_list)\n",
    "    return angles\n",
    "\n",
    "def interesting_image_indices(activations, portion_of_max):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for activity in activations:\n",
    "        sub_index_list = []\n",
    "        for neuron_idx in range(activity.shape[1]):\n",
    "            threshold = activity[:, neuron_idx].max()*portion_of_max\n",
    "            sub_index_list.append(np.nonzero((activity[:, neuron_idx] > threshold)))\n",
    "        indices.append(sub_index_list)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_of_max = 0.5\n",
    "linear_interesting_indices = interesting_image_indices(linear_activations, portion_of_max)\n",
    "lca_interesting_indices = interesting_image_indices(lca_activations, portion_of_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_zip = zip(lca_interesting_indices, linear_interesting_indices, analyzers, model_labels)\n",
    "for nl_ind, l_ind, analyzer, label in loop_zip:\n",
    "    num_nl_ind = [neuron_ind[0].size for neuron_ind in nl_ind]\n",
    "    avg_num_nl_ind = np.mean(num_nl_ind)\n",
    "    std_num_nl_ind = np.std(num_nl_ind)\n",
    "    print(f'model {analyzer.model_type}_{analyzer.model_label} had an average of {avg_num_nl_ind:.1f} interesting images')\n",
    "    num_l_ind = [neuron_ind[0].size for neuron_ind in l_ind]\n",
    "    avg_num_l_ind = np.mean(num_l_ind)\n",
    "    std_num_l_ind = np.std(num_l_ind)\n",
    "    print(f'model linear_{label} had an average of {avg_num_l_ind:.1f} interesting images')\n",
    "    analyzer.nat_selectivity['num_interesting_img_nl'] = num_nl_ind\n",
    "    analyzer.nat_selectivity['num_interesting_img_l'] = num_l_ind\n",
    "    analyzer.nat_selectivity['num_interesting_img_nl_std'] = std_num_nl_ind\n",
    "    analyzer.nat_selectivity['num_interesting_img_l_std'] = std_num_l_ind\n",
    "    analyzer.nat_selectivity['num_interesting_img_nl_mean'] = avg_num_nl_ind\n",
    "    analyzer.nat_selectivity['num_interesting_img_l_mean'] = avg_num_l_ind\n",
    "    analyzer.nat_selectivity['oc_label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interesting_means = np.stack([np.array([analyzer.nat_selectivity['num_interesting_img_nl_mean'], analyzer.nat_selectivity['num_interesting_img_l_mean']]) for analyzer in analyzers], axis=0)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    num_interesting_means,\n",
    "    index=pd.Index(model_labels, name='Overcompleteness'),\n",
    "    columns=['LCA', 'Linear']\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plot.subplots(nrows=1, aspect=2, axwidth=4.8, share=0, hratios=(3))\n",
    "obj = ax.bar(\n",
    "    df,\n",
    "    cycle=[color_vals['md_red'], color_vals['md_green']],\n",
    "    edgecolor='black',\n",
    ")\n",
    "\n",
    "num_interesting_stds = np.stack([np.array([analyzer.nat_selectivity['num_interesting_img_nl_std'], analyzer.nat_selectivity['num_interesting_img_l_std']]) for analyzer in analyzers], axis=0)\n",
    "half_bar_width = np.abs(obj[1].patches[0].xy[0] - obj[0].patches[0].xy[0])/2\n",
    "lca_bar_locs = [patch.xy[0]+half_bar_width for patch in obj[0].patches]\n",
    "lin_bar_locs = [patch.xy[0]+half_bar_width for patch in obj[1].patches]\n",
    "ax.errorbar(lca_bar_locs, num_interesting_means[:,0] , yerr=num_interesting_stds[:,0], color='k', fmt='.')\n",
    "ax.errorbar(lin_bar_locs, num_interesting_means[:,1] , yerr=num_interesting_stds[:,1], color='k', fmt='.')\n",
    "\n",
    "ax.legend(obj, frameon=False)\n",
    "ax.format(\n",
    "    xlocator=1,\n",
    "    xminorlocator=0.5,\n",
    "    ytickminor=False,\n",
    "    ylim=[0, np.max(num_interesting_means)+np.max(num_interesting_stds)],\n",
    "    suptitle='Average number of intersting images'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([analyzer.model_params.num_steps for analyzer in analyzers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_threshold = 0.5\n",
    "\n",
    "vect_size = analysis_params.patch_edge_size**2\n",
    "image_list = [data['train'].images[idx, ...].reshape((vect_size, 1))\n",
    "    for idx in range(analysis_params.batch_size)]\n",
    "weight_list = [[weight_matrix[:, idx].reshape((vect_size, 1))\n",
    "    for idx in range(weight_matrix.shape[1])]\n",
    "    for weight_matrix in weights]\n",
    "mask_list = [[envelope.reshape((vect_size, 1))\n",
    "    for envelope in analyzer.bf_stats['envelopes']]\n",
    "    for analyzer in analyzers]\n",
    "\n",
    "for model_index, analyzer in enumerate(analyzers):\n",
    "    lca_weight_angles = []\n",
    "    linear_weight_angles = []\n",
    "    for weight_index in range(analyzers[model_index].model.params.num_neurons):\n",
    "        model_weight = weight_list[model_index][weight_index]\n",
    "        model_mask = mask_list[model_index][weight_index]\n",
    "        lca_images = [data['train'].images[idx, ...].flatten()\n",
    "            for idx in lca_interesting_indices[model_index][weight_index][0]]\n",
    "        angles = masked_weight_to_image_angles(model_weight, model_mask, lca_images, mask_threshold)\n",
    "        lca_weight_angles.append(angles)\n",
    "        linear_images = [data['train'].images[idx, ...].flatten()\n",
    "            for idx in linear_interesting_indices[model_index][weight_index][0]]\n",
    "        angles = masked_weight_to_image_angles(model_weight, model_mask, linear_images, mask_threshold)\n",
    "        linear_weight_angles.append(angles)\n",
    "    analyzer.nat_selectivity['lca_angles'] = lca_weight_angles\n",
    "    analyzer.nat_selectivity['linear_angles'] = linear_weight_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_angles = [analyzer.nat_selectivity['lca_angles'] for analyzer in analyzers]\n",
    "linear_angles = [analyzer.nat_selectivity['linear_angles'] for analyzer in analyzers]\n",
    "num_plots_per_model = 3\n",
    "nbins=20\n",
    "fig, axs = plot.subplots(ncols=len(analyzers), nrows=num_plots_per_model, sharey=False)\n",
    "max_vals = []\n",
    "for model_idx in range(len(analyzers)):\n",
    "    weight_indices = np.random.randint(0, analyzers[model_idx].model_params.num_neurons, num_plots_per_model)\n",
    "    for row_idx, weight_idx in enumerate(weight_indices):\n",
    "        indiv_lin_angles = linear_angles[model_idx][weight_idx]\n",
    "        indiv_lca_angles = lca_angles[model_idx][weight_idx]\n",
    "        axs[model_idx, row_idx].hist(indiv_lin_angles, bins=nbins, color=color_vals['md_green'], alpha=0.5, label='Linear')\n",
    "        axs[model_idx, row_idx].hist(indiv_lca_angles, bins=nbins, color=color_vals['md_red'], alpha=0.5, label='LCA')\n",
    "        max_vals.append(np.max([np.max(indiv_lin_angles), np.max(indiv_lca_angles)]))\n",
    "        axs[model_idx, row_idx].format(title=f'Neuron {weight_idx}; {model_labels[model_idx]} Overcompleteness')\n",
    "axs[0,0].legend(loc='ur', ncols=1, frameon=False)\n",
    "axs.format(suptitle='Exciting image angles per neuron', xlabel='Image-to-weight angle', ylabel='Number of images', xlim=[0, 90])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    lca_model_means = []\n",
    "    lca_model_vars = []\n",
    "    lin_model_means = []\n",
    "    lin_model_vars = []\n",
    "    for weight_idx in range(analyzer.model_params.num_neurons):\n",
    "        indiv_lca_angles = analyzer.nat_selectivity['lca_angles'][weight_idx]\n",
    "        if len(indiv_lca_angles) > 0:\n",
    "            lca_model_means.append(np.mean(indiv_lca_angles))\n",
    "            lca_model_vars.append(np.var(indiv_lca_angles))\n",
    "        else:\n",
    "            lca_model_means.append(-1)\n",
    "            lca_model_vars.append(-1)\n",
    "        indiv_lin_angles = analyzer.nat_selectivity['linear_angles'][weight_idx]\n",
    "        if len(indiv_lin_angles) > 0:\n",
    "            lin_model_means.append(np.mean(indiv_lin_angles))\n",
    "            lin_model_vars.append(np.var(indiv_lin_angles))\n",
    "        else:\n",
    "            lin_model_means.append(-1)\n",
    "            lin_model_vars.append(-1)\n",
    "    analyzer.nat_selectivity['lca_means'] = lca_model_means\n",
    "    analyzer.nat_selectivity['lca_vars'] = lca_model_vars\n",
    "    analyzer.nat_selectivity['lin_means'] = lin_model_means\n",
    "    analyzer.nat_selectivity['lin_vars'] = lin_model_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(ncols=len(analyzers), nrows=1, sharey=False)\n",
    "for ax, analyzer in zip(axs, analyzers):\n",
    "    lin_data = [mean for mean in analyzer.nat_selectivity['lin_means'] if mean>0]\n",
    "    non_lin_data = [mean for mean in analyzer.nat_selectivity['lca_means'] if mean>0]\n",
    "    h1 = ax.hist(lin_data, bins=nbins, color=color_vals['md_green'], alpha=0.5, label='Linear')\n",
    "    h2 = ax.hist(non_lin_data, bins=nbins, color=color_vals['md_red'], alpha=0.5, label='LCA')\n",
    "    oc = analyzer.nat_selectivity['oc_label']\n",
    "    ax.format(title=f'{oc} Overcompleteness')\n",
    "axs[0,0].legend(loc='ul', frameon=False, ncols=1)\n",
    "axs[0,0].format(ylabel='Number of images')\n",
    "axs.format(\n",
    "    suptitle='Exciting image angles',\n",
    "    xlabel='Mean image-to-weight angle',\n",
    "    xlim=[0, 90]\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    np.savez(analyzer.analysis_out_dir+'savefiles/natural_image_selectivity.npz', data=analyzer.nat_selectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
