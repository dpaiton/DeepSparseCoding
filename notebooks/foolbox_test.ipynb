{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Union, Any, Optional, Callable, Tuple\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if ROOT_DIR not in sys.path: sys.path.append(ROOT_DIR)\n",
    "    \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proplot as plot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from DeepSparseCoding.utils.file_utils import Logger\n",
    "import DeepSparseCoding.utils.loaders as loaders\n",
    "import DeepSparseCoding.utils.run_utils as run_utils\n",
    "import DeepSparseCoding.utils.dataset_utils as dataset_utils\n",
    "import DeepSparseCoding.utils.run_utils as ru\n",
    "import DeepSparseCoding.utils.plot_functions as pf\n",
    "import DeepSparseCoding.utils.data_processing as dp\n",
    "\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "import foolbox.attacks as fa\n",
    "from foolbox.types import Bounds\n",
    "from foolbox.attacks.base import T\n",
    "from foolbox.models.base import Model\n",
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.attacks.base import raise_if_kwargs\n",
    "from foolbox.attacks.base import get_criterion\n",
    "from foolbox.attacks.projected_gradient_descent import LinfProjectedGradientDescentAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_mnist_fb() -> PyTorchModel:\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, 3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, 3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Dropout2d(0.25),\n",
    "        nn.Flatten(),  # type: ignore\n",
    "        nn.Linear(9216, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.Linear(128, 10),\n",
    "        #nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    #path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"mnist_cnn.pth\")\n",
    "    path = os.path.join(*[ROOT_DIR, 'DeepSparseCoding', 'mnist_cnn.pth'])\n",
    "    model.load_state_dict(torch.load(path))  # type: ignore\n",
    "    model.eval()\n",
    "    #preprocessing = dict(mean=0.1307, std=0.3081)\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1))#, preprocessing=preprocessing)\n",
    "    return fmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_dsc(log_file, cp_file):\n",
    "    logger = Logger(log_file, overwrite=False)\n",
    "    log_text = logger.load_file()\n",
    "    params = logger.read_params(log_text)[-1]\n",
    "    params.cp_latest_filename = cp_file\n",
    "    params.standardize_data = False\n",
    "    params.rescale_data_to_one = True\n",
    "    train_loader, val_loader, test_loader, data_params = dataset_utils.load_dataset(params)\n",
    "    for key, value in data_params.items():\n",
    "        setattr(params, key, value)\n",
    "    model = loaders.load_model(params.model_type)\n",
    "    model.setup(params, logger)\n",
    "    model.params.analysis_out_dir = os.path.join(\n",
    "        *[model.params.model_out_dir, 'analysis', model.params.version])\n",
    "    model.params.analysis_save_dir = os.path.join(model.params.analysis_out_dir, 'savefiles')\n",
    "    if not os.path.exists(model.params.analysis_save_dir):\n",
    "        os.makedirs(model.params.analysis_save_dir)\n",
    "    model.to(params.device)\n",
    "    model.load_checkpoint()\n",
    "    fmodel = PyTorchModel(model.eval(), bounds=(0, 1))\n",
    "    fmodel.orig_model = model\n",
    "    return fmodel, model, test_loader, model.params.batch_size, model.params.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = [\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'mlp_768_mnist', 'logfiles', 'mlp_768_mnist_v0.log']),\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'lca_768_mlp_mnist', 'logfiles', 'lca_768_mlp_mnist_v0.log'])\n",
    "    ]\n",
    "\n",
    "cp_latest_filenames = [\n",
    "    os.path.join(*[ROOT_DIR,'Torch_projects', 'mlp_768_mnist', 'checkpoints', 'mlp_768_mnist_latest_checkpoint_v0.pt']),\n",
    "    os.path.join(*[ROOT_DIR, 'Torch_projects', 'lca_768_mlp_mnist', 'checkpoints', 'lca_768_mlp_mnist_latest_checkpoint_v0.pt'])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel_mlp, dmodel_mlp, test_loader, batch_size, device = create_mnist_dsc(log_files[0], cp_latest_filenames[0])\n",
    "fmodel_mlp.type = 'MLP'\n",
    "fmodel_cnn = create_mnist_fb()\n",
    "fmodel_cnn.type = 'CNN'\n",
    "fmodel_lca, dmodel_lca = create_mnist_dsc(log_files[1], cp_latest_filenames[1])[:2]\n",
    "fmodel_lca.type = 'LCA'\n",
    "model_list = {fmodel_mlp.type:fmodel_mlp, fmodel_cnn.type:fmodel_cnn, fmodel_lca.type:fmodel_lca}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list['MLP'](next(iter(test_loader))[0].reshape(batch_size, 784).to(device)[0,...][None,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = False#True\n",
    "\n",
    "num_batches =  10#len(test_loader.dataset) // batch_size\n",
    "\n",
    "attack_params = {\n",
    "    'LinfPGD': {\n",
    "        'random_start':False,\n",
    "        'abs_stepsize':0.002,\n",
    "        'steps':500\n",
    "    },\n",
    "    'L2PGD': {\n",
    "        'random_start':False,\n",
    "        'abs_stepsize':0.45,\n",
    "        'steps':2000\n",
    "    }\n",
    "    #'DDN' - best attack in terms of simplicity & effectiveness - Lukas\n",
    "}\n",
    "\n",
    "linf_epsilons = [ # allowed perturbation size\n",
    "    0.0,\n",
    "    0.03,\n",
    "    0.06,\n",
    "    0.09,\n",
    "    0.1,\n",
    "    0.13,\n",
    "    0.16,\n",
    "    0.19,\n",
    "    0.2,\n",
    "    0.23,\n",
    "    0.26,\n",
    "    0.29,\n",
    "    0.3,\n",
    "    0.33,\n",
    "    0.36,\n",
    "    0.39,\n",
    "    0.4\n",
    "]\n",
    "\n",
    "l2_epsilons = [10 * eps for eps in linf_epsilons]\n",
    "\n",
    "attacks = [\n",
    "    (fa.LinfPGD(**attack_params['LinfPGD']), linf_epsilons),\n",
    "    (fa.L2PGD(**attack_params['L2PGD']), l2_epsilons),\n",
    "    #fa.FGSM(),\n",
    "    #fa.LinfBasicIterativeAttack(),\n",
    "    #fa.LinfAdditiveUniformNoiseAttack(),\n",
    "    #fa.LinfDeepFoolAttack(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if load_results:\n",
    "    attack_results = []\n",
    "    for model_index, (model_type, fmodel) in enumerate(model_list.items()):\n",
    "        attack_results.append(np.load(f'adv_attack_results_{model_type}.npz', allow_pickle=True)['data'].item())\n",
    "else:\n",
    "    attack_results = []\n",
    "    for model_index, (model_type, fmodel) in enumerate(model_list.items()):\n",
    "        attack_success = np.zeros(\n",
    "                (len(attacks), len(linf_epsilons), num_batches, batch_size), dtype=np.bool)\n",
    "        for batch_index, (data, target) in enumerate(test_loader):\n",
    "            if batch_index < num_batches:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                images, labels = ep.astensors(*(data, target))\n",
    "                if model_type == 'CNN':\n",
    "                    images = images.squeeze().expand_dims(axis=1)\n",
    "                else:\n",
    "                    images = images.reshape((batch_size, 784))\n",
    "                print('\\n', '~' * 79)\n",
    "                print(f'Model type: {model_type} [{model_index+1} out of {len(model_list)}]')\n",
    "                print(f'Batch {batch_index+1} out of {num_batches}')\n",
    "                print(f'accuracy {accuracy(fmodel, images, labels)}')\n",
    "                for attack_index, (attack, epsilons) in enumerate(attacks):\n",
    "                    advs, _, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "                    assert success.shape == (len(epsilons), len(images))\n",
    "                    success_ = success.numpy()\n",
    "                    assert success_.dtype == np.bool\n",
    "                    attack_success[attack_index, :, batch_index, :] = success_\n",
    "                    print('\\n', attack)\n",
    "                    print('  ', 1.0 - success_.mean(axis=-1).round(2))\n",
    "                robust_accuracy = 1.0 - attack_success[:, :, batch_index, :].max(axis=0).mean(axis=-1)\n",
    "                #print('\\n', '-' * 79, '\\n')\n",
    "                #print('worst case (best attack per-sample)')\n",
    "                #print('  ', robust_accuracy.round(2))\n",
    "                #print('-' * 79)\n",
    "        attack_success = attack_success.reshape(\n",
    "            (len(attacks), len(epsilons), num_batches * batch_size))\n",
    "        attack_types = []\n",
    "        epsilon_list = []\n",
    "        for attack, epsilons in attacks:\n",
    "            attack_types.append(str(type(attack)).split('.')[-1][:-2])\n",
    "            epsilon_list.append(epsilons)\n",
    "        out_dict = {\n",
    "            'num_batches':num_batches,\n",
    "            'batch_size':batch_size,\n",
    "            'adversarial_analysis':attack_success,\n",
    "            'attack_types':attack_types,\n",
    "            'epsilons':epsilon_list,\n",
    "            'attack_params':attack_params}\n",
    "        attack_results.append(out_dict)\n",
    "        np.savez(f'adv_attack_results_{model_type}.npz', data=out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_abs = True\n",
    "\n",
    "if(plot_abs):\n",
    "    abs_filename = os.path.join(\n",
    "        *[ROOT_DIR, 'analysis-by-synthesis', 'figures', 'Linf_accuracy_distortion_curves.pickle'])\n",
    "    with open(abs_filename, 'rb') as file:\n",
    "        abs_linf_pgd_accuracies = pickle.load(file)\n",
    "\n",
    "fig, axes = plot.subplots(ncols=len(attacks), nrows=1)#, share=0)\n",
    "handles = []\n",
    "for model_idx, (results_dict, model_type) in enumerate(zip(attack_results, model_list.keys())):\n",
    "    for attack_idx in range(len(attacks)):\n",
    "        score = results_dict['adversarial_analysis'][attack_idx, ...]\n",
    "        attack_accuracy = 1.0 - score.mean(axis=-1)\n",
    "        y_vals = 100*attack_accuracy\n",
    "        x_vals = results_dict['epsilons'][attack_idx]\n",
    "        handle = axes[attack_idx].plot(x_vals, y_vals, label=model_type)\n",
    "        if(attack_idx == 0):\n",
    "            handles.extend(handle)\n",
    "        if(plot_abs):\n",
    "            if(model_idx == 0 and attack_idx == 0):\n",
    "                for abs_model_type, abs_model_accuracy in abs_linf_pgd_accuracies.items():\n",
    "                    if(abs_model_type not in ['Binary CNN', 'Nearest Neighbor', 'Binary ABS', 'CNN']):\n",
    "                        handle = axes[attack_idx].plot(\n",
    "                            abs_model_accuracy['x'], abs_model_accuracy['y'], '--', label=abs_model_type)\n",
    "                        handles.extend(handle)\n",
    "        axes[attack_idx].format(title=results_dict['attack_types'][attack_idx])\n",
    "        axes[attack_idx].format(\n",
    "            xlabel='Maximum perturbation size',\n",
    "            xlim=[0.0, np.max(x_vals)],\n",
    "            ylim=[0, 100])\n",
    "axes.format(suptitle='Standard Robustness Evaluation', ylabel='Model accuracy')\n",
    "fig.legend(handles, ncols=1, frame=False, label='Model type', loc='right')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "test_confidences = []\n",
    "for model_type, fmodel in model_list.items():\n",
    "    batch_confidences = []\n",
    "    batch_accuracies = []\n",
    "    for batch_index, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        images, labels = ep.astensors(*(data, target))\n",
    "        if model_type == 'CNN':\n",
    "            images = images.squeeze().expand_dims(axis=1)\n",
    "        else:\n",
    "            images = images.reshape((batch_size, 784))\n",
    "        logits = fmodel(images)\n",
    "        confidence = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        batch_confidences.append(confidence.numpy())\n",
    "        batch_accuracies.append(accuracy(fmodel, images, labels))\n",
    "    all_confidences = np.stack(batch_confidences, axis=0)\n",
    "    all_accuracies = np.stack(batch_accuracies, axis=0)\n",
    "    num_batches, batch_size, num_classes = all_confidences.shape\n",
    "    test_confidences.append(all_confidences.reshape(num_batches*batch_size, num_classes))\n",
    "    test_accuracies.append(np.mean(all_accuracies))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class LinfProjectedGradientDescentAttackWithStopping(LinfProjectedGradientDescentAttack):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        rel_stepsize: float = 0.025,\n",
    "        abs_stepsize: Optional[float] = None,\n",
    "        steps: int = 50,\n",
    "        random_start: bool = True,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            rel_stepsize=rel_stepsize,\n",
    "            abs_stepsize=abs_stepsize,\n",
    "            steps=steps,\n",
    "            random_start=random_start,\n",
    "        )\n",
    "        \n",
    "    def normalize(\n",
    "        self, gradients: ep.Tensor, *, x: ep.Tensor, bounds: Bounds\n",
    "    ) -> ep.Tensor:\n",
    "        return gradients.sign()\n",
    "        \n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        epsilon: float,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x0, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        if not isinstance(criterion_, Misclassification):\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        labels = criterion_.labels\n",
    "        loss_fn = self.get_loss_fn(model, labels)\n",
    "\n",
    "        if self.abs_stepsize is None:\n",
    "            stepsize = self.rel_stepsize * epsilon\n",
    "        else:\n",
    "            stepsize = self.abs_stepsize\n",
    "\n",
    "        x = x0\n",
    "\n",
    "        if self.random_start:\n",
    "            x = self.get_random_start(x0, epsilon)\n",
    "            x = ep.clip(x, *model.bounds)\n",
    "        else:\n",
    "            x = x0\n",
    "        confidence_threshold = 0.7#0.9\n",
    "        store_x = np.zeros_like(x)\n",
    "        store_time_step = -1*np.ones(x.shape[0], dtype=np.int32)\n",
    "        store_confidence = np.zeros(x.shape[0], dtype=np.float32)\n",
    "        all_kept_indices = []\n",
    "        time_step = 0\n",
    "        num_failed = 0\n",
    "        while len(set(all_kept_indices)) < x.shape[0]:\n",
    "            loss, gradients = self.value_and_grad(loss_fn, x)\n",
    "            gradients = self.normalize(gradients=gradients, x=x, bounds=model.bounds)\n",
    "            x = x + stepsize * gradients\n",
    "            x = self.project(x, x0, epsilon)\n",
    "            x = ep.clip(x, *model.bounds)\n",
    "            \n",
    "            # for untargeted attacks\n",
    "            adversarial_outputs = ep.softmax(model(x)).numpy().copy()\n",
    "            adversarial_outputs[np.arange(x.shape[0]), labels.numpy()] = 0 # zero confidence at true label\n",
    "            adversarial_confidence = ep.max(adversarial_outputs, axis=1) # highest non-true label confidence\n",
    "            \n",
    "            all_above_thresh = np.nonzero(np.squeeze(adversarial_confidence>confidence_threshold))[0]\n",
    "            keep_indices = np.array([], dtype=np.int32)\n",
    "            for adv_index in all_above_thresh:\n",
    "                if adv_index not in set(all_kept_indices):\n",
    "                    keep_indices = np.append(keep_indices, adv_index)\n",
    "            all_kept_indices.extend(keep_indices)\n",
    "            store_x[keep_indices, ...] = x.numpy()[keep_indices, ...]\n",
    "            store_time_step[keep_indices] = time_step\n",
    "            store_confidence[keep_indices] = adversarial_confidence[keep_indices]\n",
    "            time_step += 1\n",
    "            if time_step == self.steps-1:\n",
    "                num_failed = x.shape[0] - len(set(all_kept_indices))\n",
    "                print(f'Max steps = {self.steps} reached for model {model.type}, {num_failed} images did not achieve adversarial confidence threshold of {confidence_threshold}')\n",
    "                #import IPython; IPython.embed(); raise SystemExit\n",
    "                break\n",
    "        failed_indices = np.array([val for val in np.arange(x.shape[0], dtype=np.int32) if val not in all_kept_indices])\n",
    "        if len(failed_indices) > 0:\n",
    "            store_confidence[failed_indices] = adversarial_confidence[failed_indices]\n",
    "            store_x[failed_indices, ...] = x[failed_indices, ...]\n",
    "        reduc_dim = tuple(range(1, len(x.shape)))\n",
    "        msd = np.mean(np.square(store_x - x0.numpy()), axis=reduc_dim)\n",
    "        model.adversarial_images.append(store_x)\n",
    "        model.adversarial_time_step.append(store_time_step)\n",
    "        model.adversarial_confidence.append(store_confidence)\n",
    "        model.confidence_threshold.append(confidence_threshold)\n",
    "        model.failed_indices.append(failed_indices)\n",
    "        model.mean_squared_distances.append(msd)\n",
    "        model.num_failed.append(num_failed)\n",
    "        return restore_type(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "load_results = False\n",
    "\n",
    "attack_params = {\n",
    "    'LinfPGD': {\n",
    "        'random_start':False,\n",
    "        'abs_stepsize':0.002,\n",
    "        'steps':500 # maximum number of steps\n",
    "    }\n",
    "}\n",
    "epsilons = [1.0]\n",
    "attack = LinfProjectedGradientDescentAttackWithStopping(**attack_params['LinfPGD'])\n",
    "\n",
    "num_batches = len(test_loader)\n",
    "batch_size = test_loader.batch_size\n",
    "num_images = batch_size * num_batches\n",
    "if load_results:\n",
    "    for fmodel in model_list.values():\n",
    "        for batch_idx in range(num_batches):\n",
    "            tmp_results = np.load(\n",
    "                f'confidence_attack_{fmodel.type}.npz',\n",
    "                allow_pickle=True)['data'].item()\n",
    "            fmodel.adversarial_images = tmp_results['adversarial_images']\n",
    "            fmodel.adversarial_time_step = tmp_results['adversarial_time_step']\n",
    "            fmodel.adversarial_confidence = tmp_results['adversarial_confidence']\n",
    "            fmodel.confidence_threshold = tmp_results['confidence_threshold']\n",
    "            fmodel.failed_indices = tmp_results['failed_indices']\n",
    "            fmodel.mean_squared_distances = tmp_results['mean_squared_distances']\n",
    "            fmodel.epsilons = tmp_results['epsilons']\n",
    "            fmodel.max_steps = tmp_results['max_steps']\n",
    "            fmodel.num_failed = tmp_results['num_failed']\n",
    "else:\n",
    "    for fmodel in model_list.values():\n",
    "        fmodel.adversarial_images = []\n",
    "        fmodel.adversarial_time_step = []\n",
    "        fmodel.adversarial_confidence = []\n",
    "        fmodel.confidence_threshold = []\n",
    "        fmodel.failed_indices = []\n",
    "        fmodel.mean_squared_distances = []\n",
    "        fmodel.num_failed = []\n",
    "        for batch_idx, (batch_images, batch_labels) in enumerate(test_loader):\n",
    "            test_images = batch_images.to(device)\n",
    "            test_labels = batch_labels.to(device)\n",
    "            test_images, test_labels = ep.astensors(*(test_images, test_labels))\n",
    "            if(fmodel.type == 'CNN'):\n",
    "                test_images = test_images.squeeze().expand_dims(axis=1)\n",
    "            else:\n",
    "                test_images = test_images.squeeze().reshape((batch_size, 784))\n",
    "            advs, _, success = attack(fmodel, test_images, test_labels, epsilons=epsilons)\n",
    "        output_dict = {\n",
    "            'adversarial_images':fmodel.adversarial_images,\n",
    "            'adversarial_time_step':fmodel.adversarial_time_step,\n",
    "            'adversarial_confidence':fmodel.adversarial_confidence,\n",
    "            'confidence_threshold':fmodel.confidence_threshold,\n",
    "            'failed_indices':fmodel.failed_indices,\n",
    "            'num_failed':fmodel.num_failed,\n",
    "            'mean_squared_distances':fmodel.mean_squared_distances,\n",
    "            'epsilons':epsilons,\n",
    "            'image_bounds':fmodel.bounds,\n",
    "            'max_steps':attack.steps\n",
    "        }\n",
    "        np.savez(f'confidence_attack_{fmodel.type}.npz', data=output_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "adv_results = {}\n",
    "for model_type in model_list.keys():\n",
    "    adv_results[model_type] = []\n",
    "    for batch_idx in range(num_batches):\n",
    "        tmp_results = np.load(\n",
    "            f'confidence_attack_{model_type}.npz',\n",
    "            allow_pickle=True)['data'].item()\n",
    "        adversarial_images = tmp_results['adversarial_images']\n",
    "        adversarial_time_step = tmp_results['adversarial_time_step']\n",
    "        adversarial_confidence = tmp_results['adversarial_confidence']\n",
    "        confidence_threshold = tmp_results['confidence_threshold']\n",
    "        failed_indices = tmp_results['failed_indices']\n",
    "        mean_squared_distances = tmp_results['mean_squared_distances']\n",
    "        epsilon = tmp_results['epsilon']\n",
    "        image_bounds = tmp_results['image_bounds']\n",
    "        max_steps = tmp_results['max_steps']\n",
    "        num_failed = tmp_results['num_failed']\n",
    "    \n",
    "#lca_success_indices = np.argwhere(adv_results['LCA']['adversarial_time_step']>=0).squeeze()\n",
    "#mlp_success_indices = np.argwhere(adv_results['MLP']['adversarial_time_step']>=0).squeeze()\n",
    "#all_success_indices = np.union1d(lca_success_indices, mlp_success_indices)\n",
    "#adv_results_list = [adv_results['LCA']['mean_squared_distances'][all_success_indices],\n",
    "#    adv_results['MLP']['mean_squared_distances'][all_success_indices]]\n",
    "#all_results = np.stack(adv_results_list, axis=-1).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "names = ['LCA 2L;768N', 'MLP 2L;768N']\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    all_results,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "fig, axs = plot.subplots(ncols=1, axwidth=2.5)\n",
    "axs.format(grid=False, suptitle='Mean Squared Distances')\n",
    "ax = axs[0]\n",
    "obj1 = ax.boxplot(\n",
    "    data, lw=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax.format(title='L inf', titleloc='uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
