{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if ROOT_DIR not in sys.path: sys.path.append(ROOT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proplot as plot\n",
    "from scipy.stats import pearsonr as linear_correlation\n",
    "\n",
    "from DeepSparseCoding.tf1x.utils.logger import Logger as Logger\n",
    "import DeepSparseCoding.tf1x.analysis.analysis_picker as ap\n",
    "import DeepSparseCoding.tf1x.data.data_selector as ds\n",
    "import DeepSparseCoding.tf1x.utils.data_processing as dp\n",
    "import DeepSparseCoding.utils.plot_functions as pf\n",
    "\n",
    "rand_seed = 123\n",
    "rand_state = np.random.RandomState(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_conf_acc_prop(softmaxes, labels, bin_boundaries):\n",
    "    # Commented lines are for PyTorch\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    #confidences, predictions = softmaxes.max(axis=1)\n",
    "    confidences = softmaxes.max(axis=1)\n",
    "    predictions = dp.dense_to_one_hot(softmaxes.argmax(axis=1), num_classes=10)\n",
    "    #accuracies = predictions.eq(labels)\n",
    "    accuracies = np.equal(predictions, labels)\n",
    "    bin_confidence = []\n",
    "    bin_accuracy = []\n",
    "    bin_prop = []\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        #in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        in_bin = (confidences > bin_lower.item()) * (confidences <= bin_upper.item())\n",
    "        #bin_prop.append(in_bin.float().mean())\n",
    "        bin_prop.append(in_bin.astype(np.float32).mean())\n",
    "        if bin_prop[-1].item() > 0:\n",
    "            #bin_accuracy.append(accuracies[in_bin].float().mean())\n",
    "            bin_accuracy.append(accuracies[in_bin].astype(np.float32).mean())\n",
    "            bin_confidence.append(confidences[in_bin].mean())\n",
    "    return bin_confidence, bin_accuracy, bin_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DeepSparseCoding analyzer & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "  def __init__(self):\n",
    "    self.device = \"/gpu:0\"\n",
    "    self.analysis_dataset = \"test\"\n",
    "    self.save_info = \"analysis_\" + self.analysis_dataset\n",
    "    self.overwrite_analysis_log = False\n",
    "    self.do_class_adversaries = True\n",
    "    self.do_run_analysis = False\n",
    "    self.do_evals = False\n",
    "    self.do_basis_analysis = False\n",
    "    self.do_inference = False\n",
    "    self.do_atas = False \n",
    "    self.do_recon_adversaries = False\n",
    "    self.do_neuron_visualization = False\n",
    "    self.do_full_recon = False\n",
    "    self.do_orientation_analysis = False \n",
    "    self.do_group_recons = False\n",
    "    \n",
    "    # Adversarial params\n",
    "    self.temperature = [0.5, 0.68]\n",
    "    self.adversarial_attack_method = \"kurakin_targeted\"\n",
    "    self.adversarial_step_size = 0.005 # learning rate for optimizer\n",
    "    self.adversarial_num_steps = 500 # Number of iterations adversarial attacks\n",
    "    self.confidence_threshold = 0.9\n",
    "    self.adversarial_max_change = None # maximum size of adversarial perturation (epsilon)\n",
    "    self.carlini_change_variable = False # whether to use the change of variable trick from carlini et al\n",
    "    self.adv_optimizer = \"sgd\" # attack optimizer\n",
    "    self.adversarial_target_method = \"random\" # Not used if attack_method is untargeted#TODO support specified\n",
    "    self.adversarial_clip = True # whether or not to clip the final perturbed image\n",
    "    self.adversarial_clip_range = [0.0, 1.0] # Maximum range of image values\n",
    "    self.adversarial_save_int = 1 # Interval at which to save adv examples to the npz file\n",
    "    self.eval_batch_size = 50 # batch size for computing adv examples\n",
    "    self.adversarial_input_id = None # Which adv images to use; None to use all\n",
    "    self.adversarial_target_labels = None # Parameter for \"specified\" target_method. Only for class attacks. Needs to be a list or numpy array of size [adv_batch_size]\n",
    "    \n",
    "    # Data params\n",
    "    self.data_dir = os.path.join(ROOT_DIR, 'Datasets')\n",
    "    self.data_type = 'mnist'\n",
    "    self.vectorize_data = True\n",
    "    self.rescale_data = True\n",
    "    self.batch_size = 100\n",
    "    self.rand_seed = rand_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names = ['mlp_cosyne_mnist', 'slp_lca_768_latent_75_steps_mnist']\n",
    "#model_names = ['mlp_768_mnist', 'slp_lca_768_latent_mnist']\n",
    "model_names = ['mlp_1568_mnist', 'slp_lca_1568_latent_mnist']\n",
    "model_types = ['MLP', 'LCA']\n",
    "\n",
    "analysis_params = params()\n",
    "analysis_params.projects_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "analyzers = []\n",
    "for model_type, model_name in zip(model_types, model_names):\n",
    "    analysis_params.model_name = model_name\n",
    "    analysis_params.version = '0.0'\n",
    "    analysis_params.model_dir = analysis_params.projects_dir+analysis_params.model_name\n",
    "    model_log_file = (analysis_params.model_dir+\"/logfiles/\"+analysis_params.model_name\n",
    "      +\"_v\"+analysis_params.version+\".log\")\n",
    "    model_logger = Logger(model_log_file, overwrite=False)\n",
    "    model_log_text = model_logger.load_file()\n",
    "    model_params = model_logger.read_params(model_log_text)[-1]\n",
    "    analysis_params.model_type = model_params.model_type\n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analysis_params.save_info = 'analysis_test_' + analysis_params.analysis_dataset\n",
    "    analysis_params.save_info += (\n",
    "        '_linf_'+str(analysis_params.adversarial_max_change)\n",
    "        +'_ss_'+str(analysis_params.adversarial_step_size)\n",
    "        +'_ns_'+str(analysis_params.adversarial_num_steps)\n",
    "        +'_ct_'+str(analysis_params.confidence_threshold)\n",
    "        +'_confidence_attack'\n",
    "    )\n",
    "    analyzer.setup(analysis_params)\n",
    "    analyzer.model_type = model_type\n",
    "    analyzer.confidence_threshold = analysis_params.confidence_threshold\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_data = ds.get_data(analysis_params)\n",
    "dsc_data = analyzers[0].model.preprocess_dataset(dsc_data, analysis_params)\n",
    "dsc_data = analyzers[0].model.reshape_dataset(dsc_data, analysis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer_idx, analyzer in enumerate(analyzers):\n",
    "    analyzer.model_params.data_shape = list(dsc_data['test'].shape[1:])\n",
    "    analyzer.model_params.temperature = analysis_params.temperature[analyzer_idx]\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "dsc_image_batch, dsc_label_batch, _ = dsc_data['test'].next_batch(analysis_params.batch_size, shuffle_data=False)\n",
    "dsc_data['test'].reset_counters()\n",
    "\n",
    "dsc_all_images = dsc_data['test'].images\n",
    "dsc_all_images = dsc_all_images.reshape((dsc_all_images.shape[0], 784))\n",
    "dsc_all_labels = dsc_data['test'].labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DeepSparseCoding confidence and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    analyzer.logits = np.squeeze(analyzer.compute_activations(dsc_all_images, batch_size=50, activation_operation=analyzer.model.get_logits_with_temp))\n",
    "    analyzer.softmaxes = np.squeeze(analyzer.compute_activations(dsc_all_images, batch_size=50, activation_operation=analyzer.model.get_label_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_bins = 75\n",
    "bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "\n",
    "fig, axs = plot.subplots(ncols=2)\n",
    "for ax, model, codebase in zip(axs, analyzers, ['DSC', 'DSC']):\n",
    "    confidence, accuracy, props = bin_conf_acc_prop(\n",
    "        model.softmaxes,\n",
    "        dsc_all_labels,\n",
    "        bin_boundaries\n",
    "    )\n",
    "    ece = 0\n",
    "    for avg_confidence_in_bin, accuracy_in_bin, prop_in_bin in zip(confidence, accuracy, props):\n",
    "        ece += np.abs(avg_confidence_in_bin.item() - accuracy_in_bin.item()) * prop_in_bin.item()\n",
    "    ece *= 100\n",
    "    ax.scatter(confidence, accuracy, s=[prop*500 for prop in props if prop > 0], color='k')\n",
    "    ax.plot([0,1], [0,1], 'k--', linewidth=0.1)\n",
    "    ax.format(title=f'{codebase}_{model.model_type}\\nECE = {ece.round(4)}%\\nTemperature={model.model_params.temperature}')\n",
    "axs.format(\n",
    "    suptitle='Reliability of classifier confidence on test set',\n",
    "    xlabel='Confidence',\n",
    "    ylabel='Accuracy',\n",
    "    xlim=[0, 1],\n",
    "    ylim=[0, 1]\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_logit_forward = [analyzer.logits for analyzer in analyzers]\n",
    "dsc_logit_forward = np.stack(dsc_logit_forward, axis=0)\n",
    "dsc_softmax_forward = [analyzer.softmaxes for analyzer in analyzers]\n",
    "dsc_softmax_forward = np.stack(dsc_softmax_forward, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = np.random.randint(analysis_params.batch_size)\n",
    "fig, axs = plot.subplots(\n",
    "    [[1, 2], [1, 3]],\n",
    "    ref=1, axwidth=1.8, span=False\n",
    ")\n",
    "im = axs[0].imshow(dsc_all_images[img_idx, ...].reshape(28, 28), cmap='greys_r')\n",
    "axs[0].format(title=f'DSC dataset digit class {dp.one_hot_to_dense(dsc_all_labels)[img_idx]}')\n",
    "axs[0].colorbar(im)\n",
    "pf.clear_axis(axs[0])\n",
    "axs[0].set_aspect='equal'\n",
    "axs[1].bar(np.arange(10), np.squeeze(dsc_logit_forward[0, img_idx, :]))\n",
    "axs[1].format(title=f'DSC_{analyzers[0].model_type}')\n",
    "axs[2].bar(np.arange(10), np.squeeze(dsc_logit_forward[1, img_idx, :]))\n",
    "axs[2].format(title=f'DSC_{analyzers[1].model_type}')\n",
    "axs.format(\n",
    "    suptitle='Logit outputs for a single image',\n",
    "    xtickminor=False,\n",
    "    xticks=1,\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(ncols=2, nrows=1)\n",
    "axs[0].bar(np.squeeze(dsc_softmax_forward[0, img_idx, :]))\n",
    "axs[0].format(title=f'DSC_{analyzers[0].model_type}')\n",
    "axs[1].bar(np.squeeze(dsc_softmax_forward[1, img_idx, :]))\n",
    "axs[1].format(title=f'DSC_{analyzers[1].model_type}')\n",
    "axs.format(suptitle='Softmax confidence for a single image', xtickminor=False, xticks=1, ylim=[0, 1])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['DSC_MLP', 'DSC_LCA']\n",
    "data = pd.DataFrame(\n",
    "    dsc_softmax_forward.reshape(2, -1).T,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "fig, ax = plot.subplots(ncols=1, axwidth=2.5, share=0)\n",
    "ax.format(\n",
    "    grid=False,\n",
    "    suptitle='Softmax confidence for the test set' \n",
    ")\n",
    "obj1 = ax.boxplot(\n",
    "    data, linewidth=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax.format(yscale='log', yformatter='sci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "fig, axs = plot.subplots(ncols=2, nrows=1)\n",
    "for ax, model, atk_type in zip(axs, analyzers, ['DSC', 'DSC']):\n",
    "    max_confidence = np.max(model.softmaxes, axis=1) # max is across categories, per image\n",
    "    conf_lim = [0, 1]\n",
    "    bins = np.linspace(conf_lim[0], conf_lim[1], num_bins)\n",
    "    count, bin_edges = np.histogram(max_confidence, bins)\n",
    "    bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "    bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "    ax.bar(bin_centers, count, color='k')\n",
    "    mean_confidence = np.mean(max_confidence)\n",
    "    mean_idx = np.abs(bin_edges - mean_confidence).argmin()\n",
    "    mean_conf_bin = bin_edges[mean_idx].round(4)\n",
    "    ax.axvline(mean_conf_bin, lw=1, ls='--', color='r')\n",
    "    ax.format(\n",
    "        title=f'{atk_type}_{model.model_type}\\nMean confidence = {mean_confidence:.3f}',\n",
    "        yscale='log',\n",
    "        xlim=conf_lim\n",
    "    )\n",
    "axs.format(\n",
    "    suptitle='Softmax confidence on the clean test set correct label',\n",
    "    ylabel='Count',\n",
    "    xlabel='Confidence'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DeepSparseCoding adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_indices(softmax_conf, all_kept_indices, confidence_threshold, num_images, labels):\n",
    "    softmax_conf[np.arange(num_images, dtype=np.int32), labels] = 0 # zero confidence at true label\n",
    "    confidence_indices = np.max(softmax_conf, axis=-1) # highest non-true label confidence\n",
    "    adversarial_labels = np.argmax(softmax_conf, axis=-1) # index of highest non-true label\n",
    "    all_above_thresh = np.nonzero(np.squeeze(confidence_indices>confidence_threshold))[0]\n",
    "    keep_indices = np.array([], dtype=np.int32)\n",
    "    for adv_index in all_above_thresh:\n",
    "        if adv_index not in set(all_kept_indices):\n",
    "            keep_indices = np.append(keep_indices, adv_index)\n",
    "    return keep_indices, confidence_indices, adversarial_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: get this working on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if run_full_test_set:\n",
    "#    data = dsc_all_images\n",
    "#    labels = dsc_all_labels\n",
    "#else:\n",
    "data = dsc_image_batch\n",
    "labels = dsc_label_batch\n",
    "\n",
    "for analyzer in analyzers:\n",
    "    analyzer.class_adversary_analysis(\n",
    "        data,\n",
    "        labels,\n",
    "        batch_size=analyzer.analysis_params.eval_batch_size,\n",
    "        input_id=analyzer.analysis_params.adversarial_input_id,\n",
    "        target_method = analyzer.analysis_params.adversarial_target_method,\n",
    "        target_labels = analyzer.analysis_params.adversarial_target_labels,\n",
    "        save_info=analyzer.analysis_params.save_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DeepSparseCoding & Foolbox adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzers:\n",
    "    analyzer.accuracy = analyzer.adversarial_clean_accuracy.item()\n",
    "    print(f'DSC {analyzer.model_type} clean accuracy = {analyzer.accuracy} and adv accuracy = {analyzer.adversarial_adv_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars(p):\n",
    "    if p < 0.0001:\n",
    "        return '****'\n",
    "    elif (p < 0.001):\n",
    "        return '***'\n",
    "    elif (p < 0.01):\n",
    "        return '**'\n",
    "    elif (p < 0.05):\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'n.s.'\n",
    "    \n",
    "names = ['MLP 2L;768N','LCA 2L;768N']\n",
    "\n",
    "dsc_all_success_indices = np.intersect1d(*[analyzer.success_indices for analyzer in analyzers])\n",
    "dsc_adv_results_list = [analyzer.mean_squared_distances[0][dsc_all_success_indices] for analyzer in analyzers]\n",
    "dsc_all_results = np.stack(dsc_adv_results_list, axis=-1).squeeze()\n",
    "dsc_dataframe = pd.DataFrame(\n",
    "    dsc_all_results,\n",
    "    columns=pd.Index(names, name='Model')\n",
    ")\n",
    "\n",
    "dsc_p_value = linear_correlation(dsc_all_results[:,0], dsc_all_results[:,1])[1]\n",
    "\n",
    "fig, axs = plot.subplots(ncols=1, axwidth=2.5, share=0)\n",
    "axs.format(grid=False, suptitle='L infinity Attack Mean Squared Distances')\n",
    "\n",
    "ax = axs[0]\n",
    "obj2 = ax.boxplot(\n",
    "    dsc_dataframe, linewidth=0.7, marker='.', fillcolor='gray5',\n",
    "    medianlw=1, mediancolor='k', meancolor='k', meanlw=1\n",
    ")\n",
    "ax_y_max = max(ax.get_ylim())\n",
    "ax.text(0.5, ax_y_max-0.1*(ax_y_max), stars(dsc_p_value),\n",
    "       horizontalalignment='center',\n",
    "       verticalalignment='center',\n",
    "       fontsize=14)\n",
    "ax.format(title='Deep Sparse Coding')#, ylim=[0, 0.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attack images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=3, ncols=len(analyzers))\n",
    "pf.clear_axes(axs)\n",
    "top_level = zip(analyzers, dsc_adv_results_list, ['DSC', 'DSC'])\n",
    "for model_idx, (model, adv_results_list, atk_type) in enumerate(top_level):\n",
    "    if atk_type == 'DSC':\n",
    "        adv_imgs = model.conf_adversarial_images[0]\n",
    "        adv_labels = model.conf_adversarial_labels[0]\n",
    "    else:\n",
    "        adv_imgs = model.conf_adversarial_images\n",
    "        adv_labels = model.conf_adversarial_labels\n",
    "    adv_results = adv_results_list#[0]\n",
    "    adv_min_idx = np.abs(adv_results - adv_results.min()).argmin()\n",
    "    adv_mean_idx = np.abs(adv_results - adv_results.mean()).argmin()\n",
    "    adv_max_idx = np.abs(adv_results - adv_results.max()).argmin()\n",
    "    for row_idx, image_idx in enumerate([adv_min_idx, adv_mean_idx, adv_max_idx]):\n",
    "        img = adv_imgs[image_idx, ...].reshape(28, 28).astype(np.float32)\n",
    "        h = axs[row_idx, model_idx].imshow(img, cmap='grays')\n",
    "        axs[row_idx, model_idx].colorbar(h, loc='r', ticks=1)\n",
    "        axs[row_idx, model_idx].format(title=f'{atk_type}_{model.model_type} adversarial label = {adv_labels[row_idx]}')\n",
    "    axs[row_idx, 0].format(llabels=['Min MSD', 'Mean MSD', 'Max MSD'])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
