{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if parent_path not in sys.path: sys.path.append(parent_path) \n",
    "\n",
    "import numpy as np\n",
    "import proplot as plot\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepSparseCoding.utils.file_utils import Logger\n",
    "import DeepSparseCoding.models.model_loader as ml\n",
    "import DeepSparseCoding.utils.run_utils as run_utils\n",
    "import DeepSparseCoding.utils.dataset_utils as dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = os.path.expanduser(\"~\")+\"/Work/\"\n",
    "#params_file = workspace_dir+\"/Projects/mlp_mnist/logfiles/mlp_mnist_v0.log\"\n",
    "params_file = workspace_dir+\"/Torch_projects/lca_mlp_mnist/logfiles/lca_mlp_mnist_v0.log\"\n",
    "logger = Logger(params_file, overwrite=False)\n",
    "\n",
    "log_text = logger.load_file()\n",
    "params = logger.read_params(log_text)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_split = [key.split('_') for key in params.__dict__.keys()][0]\n",
    "\"_\".join(key_split[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_params = types.SimpleNamespace()\n",
    "read_params.ensemble_params = []\n",
    "\n",
    "ensemble_nums = set()\n",
    "for key, value in params.__dict__.items():\n",
    "    key_split = key.split(\"_\")\n",
    "    ens_num = key_split[0] \n",
    "    if ens_num.isdigit(): # ensemble params are prefaced with the ensemble index\n",
    "        ens_num = int(ens_num)\n",
    "        if ens_num not in ensemble_nums:\n",
    "            ensemble_nums.add(ens_num)\n",
    "            read_params.ensemble_params.append(types.SimpleNamespace())\n",
    "        setattr(read_params.ensemble_params[ens_num], \"_\".join(key_split[1:]), value)\n",
    "    else: # if it is not a digit then it is a general param\n",
    "        setattr(read_params, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, params = dataset_utils.load_dataset(read_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ml.load_model(read_params.model_type)\n",
    "model.setup(read_params, logger)\n",
    "model.to(read_params.device)\n",
    "model.load_state_dict(torch.load(model.params.cp_save_dir+\"trained_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(model.params.device), target.to(model.params.device)\n",
    "        batch_test_loss, batch_correct = run_utils.test_single_model(model, data, target, 0)\n",
    "        test_loss += batch_test_loss\n",
    "        correct += batch_correct\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import re\n",
    "\n",
    "def plot_stats(data, keys=None, labels=None, start_index=0, figsize=None, save_filename=None):\n",
    "    \"\"\"\n",
    "    Generate time-series plots of stats specified by keys\n",
    "    Inputs:\n",
    "        data: [dict] containing data to be plotted. len of all values should be equal\n",
    "            data must have the key \"batch_step\"\n",
    "        keys: [list of str] optional list of keys to plot, each should exist in data.keys()\n",
    "            If nothing is given, data.keys() will be used\n",
    "        labels: [list of str] optional list of labels, should be the same length as keys input\n",
    "            If nothing is given, data.keys() will be used\n",
    "        save_filename: [str] containing the complete output filename.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(data.keys())\n",
    "    else:\n",
    "        assert all([key in data.keys() for key in keys]), (\n",
    "            \"All input keys must exist as keys in the data dictionary\")\n",
    "    assert len(keys) > 0, \"Keys must be None or have length > 0.\"\n",
    "    if \"batch_step\" in keys:\n",
    "        keys.remove(\"batch_step\")\n",
    "    if \"schedule_index\" in keys:\n",
    "        keys.remove(\"schedule_index\")\n",
    "    if \"global_batch_index\" in keys:\n",
    "        keys.remove(\"global_batch_index\")\n",
    "    if labels is None:\n",
    "        labels = keys\n",
    "    else:\n",
    "        assert len(labels) == len(keys), (\n",
    "            \"The number of labels must match the number of keys\")\n",
    "    num_keys = len(keys)\n",
    "    gs = gridspec.GridSpec(num_keys, 1, hspace=0.5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axis_image = [None]*num_keys\n",
    "    for key_idx, key in enumerate(keys):\n",
    "        x_dat = data[\"batch_step\"][start_index:]\n",
    "        y_dat = data[key][start_index:]\n",
    "        ax = fig.add_subplot(gs[key_idx])\n",
    "        axis_image[key_idx] = ax.plot(x_dat, y_dat)\n",
    "        if key_idx < len(keys)-1:\n",
    "            ax.get_xaxis().set_ticklabels([])\n",
    "        ax.locator_params(axis=\"y\", nbins=5)\n",
    "        ax.set_ylabel(\"\\n\".join(re.split(\"_\", labels[key_idx])))\n",
    "        ax.set_yticks([np.minimum(0.0, np.min(y_dat)), np.maximum(0.0, np.max(y_dat))])\n",
    "        ylabel_xpos = -0.05\n",
    "        ax.yaxis.set_label_coords(ylabel_xpos, 0.5)\n",
    "    ax.set_xlabel(\"Batch Number\")\n",
    "    fig.suptitle(\"Stats per Batch\", y=0.95, x=0.5)\n",
    "    if save_filename is not None:\n",
    "        fig.savefig(save_filename, transparent=True)\n",
    "        plt.close(fig)\n",
    "        return None\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_stats = logger.read_stats(log_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[\"loss\", \"train_accuracy\"]\n",
    "labels=[\"Loss\", \"Train Accuracy\"]\n",
    "stats_fig = plot_stats(run_stats, keys=keys, labels=labels, start_index=0, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1, subplot=[1, 1]):\n",
    "    \"\"\" Set aesthetic figure dimensions to avoid scaling in latex.\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Width in pts\n",
    "    fraction: float\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "\n",
    "    Usage: figsize = set_size(text_width, fraction=1, subplot=[1, 1])\n",
    "    Code obtained from: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "    \"\"\"\n",
    "    fig_width_pt = width * fraction # Width of figure\n",
    "    inches_per_pt = 1 / 72.27 # Convert from pt to inches\n",
    "    golden_ratio = (5**.5 - 1) / 2 # Golden ratio to set aesthetic figure height\n",
    "    fig_width_in = fig_width_pt * inches_per_pt # Figure width in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplot[0] / subplot[1]) # Figure height in inches\n",
    "    fig_dim = (fig_width_in, fig_height_in) # Final figure dimensions\n",
    "    return fig_dim\n",
    "\n",
    "def plot_weights(weights, title=\"\", figsize=None):\n",
    "    num_weights, num_input_y, num_input_x = weights.shape\n",
    "    num_plots_y = int(np.ceil(np.sqrt(num_weights))+1)\n",
    "    num_plots_x = int(np.floor(np.sqrt(num_weights)))\n",
    "    fig, axs = plot.subplots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
