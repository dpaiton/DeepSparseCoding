{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os                                                                       \n",
    "import numpy as np                                                              \n",
    "import tensorflow as tf                                                         \n",
    "import data.data_selector as ds                                                   \n",
    "import utils.plot_functions as pf                                               \n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_params = {\n",
    "  \"model_type\": \"conv_lca\",\n",
    "  \"model_name\": \"conv_lca_vh\",#\"lca_vh_ft_white\",\n",
    "  \"data_type\": \"vanHateren\",\n",
    "  \"device\": \"/gpu:0\",\n",
    "  \"version\": \"5.0\",\n",
    "  \"num_inference_images\": 5, #How many random images to average over for inference statistics\n",
    "  \"clobber\": True}\n",
    "\n",
    "# Computed params\n",
    "analysis_params[\"model_dir\"] = (os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "  +analysis_params[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzer = ap.get_analyzer(analysis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer.model_params[\"data_type\"] = analysis_params[\"data_type\"]\n",
    "data = ds.get_data(analyzer.model_params)\n",
    "analyzer.model_params[\"input_shape\"] = [\n",
    "  data[\"train\"].num_rows*data[\"train\"].num_cols*data[\"train\"].num_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis params:\n",
      "\n",
      "gen_plot_int        \t1000\n",
      "data_dir            \t/home/dpaiton/Work/Datasets//vanHateren/\n",
      "center_data         \tTrue\n",
      "version             \t5.0\n",
      "input_shape         \t[65536]\n",
      "norm_data           \tFalse\n",
      "norm_weights        \tTrue\n",
      "batch_size          \t1\n",
      "device              \t/gpu:0\n",
      "thresh_type         \tsoft\n",
      "cp_load             \tFalse\n",
      "model_name          \tconv_lca_vh\n",
      "rectify_a           \tTrue\n",
      "patch_size_x        \t16\n",
      "extract_patches     \tFalse\n",
      "max_cp_to_keep      \t1\n",
      "num_images          \t300\n",
      "stride_y            \t8\n",
      "out_dir             \t/home/dpaiton/Work/Projects/\n",
      "model_type          \tconv_lca\n",
      "optimizer           \tannealed_sgd\n",
      "num_pixels          \t65536\n",
      "stride_x            \t8\n",
      "vectorize_data      \tFalse\n",
      "save_plots          \tTrue\n",
      "log_int             \t10\n",
      "log_to_file         \tTrue\n",
      "cp_int              \t10000\n",
      "num_steps           \t120\n",
      "image_edge_size     \t256\n",
      "contrast_normalize  \tFalse\n",
      "whiten_data         \tTrue\n",
      "rand_seed           \t1234567890\n",
      "eps                 \t1e-12\n",
      "patch_size_y        \t16\n",
      "dt                  \t0.001\n",
      "tau                 \t0.03\n",
      "num_neurons         \t512\n",
      "data_type           \tvanHateren\n",
      "model_out_dir       \t/home/dpaiton/Work/Projects/conv_lca_vh/analysis/5.0/\n"
     ]
    }
   ],
   "source": [
    "#params = {'data_type': 'vanHateren', 'vectorize_data': False, 'norm_data': False, 'batch_size': 3, 'center_data': False, 'data_dir': '/home/dpaiton/Work/Datasets/vanHateren/'}\n",
    "print(\"Analysis params:\\n\")\n",
    "print(\"\\n\".join([key.ljust(20)+\"\\t\"+str(analyzer.model_params[key]) for key in analyzer.model_params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (300, 256, 256) for Tensor 'placeholders/input_data:0', which has shape '(?, 256, 256, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc0a0724a9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0manalysis_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clobber\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full_imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full_imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DeepSparseCoding/analysis/conv_lca_analyzer.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m(self, images, save_info)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0;31m#  self.atas = self.compute_atas(self.evals[\"inference/activity:0\"], images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m#  image_indices = np.random.choice(np.arange(images.shape[0]), self.num_inference_images,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/DeepSparseCoding/analysis/base_analysis.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(self, images, var_names)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcp_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (300, 256, 256) for Tensor 'placeholders/input_data:0', which has shape '(?, 256, 256, 1)'"
     ]
    }
   ],
   "source": [
    "if analysis_params[\"clobber\"]:\n",
    "  analyzer.run_analysis(data[\"train\"].images, save_info=\"full_imgs\")\n",
    "else:\n",
    "  analyzer.load_analysis(save_info=\"full_imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_fig = pf.plot_stats(analyzer.run_stats,\n",
    "  keys=[\"a_fraction_active\", \"recon_loss\", \"sparse_loss\", \"total_loss\"],\n",
    "  labels=[\"activity\", \"recon loss\", \"sparse loss\", \"total loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_pixels, num_neurons = analyzer.atas.shape\n",
    "atas_fig = pf.plot_data_tiled(analyzer.atas.T.reshape(num_neurons,\n",
    "  int(np.sqrt(num_pixels)), int(np.sqrt(num_pixels))), normalize=False,\n",
    "  title=\"Activity triggered averages on image data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_images = np.random.standard_normal(data[\"train\"].images.shape) \n",
    "noise_evals = analyzer.evaluate_model(noise_images, analyzer.var_names)\n",
    "noise_atas = analyzer.compute_atas(noise_evals[\"inference/activity:0\"],\n",
    "  noise_images)\n",
    "noise_atas_fig = pf.plot_data_tiled(noise_atas.T.reshape(num_neurons,\n",
    "  int(np.sqrt(num_pixels)), int(np.sqrt(num_pixels))), normalize=False,\n",
    "  title=\"Activity triggered averages on standard normal noise data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_fig = pf.plot_data_tiled(analyzer.evals[\"weights/phi:0\"].T.reshape(analyzer.model.num_neurons,\n",
    "  data[\"train\"].num_cols, data[\"train\"].num_rows), normalize=False, title=\"Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inference_fig = pf.plot_inference_traces(analyzer.inference_stats, analyzer.model_schedule[0][\"sparse_mult\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = pf.plot_inference_stats(analyzer.inference_stats, title=\"Loss During Inference\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
