{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Computation Paper Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from functools import reduce as reduce\n",
    "from skimage import measure\n",
    "from skimage.io import imread\n",
    "from skimage.util import crop\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from utils.logger import Logger\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import analysis.analysis_picker as ap\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import utils.neural_comp_funcs as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (16, 16)\n",
    "fontsize = 20\n",
    "dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lca_512_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_512_vh\"\n",
    "    self.display_name = \"Sparse Coding 512\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_vh\"\n",
    "    self.display_name = \"Sparse Coding 768\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_1024_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_1024_vh\"\n",
    "    self.display_name = \"Sparse Coding 1024\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_2560_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_2560_vh\"\n",
    "    self.display_name = \"Sparse Coding\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_vh\"\n",
    "    self.display_name = \"Sparse Autoencoder\"\n",
    "    self.version = \"1.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class rica_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"rica\"\n",
    "    self.model_name = \"rica_768_vh\"\n",
    "    self.display_name = \"Linear Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_vh\"\n",
    "    self.display_name = \"ReLU\"\n",
    "    self.version = \"1.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_mnist\"\n",
    "    self.display_name = \"Sparse Coding 768\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_1536_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_1536_mnist\"\n",
    "    self.display_name = \"Sparse Coding 1536\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.display_name = \"Leaky ReLU\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_mnist\"\n",
    "    self.display_name = \"Sparse Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class rica_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"rica\"\n",
    "    self.model_name = \"rica_768_mnist\"\n",
    "    self.display_name = \"Linear Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_deep_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_deep_mnist\"\n",
    "    self.display_name = \"Leaky ReLU\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_levels = 10\n",
    "color_vals = dict(zip([\"blk\", \"lt_green\", \"md_green\", \"dk_green\", \"lt_blue\", \"md_blue\", \"dk_blue\", \"lt_red\", \"md_red\", \"dk_red\"],\n",
    "  [\"#000000\", \"#A9DFBF\", \"#196F3D\", \"#27AE60\", \"#AED6F1\", \"#3498DB\", \"#21618C\", \"#F5B7B1\", \"#E74C3C\", \"#943126\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iso-contour activations comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [rica_768_vh_params(), ae_768_vh_params(), sae_768_vh_params(), lca_2560_vh_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"\"\n",
    "for analyzer in analyzer_list:\n",
    "  run_params = np.load(analyzer.analysis_out_dir+\"savefiles/iso_params_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  min_angle = run_params[\"min_angle\"]\n",
    "  max_angle = run_params[\"max_angle\"]\n",
    "  num_neurons = run_params[\"num_neurons\"]\n",
    "  use_bf_stats = run_params[\"use_bf_stats\"]\n",
    "  num_comparison_vectors = run_params[\"num_comparison_vects\"]\n",
    "  x_range = run_params[\"x_range\"]\n",
    "  y_range = run_params[\"y_range\"]\n",
    "  num_images = run_params[\"num_images\"]\n",
    "\n",
    "  iso_vectors = np.load(analyzer.analysis_out_dir+\"savefiles/iso_vectors_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.target_neuron_ids = iso_vectors[\"target_neuron_ids\"]\n",
    "  analyzer.comparison_neuron_ids = iso_vectors[\"comparison_neuron_ids\"]\n",
    "  analyzer.target_vectors = iso_vectors[\"target_vectors\"]\n",
    "  analyzer.rand_orth_vectors = iso_vectors[\"rand_orth_vectors\"]\n",
    "  analyzer.comparison_vectors = iso_vectors[\"comparison_vectors\"]\n",
    "\n",
    "  analyzer.comp_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.rand_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_activations_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.rand_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_contour_dataset_\"+save_name\n",
    "    +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neuron_indices = [0, 0, 0, 0]\n",
    "orth_indices = [0, 0, 0, 1]\n",
    "num_plots_y = 2\n",
    "num_plots_x = 2\n",
    "show_contours = True\n",
    "\n",
    "fig, contour_handles = nc.plot_goup_iso_contours(analyzer_list, neuron_indices, orth_indices,\n",
    "  num_levels, x_range, y_range, show_contours, figsize, dpi, fontsize)\n",
    "for analyzer, neuron_index, orth_index in zip(analyzer_list, neuron_indices, orth_indices):\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    neuron_str = str(analyzer.target_neuron_ids[neuron_index])\n",
    "    orth_str = str(analyzer.comparison_neuron_ids[neuron_index][orth_index])\n",
    "    save_name = analyzer.analysis_out_dir+\"/vis/iso_contour_comparison_\"\n",
    "    if not show_contours:\n",
    "      save_name += \"continuous_\"\n",
    "    save_name += \"bf0id\"+neuron_str+\"_bf1id\"+orth_str+\"_\"+analyzer.analysis_params.save_info+ext\n",
    "    fig.savefig(save_name, dpi=dpi, transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "line_alpha = 0.08\n",
    "for analyzer in analyzer_list:\n",
    "  target_neuron_index = 0\n",
    "  fig = nc.plot_bf_curvature(analyzer, target_neuron_index, line_alpha=line_alpha,\n",
    "    figsize=(figsize[0], 2*figsize[1]), dpi=dpi, fontsize=fontsize)\n",
    "  neuron_str = str(analyzer.target_neuron_ids[target_neuron_index])\n",
    "  save_name = (analyzer.analysis_out_dir+\"/vis/bf_curvatures_bfid0\"+neuron_str\n",
    "    +\"_\"+analyzer.analysis_params.save_info+\".png\")\n",
    "  fig.savefig(save_name, transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for analyzer in analyzer_list:\n",
    "  target_neuron_index = 0\n",
    "  fig = nc.plot_fit_curvature(analyzer, target_neuron_index=0, line_alpha=line_alpha,\n",
    "    figsize=(figsize[0], 2*figsize[1]), dpi=dpi, fontsize=fontsize)\n",
    "  neuron_str = str(analyzer.target_neuron_ids[target_neuron_index])\n",
    "  save_name = (analyzer.analysis_out_dir+\"/vis/bf_fit_curvatures_bfid0\"+neuron_str\n",
    "    +\"_\"+analyzer.analysis_params.save_info+\".png\")\n",
    "  fig.savefig(save_name, transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvature histogram"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [lca_512_vh_params(), lca_768_vh_params(), lca_2560_vh_params()]\n",
    "iso_save_name = \"iso_curvature_xrange1.3_yrange-2.2_\"\n",
    "attn_save_name = \"1d_\"\n",
    "\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name\n",
    "\n",
    "  iso_run_params = np.load(analyzer.analysis_out_dir+\"savefiles/iso_params_\"+iso_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.iso_comp_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+iso_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.iso_comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+iso_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.iso_rand_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_activations_\"+iso_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.iso_rand_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_contour_dataset_\"+iso_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "\n",
    "  analyzer.iso_num_target_neurons = iso_run_params[\"num_neurons\"]\n",
    "  analyzer.iso_num_comparison_vectors = iso_run_params[\"num_comparison_vects\"]\n",
    "  \n",
    "  attn_run_params = np.load(analyzer.analysis_out_dir+\"savefiles/iso_params_\"+attn_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.attn_comp_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+attn_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.attn_comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+attn_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  analyzer.attn_rand_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_activations_\"+attn_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"]\n",
    "  analyzer.attn_rand_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_contour_dataset_\"+attn_save_name+analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "  \n",
    "  analyzer.attn_num_target_neurons = attn_run_params[\"num_neurons\"]\n",
    "  analyzer.attn_num_comparison_vectors = attn_run_params[\"num_comparison_vects\"]\n",
    "  \n",
    "mesh_save_name = \"iso_curvature_ryan_\"\n",
    "contour_activity = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+mesh_save_name\n",
    "  +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"][0, 1, ...]\n",
    "comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+mesh_save_name\n",
    "  +analyzer.analysis_params.save_info+\".npz\", allow_pickle=True)[\"data\"].item()\n",
    "x = range(comp_contour_dataset[\"x_pts\"].size)\n",
    "y = range(comp_contour_dataset[\"y_pts\"].size)\n",
    "contour_pts = (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_act = 0.3 # target activity spot between min & max value of normalized activity (btwn 0 and 1)\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.iso_comp_curvatures = []\n",
    "  analyzer.iso_rand_curvatures = []\n",
    "  activations_and_curvatures = ((analyzer.iso_comp_activations, analyzer.iso_comp_curvatures),\n",
    "    (analyzer.iso_rand_activations, analyzer.iso_rand_curvatures))\n",
    "  for activations, curvatures in activations_and_curvatures:\n",
    "    (num_neurons, num_planes, num_points_y, num_points_x) = activations.shape\n",
    "    for neuron_id in range(num_neurons):\n",
    "      sub_curvatures = []\n",
    "      for plane_id in range(num_planes):\n",
    "        activity = activations[neuron_id, plane_id, ...]\n",
    "        ## mirror top half of activations to bottom half to only measure curvature in the upper quadrant\n",
    "        num_y, num_x = activity.shape \n",
    "        activity[:int(num_y/2), :] = activity[int(num_y/2):, :][::-1,:]\n",
    "        ## compute curvature\n",
    "        contours = measure.find_contours(activity, target_act)[0]\n",
    "        x_vals = contours[:,1]\n",
    "        y_vals = contours[:,0]\n",
    "        coeffs = np.polynomial.polynomial.polyfit(y_vals, x_vals, deg=2)\n",
    "        sub_curvatures.append(coeffs[-1])\n",
    "      curvatures.append(sub_curvatures)\n",
    "\n",
    "  comp_x_pts = analyzer.attn_comp_contour_dataset[\"x_pts\"]\n",
    "  rand_x_pts = analyzer.attn_rand_contour_dataset[\"x_pts\"]\n",
    "  assert(np.all(comp_x_pts == rand_x_pts)) # This makes sure we don't need to recompute proj_datapoints for each case\n",
    "  num_x_imgs = len(comp_x_pts)\n",
    "  x_target = comp_x_pts[num_x_imgs-1] # find a location to take a slice\n",
    "  proj_datapoints = analyzer.attn_comp_contour_dataset[\"proj_datapoints\"]\n",
    "  slice_indices = np.where(proj_datapoints[:, 0] == x_target)[0]\n",
    "  analyzer.sliced_datapoints = proj_datapoints[slice_indices, :][:, :] # slice grid\n",
    "\n",
    "  analyzer.attn_comp_curvatures = []\n",
    "  analyzer.attn_comp_fits = []\n",
    "  analyzer.attn_comp_sliced_activity = []\n",
    "  analyzer.attn_rand_curvatures = []\n",
    "  analyzer.attn_rand_fits = []\n",
    "  analyzer.attn_rand_sliced_activity = []\n",
    "  for neuron_index in range(analyzer.attn_num_target_neurons):\n",
    "    sub_comp_curvatures = []\n",
    "    sub_comp_fits = []\n",
    "    sub_comp_sliced_activity = []\n",
    "    sub_comp_delta_activity = []\n",
    "    sub_rand_curvatures = []\n",
    "    sub_rand_fits = []\n",
    "    sub_rand_sliced_activity = []\n",
    "    for orth_index in range(analyzer.attn_num_comparison_vectors):\n",
    "      comp_activity = analyzer.attn_comp_activations[neuron_index, orth_index, ...].reshape([-1])\n",
    "      sub_comp_sliced_activity.append(comp_activity[slice_indices][:])\n",
    "      coeff = np.polynomial.polynomial.polyfit(analyzer.sliced_datapoints[:, 1],\n",
    "        sub_comp_sliced_activity[-1], deg=2) # [c0, c1, c2], where p = c0 + c1x + c2x^2\n",
    "      sub_comp_curvatures.append(coeff[2])\n",
    "      sub_comp_fits.append(np.polynomial.polynomial.polyval(analyzer.sliced_datapoints[:, 1], coeff))\n",
    "      \n",
    "    num_rand_vectors = np.minimum(analyzer.bf_stats[\"num_inputs\"]-1, analyzer.attn_num_comparison_vectors)\n",
    "    for orth_index in range(num_rand_vectors):\n",
    "      rand_activity = analyzer.attn_rand_activations[neuron_index, orth_index, ...].reshape([-1])\n",
    "      sub_rand_sliced_activity.append(rand_activity[slice_indices][:])\n",
    "      coeff = np.polynomial.polynomial.polyfit(analyzer.sliced_datapoints[:, 1],\n",
    "        sub_rand_sliced_activity[-1], deg=2)\n",
    "      sub_rand_curvatures.append(coeff[2])\n",
    "      sub_rand_fits.append(np.polynomial.polynomial.polyval(analyzer.sliced_datapoints[:, 1], coeff))\n",
    "\n",
    "    analyzer.attn_comp_curvatures.append(sub_comp_curvatures)\n",
    "    analyzer.attn_comp_fits.append(sub_comp_fits)\n",
    "    analyzer.attn_comp_sliced_activity.append(sub_comp_sliced_activity)\n",
    "    analyzer.attn_rand_curvatures.append(sub_rand_curvatures)\n",
    "    analyzer.attn_rand_fits.append(sub_rand_fits)\n",
    "    analyzer.attn_rand_sliced_activity.append(sub_rand_sliced_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50\n",
    "def get_bins(all_curvatures, num_bins=50):\n",
    "  max_curvature = np.amax(all_curvatures)\n",
    "  min_curvature = np.amin(all_curvatures)\n",
    "  bin_width = (max_curvature - min_curvature) / (num_bins-1) # subtract 1 to leave room for the zero bin\n",
    "  bin_centers = [0.0]\n",
    "  while min(bin_centers) > min_curvature:\n",
    "    bin_centers.append(bin_centers[-1]-bin_width)\n",
    "  bin_centers = bin_centers[::-1]\n",
    "  while max(bin_centers) < max_curvature:\n",
    "    bin_centers.append(bin_centers[-1]+bin_width)\n",
    "  bin_lefts = bin_centers - (bin_width / 2)\n",
    "  bin_rights = bin_centers + (bin_width / 2)\n",
    "  bins = np.append(bin_lefts, bin_rights[-1])\n",
    "  return bins\n",
    "\n",
    "iso_all_curvatures = []\n",
    "for analyzer in analyzer_list:\n",
    "  for neuron_index in range(num_neurons):\n",
    "    iso_all_curvatures += analyzer.iso_comp_curvatures[neuron_index]\n",
    "    iso_all_curvatures += analyzer.iso_rand_curvatures[neuron_index]\n",
    "iso_bins = get_bins(iso_all_curvatures, num_bins)\n",
    "\n",
    "attn_all_curvatures = []\n",
    "for analyzer in analyzer_list:\n",
    "  for neuron_index in range(analyzer.attn_num_target_neurons):\n",
    "    attn_all_curvatures += analyzer.attn_comp_curvatures[neuron_index]\n",
    "    attn_all_curvatures += analyzer.attn_rand_curvatures[neuron_index]\n",
    "attn_bins = get_bins(attn_all_curvatures, num_bins)\n",
    "  \n",
    "for analyzer in analyzer_list:\n",
    "  flat_comp_curvatures = [item for sub_list in analyzer.iso_comp_curvatures for item in sub_list]\n",
    "  comp_hist, analyzer.iso_bin_edges = np.histogram(flat_comp_curvatures, iso_bins, density=False)\n",
    "  analyzer.iso_comp_hist = comp_hist / np.sum(comp_hist)\n",
    "  flat_rand_curvatures = [item for sub_list in analyzer.iso_rand_curvatures for item in sub_list]\n",
    "  rand_hist, _ = np.histogram(flat_rand_curvatures, iso_bins, density=False)\n",
    "  analyzer.iso_rand_hist = rand_hist / np.sum(rand_hist)\n",
    "\n",
    "  flat_comp_curvatures = [item for sub_list in analyzer.attn_comp_curvatures for item in sub_list]\n",
    "  comp_hist, analyzer.attn_bin_edges = np.histogram(flat_comp_curvatures, attn_bins, density=False)\n",
    "  analyzer.attn_comp_hist = comp_hist / np.sum(comp_hist)\n",
    "  flat_rand_curvatures = [item for sub_list in analyzer.attn_rand_curvatures for item in sub_list]\n",
    "  rand_hist, _ = np.histogram(flat_rand_curvatures, attn_bins, density=False)\n",
    "  analyzer.attn_rand_hist = rand_hist / np.sum(rand_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_hist_list = [[analyzer.iso_comp_hist for analyzer in analyzer_list],\n",
    "  [analyzer.iso_rand_hist for analyzer in analyzer_list]]\n",
    "label_list = [[\"Comparison vectors, 2x\", \"Comparison vectors, 4x\", \"Comparison vectors, 10x\"],\n",
    "  [\"Random vectors, 2x\", \"Random vectors, 4x\", \"Random vectors, 10x\"]]\n",
    "color_list = [[color_vals[\"lt_red\"], color_vals[\"md_red\"], color_vals[\"dk_red\"]],\n",
    "  [color_vals[\"lt_blue\"], color_vals[\"md_blue\"], color_vals[\"dk_blue\"]]]\n",
    "\n",
    "plot_bin_lefts, plot_bin_rights = analyzer_list[0].iso_bin_edges[:-1], analyzer_list[0].iso_bin_edges[1:]\n",
    "iso_plot_bin_centers = plot_bin_lefts + (plot_bin_rights - plot_bin_lefts)\n",
    "\n",
    "label_loc = [0.5, 0.3]\n",
    "iso_title = \"Iso-Response\"\n",
    "iso_xlabel = \"Curvature of Iso-Response Contours\"\n",
    "\n",
    "attn_hist_list = [[analyzer.attn_comp_hist for analyzer in analyzer_list],\n",
    "  [analyzer.attn_rand_hist for analyzer in analyzer_list]]\n",
    "\n",
    "plot_bin_lefts, plot_bin_rights = analyzer_list[0].attn_bin_edges[:-1], analyzer_list[0].attn_bin_edges[1:]\n",
    "attn_plot_bin_centers = plot_bin_lefts + (plot_bin_rights - plot_bin_lefts)\n",
    "\n",
    "label_loc = [0.08, 0.30]\n",
    "attn_title = \"Response Attenuation\"\n",
    "attn_xlabel = \"Curvature of Response Attenuation\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_curvature_histograms(activity, contour_pts, contour_angle, contour_text_loc, hist_list, label_list, color_list, bin_centers, title, xlabel, figsize=None, dpi=100, fontsize=12):\n",
    "  fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "  num_y_plots = 4\n",
    "  num_x_plots = 4\n",
    "  gs0 = gridspec.GridSpec(num_y_plots, num_x_plots, wspace=0.5)\n",
    "\n",
    "  x_mesh, y_mesh = np.meshgrid(*contour_pts)\n",
    "  curve_ax = fig.add_subplot(gs0[:, 0:2], projection='3d')\n",
    "  curve_ax.set_zlim(0,1)\n",
    "  curve_ax.set_xlim3d(5,200)\n",
    "  x_ticks = curve_ax.get_xticks().tolist()\n",
    "  x_ticks = np.round(np.linspace(0.6, 4.4, 11), 1).astype(str)\n",
    "  a_x = [\" \"]*len(x_ticks)\n",
    "  a_x[1] = x_ticks[1]\n",
    "  a_x[-3] = x_ticks[-2]\n",
    "  curve_ax.set_xticklabels(a_x, size=fontsize)\n",
    "  y_ticks = curve_ax.get_yticks().tolist()\n",
    "  y_ticks = np.round(np.linspace(-10, 10, 11), 1).astype(str)\n",
    "  a_y = [\" \"]*len(y_ticks)\n",
    "  a_y[1] = y_ticks[1]\n",
    "  a_y[-2] = y_ticks[-2]\n",
    "  curve_ax.set_yticklabels(a_y, size=fontsize)\n",
    "  curve_ax.set_zticklabels([])\n",
    "  curve_ax.zaxis.set_rotate_label(False)\n",
    "  curve_ax.set_zlabel(\"Normalized Activity\", rotation=90, size=fontsize)\n",
    "  curve_ax.scatter(x_mesh, y_mesh, activity, color=\"#A9A9A9\",s=0.05)\n",
    "  loc0, loc1, loc2 = contour_text_loc[0]\n",
    "  curve_ax.text(loc0, loc1, loc2, \"Iso-\\nresponse\", color='black', size=fontsize)\n",
    "  iso_line_offset = 165\n",
    "  curve_ax.plot(np.zeros_like(x)+iso_line_offset, y, activity[:, iso_line_offset], color=\"black\", lw=5)\n",
    "  v = Arrow3D([-200/3., -200/3.], [200/2., 200/2.+200/16.], \n",
    "              [0, 0.0], mutation_scale=10, \n",
    "              lw=2, arrowstyle=\"-|>\", color=\"r\", linestyle=\"dashed\")\n",
    "  curve_ax.add_artist(v)\n",
    "  curve_ax.text(-270/3., 300/3.0, 0.0, \"v\", color='red', size=fontsize)\n",
    "  phi_k = Arrow3D([-200/3., 0.], [200/2., 200/2.], \n",
    "              [0, 0.0], mutation_scale=10, \n",
    "              lw=2, arrowstyle=\"-|>\", color=\"r\", linestyle = \"dashed\")\n",
    "  curve_ax.add_artist(phi_k)\n",
    "  curve_ax.text(-175/3., 270/3.0, 0.0, r\"${\\phi}_{k}$\", color='red', size=fontsize)\n",
    "  loc0, loc1, loc2 = contour_text_loc[1]\n",
    "  curve_ax.text(loc0, loc1, loc2, \"Response\\nAttenuation\", color='black', size=fontsize)\n",
    "  lines = np.array([0.2, 0.203, 0.197]) - 0.1\n",
    "  for i in lines:\n",
    "      curve_ax.contour3D(x_mesh, y_mesh, activity, [i], colors=\"black\")\n",
    "  curve_ax.view_init(30, contour_angle)\n",
    "  \n",
    "  sub_num_y_plots = 4#len(hist_list) #2\n",
    "  sub_num_x_plots = 1#len(hist_list[0]) #2\n",
    "  hist_gs = gridspec.GridSpecFromSubplotSpec(sub_num_y_plots, sub_num_x_plots, gs0[:, 2:], hspace=0.40, wspace=0.15)\n",
    "  all_lists = zip(hist_list, label_list, color_list, bin_centers, title, xlabel)\n",
    "  orig_ax = fig.add_subplot(hist_gs[0])\n",
    "  axes = []\n",
    "  axis_index = 0\n",
    "  for sub_plt_x in range(0, sub_num_x_plots):\n",
    "    for sub_plt_y in range(0, sub_num_y_plots):\n",
    "      if (sub_plt_x, sub_plt_y) == (0,0):\n",
    "        axes.append(orig_ax)\n",
    "      else:\n",
    "        #axes.append(fig.add_subplot(hist_gs[sub_plt_y, sub_plt_x], sharey=orig_ax))\n",
    "        axes.append(fig.add_subplot(hist_gs[axis_index], sharey=orig_ax))\n",
    "      axis_index += 1\n",
    "  axis_index = 0\n",
    "  for axis_x, (sub_hist, sub_label, sub_color, sub_bins, sub_title, sub_xlabel) in enumerate(all_lists):\n",
    "    handles = []\n",
    "    labels = []\n",
    "    max_val = 0\n",
    "    for axis_y, (axis_hists, axis_labels, axis_colors) in enumerate(zip(sub_hist, sub_label, sub_color)):\n",
    "      axes[axis_index].set_xticks(sub_bins, minor=True)\n",
    "      axes[axis_index].set_xticks(sub_bins[::int(len(sub_bins)/5)], minor=False)\n",
    "      axes[axis_index].set_xlabel(sub_xlabel, fontsize=fontsize)\n",
    "      axes[axis_index].xaxis.set_major_formatter(FormatStrFormatter(\"%0.3f\"))\n",
    "      for hist, label, color in zip(axis_hists, axis_labels, axis_colors):\n",
    "        axes[axis_index].plot(sub_bins, hist, color=color, linestyle=\"-\", drawstyle=\"steps-mid\", label=label)\n",
    "        axes[axis_index].set_yscale('log')\n",
    "        if np.max(hist) > max_val:\n",
    "          max_val = np.max(hist)\n",
    "      axes[axis_index].axvline(0.0, color='k', linestyle='dashed', linewidth=1)\n",
    "      for tick in axes[axis_index].xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(fontsize) \n",
    "      for tick in axes[axis_index].yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(fontsize) \n",
    "      axes[axis_index].set_ylabel(\"Normalized\\nCount\", fontsize=fontsize)\n",
    "      ax_handles, ax_labels = axes[axis_index].get_legend_handles_labels()\n",
    "      handles += ax_handles\n",
    "      labels += ax_labels\n",
    "      if axis_x == 0 and axis_y == 1:#sub_num_y_plots-1:\n",
    "        legend = axes[axis_index].legend(handles=handles, labels=labels, fontsize=fontsize, loc=\"upper right\",\n",
    "          borderaxespad=0.5, borderpad=0., ncol=2)\n",
    "        legend.get_frame().set_linewidth(0.0)\n",
    "        for text, color in zip(legend.get_texts(), [color for sublist in sub_color for color in sublist]):\n",
    "          text.set_color(color)\n",
    "        for item in legend.legendHandles:\n",
    "          item.set_visible(False)\n",
    "      axis_index += 1\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_angle = 210\n",
    "\n",
    "full_hist_list = [iso_hist_list, attn_hist_list]\n",
    "full_label_list = [label_list,]*2\n",
    "full_color_list = [color_list,]*2\n",
    "full_bin_centers = [iso_plot_bin_centers, attn_plot_bin_centers]\n",
    "full_title = [iso_title, attn_title]\n",
    "full_xlabel = [iso_xlabel, attn_xlabel]\n",
    "\n",
    "iso_resp_loc = [0, 180, 0.42]\n",
    "resp_att_loc = [100, 240, 0.38]\n",
    "contour_text_loc = [iso_resp_loc, resp_att_loc]\n",
    "\n",
    "curvature_fig = nc.plot_curvature_histograms(contour_activity, contour_pts, contour_angle, contour_text_loc,\n",
    "  full_hist_list, full_label_list, full_color_list, full_bin_centers, full_title, full_xlabel,\n",
    "  figsize=(2*figsize[0], figsize[1]), dpi=dpi, fontsize=fontsize)\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  for ext in [\".png\"]:#, \".eps\"]:\n",
    "    save_name = (analyzer.analysis_out_dir+\"/vis/curvatures_and_histograms\"\n",
    "      +\"_\"+analyzer.analysis_params.save_info+ext)\n",
    "    curvature_fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation Selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [rica_768_vh_params(), sae_768_vh_params(), lca_768_vh_params()]\n",
    "params_list[-1].display_name = \"Sparse Coding\"\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_var_list = []\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_indices = np.random.choice(analyzer.ot_grating_responses[\"neuron_indices\"], 12)\n",
    "  num_orientation_samples = len(analyzer.ot_grating_responses['orientations'])\n",
    "  corresponding_angles_deg = (180 * np.arange(num_orientation_samples) / num_orientation_samples) - 90\n",
    "  corresponding_angles_rad = (np.pi * np.arange(num_orientation_samples) / num_orientation_samples) - (np.pi/2)\n",
    "  analyzer.metrics_list = {\"fwhm\":[], \"circ_var\":[], \"osi\":[], \"skipped_indices\":[]}\n",
    "  contrast_idx = -1\n",
    "  for bf_idx in range(analyzer.bf_stats[\"num_outputs\"]):\n",
    "    ot_curve = nc.center_curve(analyzer.ot_grating_responses[\"mean_responses\"][bf_idx, contrast_idx, :])\n",
    "    if np.max(ot_curve) - np.min(ot_curve) == 0:\n",
    "      analyzer.metrics_list[\"skipped_indices\"].append(bf_idx)\n",
    "    else:\n",
    "      fwhm = nc.compute_fwhm(ot_curve, corresponding_angles_deg)\n",
    "      analyzer.metrics_list[\"fwhm\"].append(fwhm)\n",
    "      circ_var = nc.compute_circ_var(ot_curve, corresponding_angles_rad)\n",
    "      analyzer.metrics_list[\"circ_var\"].append(circ_var)\n",
    "      osi = nc.compute_osi(ot_curve)\n",
    "      analyzer.metrics_list[\"osi\"].append(osi)\n",
    "  circ_var_list.append(np.array([val[2] for val in analyzer.metrics_list[\"circ_var\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_list = [color_vals[\"md_green\"], color_vals[\"md_blue\"], color_vals[\"md_red\"]]\n",
    "label_list = [\"Linear Autoencoder\", \"Sparse Autoencoder\", \"Sparse Coding\"]\n",
    "num_bins = 30\n",
    "width_ratios = [0.5, 0.25, 0.25]\n",
    "height_ratios = [0.13, 0.25, 0.25, 0.25]\n",
    "density = False\n",
    "\n",
    "fig = nc.plot_circ_variance_histogram(analyzer_list, circ_var_list, color_list, label_list, num_bins,\n",
    "  density, width_ratios, height_ratios, fontsize, figsize, dpi)\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = (analyzer.analysis_out_dir+\"/vis/circular_variance_combo\"\n",
    "      +\"_\"+analyzer.analysis_params.save_info+ext)\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_frequencies = np.stack([np.array(analyzer.bf_stats[\"spatial_frequencies\"]) for analyzer in analyzer_list], axis=0)\n",
    "circular_variances = np.stack([variance for variance in circ_var_list], axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "ax = fig.add_subplot()\n",
    "for analyzer_idx in range(len(analyzer_list)):\n",
    "  ax.scatter(spatial_frequencies[analyzer_idx, :], circular_variances[analyzer_idx, :],\n",
    "    s=12, color=color_list[analyzer_idx], label=label_list[analyzer_idx])\n",
    "ax.set_xlabel(\"Spatial Frequency (Cycles/Patch)\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Circular Variance\", fontsize=fontsize)\n",
    "ax.set_title(\"Weight spatial frequency alone does not account for improved selectivity\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "ax.legend(loc=\"upper center\", framealpha=1.0, fontsize=fontsize)\n",
    "plt.show()\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = (analyzer.analysis_out_dir+\"/vis/spatial_freq_vs_circular_variance\"\n",
    "      +\"_\"+analyzer.analysis_params.save_info+ext)\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [lca_512_vh_params(), lca_768_vh_params(), lca_1024_vh_params()]#, lca_2560_vh_params()]\n",
    "display_names = [\"512 Neurons\", \"768 Neurons\", \"1024 Neurons\"]#, \"2560 Neurons\"]\n",
    "for params, display_name in zip(params_list, display_names):\n",
    "  params.display_name = display_name\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_var_list = []\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_indices = np.random.choice(analyzer.ot_grating_responses[\"neuron_indices\"], 12)\n",
    "  num_orientation_samples = len(analyzer.ot_grating_responses['orientations'])\n",
    "  corresponding_angles_deg = (180 * np.arange(num_orientation_samples) / num_orientation_samples) - 90\n",
    "  corresponding_angles_rad = (np.pi * np.arange(num_orientation_samples) / num_orientation_samples) - (np.pi/2)\n",
    "  analyzer.metrics_list = {\"fwhm\":[], \"circ_var\":[], \"osi\":[], \"skipped_indices\":[]}\n",
    "  contrast_idx = -1\n",
    "  for bf_idx in range(analyzer.bf_stats[\"num_outputs\"]):\n",
    "    ot_curve = nc.center_curve(analyzer.ot_grating_responses[\"mean_responses\"][bf_idx, contrast_idx, :])\n",
    "    if np.max(ot_curve) - np.min(ot_curve) == 0:\n",
    "      analyzer.metrics_list[\"skipped_indices\"].append(bf_idx)\n",
    "    else:\n",
    "      fwhm = nc.compute_fwhm(ot_curve, corresponding_angles_deg)\n",
    "      analyzer.metrics_list[\"fwhm\"].append(fwhm)\n",
    "      circ_var = nc.compute_circ_var(ot_curve, corresponding_angles_rad)\n",
    "      analyzer.metrics_list[\"circ_var\"].append(circ_var)\n",
    "      osi = nc.compute_osi(ot_curve)\n",
    "      analyzer.metrics_list[\"osi\"].append(osi)\n",
    "  circ_var_list.append(np.array([val[2] for val in analyzer.metrics_list[\"circ_var\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [color_vals[\"md_green\"], color_vals[\"md_blue\"], color_vals[\"md_red\"]]#, color_vals[\"blk\"]]\n",
    "label_list = display_names\n",
    "num_bins = 30\n",
    "width_ratios = [0.5, 0.25, 0.25]\n",
    "height_ratios = [0.13, 0.25, 0.25, 0.25]\n",
    "density = True\n",
    "\n",
    "fig = nc.plot_circ_variance_histogram(analyzer_list, circ_var_list, color_list, label_list, num_bins,\n",
    "  density, width_ratios, height_ratios, fontsize, figsize, dpi)\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = (analyzer.analysis_out_dir+\"/vis/overcompleteness_vs_circular_variance\"\n",
    "      +\"_\"+analyzer.analysis_params.save_info+ext)\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted attacks on MLP & LCA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_conf(outputs, labels, index):\n",
    "  return np.std(np.sum(outputs[index] * labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for finding MSE data\n",
    "def find_conf_index(analysis, stop_conf):\n",
    "  outputs = analysis[\"adversarial_outputs\"][0]\n",
    "  target_labels = analysis[\"target_labels\"]\n",
    "  confs = np.sum(outputs * target_labels, axis=-1)\n",
    "  stop_indices = []\n",
    "  for i in range(len(confs.T)):\n",
    "    gt_stop_conf = np.where(confs.T[i] >= stop_conf)[0]\n",
    "    if len(gt_stop_conf) > 0:\n",
    "      stop_indices.append(gt_stop_conf[0])\n",
    "    else:\n",
    "      stop_indices.append(-1)\n",
    "  return stop_indices\n",
    "\n",
    "### Functions for the adv MSE bar plots\n",
    "def get_rects(filename_list, metric, stop_conf):\n",
    "  data = []; means = []; stds = [];\n",
    "  for file in filename_list:\n",
    "    metrics = np.load(file, allow_pickle=True)[\"data\"].item()\n",
    "    stop_indices = find_conf_index(metrics, stop_conf)\n",
    "    MSE = metrics[metric][0, stop_indices, np.arange(metrics[metric][0].shape[-1])]\n",
    "    data.append(MSE)\n",
    "    means.append(np.mean(MSE))\n",
    "    stds.append(np.std(MSE)) \n",
    "  return data, means, stds\n",
    "\n",
    "def get_flat_mnist_mse_data(file_list, metric, stop_conf):\n",
    "  return get_rects(file_list, metric, stop_conf)\n",
    "\n",
    "### Visualizing adv examples plotting code\n",
    "def show(axis, image, clf, vmin=0, vmax=1, cmap=\"Greys\"):\n",
    "  im = axis.imshow(image, cmap=cmap, interpolation=\"nearest\", vmin=vmin, vmax=vmax)\n",
    "  for spine in axis.spines.values():\n",
    "    spine.set_visible(False)\n",
    "  axis.tick_params(\n",
    "    axis=\"both\",\n",
    "    bottom=\"off\",\n",
    "    top=\"off\", \n",
    "    left=\"off\",\n",
    "    right=\"off\")\n",
    "  axis.set_xticks([])\n",
    "  axis.set_yticks([])\n",
    "  props = dict(facecolor='white', alpha=1)\n",
    "  if clf is not None:\n",
    "    axis.text(.05, .95, str(clf), fontsize=8, bbox=props,\n",
    "      verticalalignment='center', color = \"black\")\n",
    "  return im \n",
    "\n",
    "def get_results(metric_files, img_files, stop_conf):\n",
    "  imgs = [np.load(file, allow_pickle=True)[\"data\"].item() for file in img_files]\n",
    "  metrics = [np.load(file, allow_pickle=True)[\"data\"].item() for file in metric_files]\n",
    "  indices = [np.array(find_conf_index(r, stop_conf)) for r in metrics]\n",
    "  input_images = [r[\"input_images\"] for r in metrics]\n",
    "  input_clf = [np.argmax(r[\"input_labels\"], axis=1) for r in metrics]\n",
    "  adv_images = [r[\"adversarial_images\"][0, i, np.arange(len(i)), :] for i, r in zip(indices,imgs)]\n",
    "  adv_clf = [np.argmax(r[\"adversarial_outputs\"][0, i, np.arange(len(i))], axis=1)\n",
    "    for i, r in zip(indices,metrics)]\n",
    "  return input_images, input_clf, adv_images, adv_clf\n",
    "\n",
    "def get_mnist_data(metric_files, img_files, stop_conf):\n",
    "  imgs = [np.load(file, allow_pickle=True)[\"data\"].item() for file in img_files]\n",
    "  metrics = [np.load(file, allow_pickle=True)[\"data\"].item() for file in metric_files]\n",
    "  indices = [np.array(find_conf_index(r, stop_conf)) for r in metrics]\n",
    "  input_images = [r[\"input_images\"].reshape(-1, 28, 28) for r in metrics]\n",
    "  input_clf = [np.argmax(r[\"input_labels\"], axis=1) for r in metrics]\n",
    "  adv_images = [r[\"adversarial_images\"][0, i, np.arange(len(i)), :].reshape(-1, 28, 28) for i, r in zip(indices, imgs)]\n",
    "  adv_clf = [np.argmax(r[\"adversarial_outputs\"][0, i, np.arange(len(i))], axis=1)\n",
    "    for i, r in zip(indices,metrics)]\n",
    "  return input_images, input_clf, adv_images, adv_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE bar chart plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: MSE bar chart + example images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "# kurakin analysis path\n",
    "k_file_path = \"/analysis/0.0/savefiles/class_adversary_analysis_test_kurakin_targeted.npz\"\n",
    "k_img_path = \"/analysis/0.0/savefiles/class_adversary_images_analysis_test_kurakin_targeted.npz\"\n",
    "\n",
    "# carlini analysis path\n",
    "c_file_path = \"/analysis/0.0/savefiles/class_adversary_analysis_test_carlini_targeted.npz\"\n",
    "c_img_path = \"/analysis/0.0/savefiles/class_adversary_images_analysis_test_carlini_targeted.npz\"\n",
    "\n",
    "# model names\n",
    "lca_768_2layer = \"slp_lca_768_latent_75_steps_mnist\"\n",
    "lca_768_3layer = \"mlp_lca_768_latent_75_steps_mnist\"\n",
    "lca_1568_2layer = \"slp_lca_1568_latent_75_steps_mnist\"\n",
    "lca_1568_3layer = \"mlp_lca_1568_latent_75_steps_mnist\"\n",
    "mlp_768_2layer = \"mlp_cosyne_mnist\"\n",
    "mlp_768_3layer = \"mlp_3layer_cosyne_mnist\"\n",
    "mlp_1568_2layer = \"mlp_1568_mnist\"\n",
    "mlp_1568_3layer = \"mlp_1568_3layer_mnist\"\n",
    "\n",
    "# bar chart files/parameters\n",
    "lca_1568_files = [path + model_name + k_file_path for model_name in [lca_1568_2layer, lca_1568_3layer]]\n",
    "lca_768_files = [path + model_name + k_file_path for model_name in [lca_768_2layer, lca_768_3layer]]\n",
    "mlp_1568_files = [path + model_name + k_file_path for model_name in [mlp_1568_2layer, mlp_1568_3layer]]\n",
    "mlp_768_files = [path + model_name + k_file_path for model_name in [mlp_768_2layer, mlp_768_3layer]]\n",
    "\n",
    "xtick_labels = ['2-layer', '3-layer']\n",
    "file_lists = [mlp_768_files, mlp_1568_files, lca_768_files, lca_1568_files]\n",
    "metric = \"input_adv_mses\"\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "names = ['w/o LCA_768', 'w/o LCA_1568', 'w/ LCA_768', 'w/ LCA_1568']\n",
    "\n",
    "# adv example image files/parameters\n",
    "mlp_metric_files = [path +  file + k_file_path for file in [mlp_768_2layer, mlp_768_3layer]]\n",
    "lca_metric_files = [path +  file + k_file_path for file in [lca_768_2layer, lca_768_3layer]]\n",
    "mlp_img_files = [path +  file + k_img_path for file in [mlp_768_2layer, mlp_768_3layer]]\n",
    "lca_img_files = [path +  file + k_img_path for file in [lca_768_2layer, lca_768_3layer]]\n",
    "\n",
    "# adv stop confidence\n",
    "stop_conf = .95\n",
    "\n",
    "text_width = 7.2\n",
    "fig = plt.figure(constrained_layout=True, figsize=figsize, dpi=dpi)#(text_width, text_width/2))\n",
    "\n",
    "#gs = plt.GridSpec(3, 7, figure=fig)\n",
    "#\n",
    "## MSE bar chart\n",
    "#ax1 = fig.add_subplot(gs[:, :2])\n",
    "#data_points = adv_mse_comparison_plot(ax1, file_lists, metric, stop_conf, colors, names,\n",
    "#                                      xtick_labels, xlabel=\"Layer Depth\", \n",
    "#                                      ylabel=\"Mean Squared Distance\", ylim=0.08,\n",
    "#                                      width=.18, fontsize=fontsize)\n",
    "## Example images\n",
    "#ax2 = fig.add_subplot(gs[0, 2])\n",
    "#ax3 = fig.add_subplot(gs[0, 3:5])\n",
    "#ax4 = fig.add_subplot(gs[0, 5:])\n",
    "#\n",
    "#ax5 = fig.add_subplot(gs[1, 2])\n",
    "#ax6 = fig.add_subplot(gs[1, 3:5])\n",
    "#ax7 = fig.add_subplot(gs[1,5:])\n",
    "#\n",
    "#ax8 = fig.add_subplot(gs[2, 2])\n",
    "#ax9 = fig.add_subplot(gs[2, 3:5])\n",
    "#ax10 = fig.add_subplot(gs[2, 5:])\n",
    "#\n",
    "#image_axes = np.array([[ax2, ax3, ax4], [ax5, ax6, ax7], [ax8, ax9, ax10]])\n",
    "\n",
    "gs0 = plt.GridSpec(2, 2, figure=fig)\n",
    "ax0 = fig.add_subplot(gs0[0, 0])\n",
    "data_points0 = adv_mse_comparison_plot(ax0, file_lists, metric, stop_conf, colors, names,\n",
    "  xtick_labels, xlabel=\"Layer Depth\", ylabel=\"Mean Squared Distance\", ylim=0.08,\n",
    "  width=.18, title=\"MNIST\", fontsize=fontsize)\n",
    "\n",
    "ax1 = fig.add_subplot(gs0[0, 1])\n",
    "data_points1 = adv_mse_comparison_plot(ax1, file_lists, metric, stop_conf, colors, names,\n",
    "  xtick_labels, xlabel=\"Layer Depth\", ylabel=\"Mean Squared Distance\", ylim=0.08,\n",
    "  width=.18, title=\"Gray CIFAR10\", fontsize=fontsize)\n",
    "\n",
    "gs_images = gridspec.GridSpecFromSubplotSpec(3, 5, gs0[1,:])#, hspace=-0.6)\n",
    "ax2 = fig.add_subplot(gs_images[0, 0])\n",
    "ax3 = fig.add_subplot(gs_images[0, 1:3])\n",
    "ax4 = fig.add_subplot(gs_images[0, 3:])\n",
    "\n",
    "ax5 = fig.add_subplot(gs_images[1, 0])\n",
    "ax6 = fig.add_subplot(gs_images[1, 1:3])\n",
    "ax7 = fig.add_subplot(gs_images[1, 3:])\n",
    "\n",
    "ax8 = fig.add_subplot(gs_images[2, 0])\n",
    "ax9 = fig.add_subplot(gs_images[2, 1:3])\n",
    "ax10 = fig.add_subplot(gs_images[2, 3:])\n",
    "\n",
    "image_axes = np.array([[ax2, ax3, ax4], [ax5, ax6, ax7], [ax8, ax9, ax10]])\n",
    "\n",
    "\n",
    "show_example(image_axes, mlp_img_files, mlp_metric_files, lca_img_files, lca_metric_files,\n",
    "             stop_conf, [\"Unperturbed\"]+xtick_labels)\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(path+\"adv_mse_examples.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar_mse_data(saved_info, model_names):\n",
    "  data = []; means = []; stds = []\n",
    "  for model_name in model_names:\n",
    "    target_adv_mses = saved_info[model_name][\"target_adv_mses\"]\n",
    "    data.append(target_adv_mses)\n",
    "    means.append(np.mean(target_adv_mses))\n",
    "    stds.append(np.std(target_adv_mses))\n",
    "  return (data, means, stds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def construct_conf_control_plot(saved_info, model_names, bar_groups,\n",
    "  inner_group_names, outer_group_names, bar_width=.4, conf_thresh=.9):\n",
    "  \"\"\"\n",
    "  saved_info: A dictionary of dictionaries, with the outer dictionary containing\n",
    "    the name of the model, and the inner dictionary containing the model stats (target_adv_mses)\n",
    "  model_names: A list of model names that's the key into saved_info\n",
    "  bar_groups: An m by n array of indices into model_names\n",
    "    that denotes which bars should be grouped (if flattened, bar indices goes from\n",
    "    left to right)\n",
    "  inner_group_names: A list of n strings denoting the label of inner group names\n",
    "    (legend labels)\n",
    "  outer_group_names: A list of m strings denoting the label of outer group names\n",
    "    (x axis labels)\n",
    "  bar_width: Sets the width of the bars in the bar plot\n",
    "  conf_thresh: A float denoting the confidence threshold used (only used in the\n",
    "    plot title) TODO remove this param\n",
    "  \"\"\"\n",
    "  COLORS = [\n",
    "    [1.0, 0.0, 0.0], #\"r\"\n",
    "    [0.0, 0.0, 1.0], #\"b\"\n",
    "    [1.0, 0.5, 0.5], #\"dark r\"\n",
    "    [0.0, 0.0, 0.5], #\"light b\"\n",
    "    [0.5, 0.5, 1.0], #\"dark b\"\n",
    "\n",
    "    [0.0, 1.0, 0.0], #\"g\"\n",
    "    [0.5, 1.0, 0.5], #\"dark g\"\n",
    "    [0.0, 1.0, 1.0], #\"c\"\n",
    "    [1.0, 0.0, 1.0], #\"m\"\n",
    "    [1.0, 1.0, 0.0], #\"y\"\n",
    "    [0.0, 0.0, 1.0], #\"k\"\n",
    "    ]\n",
    "  vals, means, errs = get_cifar_mse_data(saved_info, model_names)\n",
    "  color = []; n = []\n",
    "  for model_idx, model_name in enumerate(model_names):\n",
    "    color.append(COLORS[model_idx])\n",
    "    n.append(vals[model_idx].shape[0])\n",
    "  num_groups = len(bar_groups)\n",
    "  num_per_group = len(bar_groups[0])\n",
    "  bar_groups = np.array(bar_groups)\n",
    "  #Plot bar of ave mse per model\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  for i_g in range(num_per_group):\n",
    "    group_means = [means[i] for i in bar_groups[:, i_g]]\n",
    "    group_err = [errs[i] for i in bar_groups[:, i_g]]\n",
    "    group_vals = [vals[i] for i in bar_groups[:, i_g]]\n",
    "    group_n = [n[i] for i in bar_groups[:, i_g]]\n",
    "    x_pos = np.arange(num_groups) + i_g * bar_width\n",
    "    ax.bar(x_pos, group_means, width=bar_width, yerr=group_err,\n",
    "      label=inner_group_names[i_g], color=color[i_g], alpha=.5)\n",
    "    #data points\n",
    "    #TODO do we want to sample here?\n",
    "    for i_gg in range(num_groups):\n",
    "      pos = np.tile(x_pos[i_gg]+(bar_width/4), (group_vals[i_gg].shape[0]))\n",
    "      ax.scatter(pos, group_vals[i_gg], color='black', s=1, zorder=2)\n",
    "    #for i_gg in range(num_groups):\n",
    "    #  ax.text(x_pos[i_gg] + (bar_width/2.0), group_vals[i_gg],\n",
    "    #    \"n=\"+str(group_n[i_gg]), ha='center', va='bottom')\n",
    "  plt.xlabel('Layers', fontsize=fontsize)\n",
    "  plt.xticks([r + (bar_width)/2 for r in range(num_groups)], outer_group_names)\n",
    "  plt.legend(fontsize=fontsize)\n",
    "  #plt.xticks(rotation='vertical')\n",
    "  #ax.set_xlabel(\"Model\")\n",
    "  ax.set_ylabel(\"Input Adv MSE\", fontsize=fontsize)\n",
    "  ax.set_title(\"Average MSE at confidence level \"+str(conf_thresh), fontsize=fontsize)\n",
    "  #plt.tight_layout()\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_names = [\n",
    "    \"mlp_lca_latent_cifar10_gray_2layer\",\n",
    "    \"mlp_cifar10_gray_2layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3layer\",\n",
    "    \"mlp_cifar10_gray_3layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3136_2layer\",\n",
    "    \"mlp_cifar10_gray_3136_2layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3136_3layer\",\n",
    "    \"mlp_cifar10_gray_3136_3layer\",\n",
    "    ]\n",
    "\n",
    "#Organized from left to right, with space between inner lists\n",
    "bar_groups = [[0, 1], [2, 3], [4, 5], [6, 7]]\n",
    "\n",
    "#Legend labels:\n",
    "inner_group_names = [\"w/ LCA\", \"w/o LCA\"]\n",
    "\n",
    "#x axis labels\n",
    "outer_group_names = [\"2 layers 1568\", \"3 layers 1568\", \"2 layers 3136\", \"3 layers 3136\"]\n",
    "\n",
    "save_info = \"analysis_test_kurakin_targeted\"\n",
    "outdir = os.path.expanduser(\"~\")+\"/Work/Projects/vis/\"\n",
    "\n",
    "#Load data\n",
    "pickle_filename = \"vis/CIFAR10_adv_Sheng.pkl\"\n",
    "with open(pickle_filename, \"rb\") as f:\n",
    "  saved_info = pickle.load(f)\n",
    "\n",
    "fig = construct_conf_control_plot(saved_info, model_names, bar_groups,\n",
    "  inner_group_names, outer_group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_violin(ax, group_data, group_means, x_pos, bar_width, color='k', plot_means=True, plot_medians=False):\n",
    "  for data, means, pos in zip(group_data, group_means, x_pos):\n",
    "    parts = ax.violinplot(data, [pos], widths=bar_width,\n",
    "      showmeans=False, showextrema=False, showmedians=False, bw_method=\"silverman\")#, bw_method=0.5)\n",
    "    for pc in parts['bodies']:\n",
    "      pc.set_facecolor(color)\n",
    "      pc.set_edgecolor('k')\n",
    "      pc.set_alpha(1)\n",
    "    quartile1, medians, quartile3 = np.percentile(np.array(data), [25, 50, 75])#, axis=1)\n",
    "    whiskers = np.array([adjacent_values(data, quartile1, quartile3)])\n",
    "    whiskersMin, whiskersMax = whiskers[:, 0], whiskers[:, 1]\n",
    "    if plot_medians:\n",
    "      ax.scatter(pos, medians, marker='o', color='white', s=10, zorder=3, alpha=1)\n",
    "    if plot_means:\n",
    "      ax.scatter(pos, means, marker='o', color='white', s=10, zorder=3, alpha=1)\n",
    "    ax.vlines(pos, quartile1, quartile3, color='k', linestyle='-', lw=5, alpha=1)\n",
    "    ax.vlines(pos, whiskersMin, whiskersMax, color='k', linestyle='-', lw=1, alpha=1)\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxplot(ax, group_data, group_means, x_pos, bar_width, color='k', plot_means=True, plot_medians=False):\n",
    "  boxprops = dict(linestyle='-', linewidth=2, color=color)\n",
    "  whiskerprops = boxprops\n",
    "  capprops = boxprops\n",
    "  medianprops = dict(linestyle='--', linewidth=1, color='k')\n",
    "  meanprops = dict(linestyle='-', linewidth=1, color='k')\n",
    "  for data, means, pos in zip(group_data, group_means, x_pos):\n",
    "    ax.boxplot(data, sym='', positions=[pos], widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "      whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cifar_label(label):\n",
    "  if(label == 0 or label == \"0\"):\n",
    "    return \"airplane\"\n",
    "  if(label == 1 or label == \"1\"):\n",
    "    return \"automobile\"\n",
    "  if(label == 2 or label == \"2\"):\n",
    "    return \"bird\"\n",
    "  if(label == 3 or label == \"3\"):\n",
    "    return \"cat\"\n",
    "  if(label == 4 or label == \"4\"):\n",
    "    return \"deer\"\n",
    "  if(label == 5 or label == \"5\"):\n",
    "    return \"dog\"\n",
    "  if(label == 6 or label == \"6\"):\n",
    "    return \"frog\"\n",
    "  if(label == 7 or label == \"7\"):\n",
    "    return \"horse\"\n",
    "  if(label == 8 or label == \"8\"):\n",
    "    return \"ship\"\n",
    "  if(label == 9 or label == \"9\"):\n",
    "    return \"truck\"\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(ax, data, means, stds, num_groups, num_per_group, bar_groups, bar_width, COLORS,\n",
    "             inner_group_names, outer_group_names, title, fontsize):\n",
    "  for i_g in range(num_per_group):\n",
    "    group_data = [data[i] for i in bar_groups[:, i_g]]\n",
    "    group_means = [means[i] for i in bar_groups[:, i_g]]\n",
    "    group_stds = [stds[i] for i in bar_groups[:, i_g]]\n",
    "    x_pos = np.arange(num_groups) + i_g * bar_width\n",
    "    #ax = make_violin(ax, group_data, group_means, x_pos, bar_width, COLORS[i_g])\n",
    "    ax = make_boxplot(ax, group_data, group_means, x_pos, bar_width, COLORS[i_g])\n",
    "  legend_elements = [Line2D([0], [0], color=COLORS[0], lw=10),\n",
    "                     Line2D([0], [0], color=COLORS[1], lw=10)]\n",
    "  ax.legend(legend_elements, inner_group_names, framealpha=1.0, fontsize=fontsize)\n",
    "  ax.set_xticks([r + (bar_width)/2 for r in range(num_groups)])\n",
    "  ax.set_xticklabels(outer_group_names)\n",
    "  ax.set_ylabel(\"Input Adv MSE\", fontsize=fontsize)\n",
    "  ax.set_xlabel('Number of Layers and Neurons', fontsize=fontsize)\n",
    "  ax.tick_params(\"both\", labelsize=fontsize)\n",
    "  ax.tick_params(\"x\", labelrotation=labelrotation)\n",
    "  ylim = ax.get_ylim()\n",
    "  ax.set_ylim([0, ylim[1]])\n",
    "  ax.set_title(title, fontsize=fontsize)\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labelrotation = 50\n",
    "bar_width = 0.4\n",
    "inner_group_names = [\"w/ LCA\", \"w/o LCA\"]\n",
    "outer_group_names = [\"2 layers 1568\", \"3 layers 1568\", \"2 layers 3136\", \"3 layers 3136\"]\n",
    "COLORS = [\n",
    "  [1.0, 0.0, 0.0], #\"r\"\n",
    "  [0.0, 0.0, 1.0], #\"b\"\n",
    "]\n",
    "\n",
    "bar_groups = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])\n",
    "num_groups = bar_groups.shape[0]\n",
    "num_per_group = bar_groups.shape[1]\n",
    "\n",
    "cifar_data, cifar_means, cifar_stds = get_cifar_mse_data(saved_info, model_names)\n",
    "\n",
    "fig = plt.figure(figsize=[figsize[0], figsize[1]/2], dpi=dpi)\n",
    "gs0 = plt.GridSpec(1, 2, figure=fig, wspace=0.5)\n",
    "\n",
    "ax0 = fig.add_subplot(gs0[0])\n",
    "for i_g in range(num_per_group):\n",
    "  group_data = [cifar_data[i] for i in bar_groups[:, i_g]]\n",
    "  group_means = [cifar_means[i] for i in bar_groups[:, i_g]]\n",
    "  group_stds = [cifar_stds[i] for i in bar_groups[:, i_g]]\n",
    "  x_pos = np.arange(num_groups) + i_g * bar_width\n",
    "  ax0.bar(x_pos, group_means, width=bar_width, yerr=group_stds,\n",
    "    label=inner_group_names[i_g], color=COLORS[i_g])\n",
    "  for i_gg in range(num_groups):\n",
    "    pos = np.tile(x_pos[i_gg]+(bar_width/4), (group_data[i_gg].shape[0]))\n",
    "    ax0.scatter(pos, group_data[i_gg], color='black', s=1, alpha=1.0, zorder=2) \n",
    "legend_elements = [Line2D([0], [0], color=COLORS[0], lw=10),\n",
    "                   Line2D([0], [0], color=COLORS[1], lw=10)]\n",
    "ax0.legend(legend_elements, inner_group_names, fontsize=fontsize)\n",
    "ax0.set_xticks([r + (bar_width)/2 for r in range(num_groups)])\n",
    "ax0.set_xticklabels( outer_group_names)\n",
    "ax0.set_xlabel('Layers', fontsize=fontsize)\n",
    "ax0.set_ylabel(\"Input Adv MSE\", fontsize=fontsize)\n",
    "ax0.tick_params(\"both\", labelsize=fontsize)\n",
    "ax0.tick_params(\"x\", labelrotation=labelrotation)\n",
    "ylim = ax0.get_ylim()\n",
    "ax0.set_ylim([0, ylim[1]])\n",
    "ax0.set_title(\"Bar Plot\", fontsize=fontsize)\n",
    "\n",
    "ax1 = fig.add_subplot(gs0[1])\n",
    "for i_g in range(num_per_group):\n",
    "  group_data = [cifar_data[i] for i in bar_groups[:, i_g]]\n",
    "  group_means = [cifar_means[i] for i in bar_groups[:, i_g]]\n",
    "  group_stds = [cifar_stds[i] for i in bar_groups[:, i_g]]\n",
    "  x_pos = np.arange(num_groups) + i_g * bar_width\n",
    "  ax1 = make_violin(ax1, group_data, group_means, x_pos, bar_width, COLORS[i_g])\n",
    "legend_elements = [Line2D([0], [0], color=COLORS[0], lw=10),\n",
    "                   Line2D([0], [0], color=COLORS[1], lw=10)]\n",
    "ax1.legend(legend_elements, inner_group_names, fontsize=fontsize)\n",
    "ax1.set_xticks([r + (bar_width)/2 for r in range(num_groups)])\n",
    "ax1.set_xticklabels(outer_group_names)\n",
    "ax1.set_ylabel(\"Input Adv MSE\", fontsize=fontsize)\n",
    "ax1.set_xlabel('Layers', fontsize=fontsize)\n",
    "ax1.tick_params(\"both\", labelsize=fontsize)\n",
    "ax1.tick_params(\"x\", labelrotation=labelrotation)\n",
    "ylim = ax1.get_ylim()\n",
    "ax1.set_ylim([0, ylim[1]])\n",
    "ax1.set_title(\"Violin Plot\", fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def show_mnist_example(ax, grp1_imgs, grp1_metrics, grp2_imgs, grp2_metrics, stop_conf, grp_names, start=0):\n",
    "  \"\"\"\n",
    "  shows adv examples\n",
    "  Params\n",
    "  -------\n",
    "  size: int\n",
    "      the number of examples to show\n",
    "  grp1_imgs: list\n",
    "      list of image files for group 1 (i.e mlp models)\n",
    "  grp1_metrics: list: list\n",
    "      list of metric files for group 1 \n",
    "  grp_names: list\n",
    "      list of the group name (e.g. \"Unperturbed\", \"2-layer\")\n",
    "  \"\"\"\n",
    "  size = ax.shape[0]\n",
    "  input_images, _, adv_grp1, adv_clf = get_results(grp1_metrics, grp1_imgs, stop_conf)\n",
    "  _, _, adv_grp2, _ = get_results(grp2_metrics, grp2_imgs, stop_conf)\n",
    "  adv = [(img1, img2) for img1, img2 in zip(adv_grp1, adv_grp2)]\n",
    "  for i in range(start,start+size): # figure rows\n",
    "    for j in range(0, len(grp1_metrics)+1): #figure columns\n",
    "      if j == 0:\n",
    "        if i == start:\n",
    "          ax[i-start, j].set_title(grp_names[j])\n",
    "        orig_data = input_images[j][i].reshape(28,28)\n",
    "        orig_im = show(ax[i-start,j], orig_data, None)\n",
    "      else:\n",
    "        if i == start:\n",
    "          ax[i-start, j].set_title(grp_names[j])\n",
    "        img1, img2 = adv[j-1]\n",
    "        img1 = np.squeeze(img1[i, ...]).reshape(28,28)\n",
    "        delta1 = orig_data - img1\n",
    "        #delta1 = (delta1 - np.min(delta1)) / (np.max(delta1) - np.min(delta1))\n",
    "        stiched1 = np.vstack((img1, delta1))\n",
    "        img2 = np.squeeze(img2[i, ...]).reshape(28,28)\n",
    "        delta2 = orig_data - img2\n",
    "        #delta2 = (delta2 - np.min(delta2)) / (np.max(delta2) - np.min(delta1))\n",
    "        stiched2 = np.vstack((img2, delta2))\n",
    "        stitched_image = np.hstack((stiched1, stiched2))\n",
    "        im = show(ax[i-start,j], stitched_image, adv_clf[j-1][i])\n",
    "        # only display color bar on last column\n",
    "        if j == len(grp1_metrics):\n",
    "          pf.add_colorbar_to_im(im, aspect=20, ax=ax[i-start,j],\n",
    "            ticks=[0.0, 1.0])\n",
    "        ax[i-start, j].set_xlabel(\"w/o LCA         w/ LCA\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def show_cifar_example(ax, grp1_imgs, grp2_imgs, target_labels, orig_labels, grp_names):\n",
    "  \"\"\"\n",
    "  shows adv examples from cifar dataset\n",
    "  Params\n",
    "  -------\n",
    "  ax: list\n",
    "    nested list of axes of len [num_obj_categories][num_groups] which corresponds to [cols][rows]\n",
    "  grp[n]_imgs: list\n",
    "      list of image files for group n (i.e mlp models)\n",
    "      list contains [origina, adv] pairs\n",
    "  grp_names: list\n",
    "      list of the group name (e.g. \"Unperturbed\", \"2-layer\")\n",
    "  \"\"\"\n",
    "  vmin = 0; vmax = 1\n",
    "  num_categories = ax.shape[0]\n",
    "  input_images1, adv_imgs1 = grp1_imgs\n",
    "  input_images2, adv_imgs2 = grp2_imgs\n",
    "  input_images = input_images1\n",
    "  adv = [(img1, img2) for img1, img2 in zip(adv_imgs1, adv_imgs2)]\n",
    "  start = 0\n",
    "  for i in range(start, start+num_categories): # figure rows (obj categories)\n",
    "    for j in range(0, len(input_images)+1): #figure columns (orig, model group 1, model group 2)\n",
    "      if j == 0:\n",
    "        if i == start:\n",
    "          ax[i-start, j].set_title(grp_names[j])\n",
    "        orig_data = crop(np.squeeze(input_images[j][i, ...]), 2)\n",
    "        orig_label = convert_cifar_label(orig_labels[0][i])\n",
    "        orig_im = show(ax[i-start, j], orig_data, orig_label, vmin=vmin, vmax=vmax, cmap=\"Greys_r\")\n",
    "      else:\n",
    "        if i == start:\n",
    "          ax[i-start, j].set_title(grp_names[j])\n",
    "        img1, img2 = adv[j-1]\n",
    "        img1 = crop(np.squeeze(img1[i, ...]), 2)\n",
    "        delta1 = orig_data - img1\n",
    "        #delta1 = (delta1 - np.min(delta1)) / (np.max(delta1) - np.min(delta1))\n",
    "        stiched1 = np.vstack((img1, delta1))\n",
    "        img2 = crop(np.squeeze(img2[i, ...]), 2)\n",
    "        delta2 = orig_data - img2\n",
    "        #delta2 = (delta2 - np.min(delta2)) / (np.max(delta2) - np.min(delta1))\n",
    "        stiched2 = np.vstack((img2, delta2))\n",
    "        stitched_image = np.hstack((stiched1, stiched2))\n",
    "        label = convert_cifar_label(target_labels[j-1][i])\n",
    "        im = show(ax[i-start,j], stitched_image, label, vmin=vmin, vmax=vmax, cmap=\"Greys_r\")\n",
    "        # only display color bar on last column\n",
    "        if j == len(input_images):\n",
    "          pf.add_colorbar_to_im(im, aspect=20, ax=ax[i-start,j],\n",
    "            ticks=[vmin, vmax])\n",
    "        ax[i-start, j].set_xlabel(\"w/o LCA       w/ LCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_subplots(fig, gs, mlp_grp, lca_grp, orig_labels, target_labels, group_names, group_name_loc,\n",
    "                       orig_y_adj, start_idx=0, num_categories=3, crop_ammount=0, hspace=0.5, wspace=-0.4,\n",
    "                       cmap=\"Greys_r\"):\n",
    "  ax_orig_list = []\n",
    "  gs_sub0_list = []\n",
    "  gs_sub1_list = []\n",
    "  for i in range(num_categories):\n",
    "    ax_orig_list.append(fig.add_subplot(gs[i, :2]))\n",
    "    gs_sub0_list.append(gridspec.GridSpecFromSubplotSpec(2, 2, gs[i, 2:4], hspace=hspace, wspace=wspace))\n",
    "    gs_sub1_list.append(gridspec.GridSpecFromSubplotSpec(2, 2, gs[i, 4:], hspace=hspace, wspace=wspace))\n",
    "  \n",
    "  for category_idx in range(num_categories):\n",
    "    image_idx = category_idx + start_idx\n",
    "    orig_ax = ax_orig_list[category_idx]\n",
    "    if category_idx == 0:\n",
    "      orig_ax.set_title(\"Unperturbed\", y=orig_y_adj, fontsize=fontsize)\n",
    "    orig_img = crop(np.squeeze(mlp_grp[0][0][image_idx, ...]), crop_ammount)\n",
    "    orig_im_handle = show(orig_ax, orig_img, orig_labels[0][0][image_idx], cmap=cmap)\n",
    "    for model_idx, gs_sub in enumerate([gs_sub0_list[category_idx], gs_sub1_list[category_idx]]):\n",
    "      mlp_adv_img = crop(np.squeeze(mlp_grp[1][model_idx][image_idx, ...]), crop_ammount)\n",
    "      mlp_diff_img = crop(np.squeeze(mlp_grp[2][model_idx][image_idx, ...]), crop_ammount)\n",
    "      lca_adv_img = crop(np.squeeze(lca_grp[1][model_idx][image_idx, ...]), crop_ammount)\n",
    "      lca_diff_img = crop(np.squeeze(lca_grp[2][model_idx][image_idx, ...]), crop_ammount)\n",
    "      diff_vmin = np.min(np.concatenate((mlp_diff_img, lca_diff_img)))\n",
    "      diff_vmax = np.max(np.concatenate((mlp_diff_img, lca_diff_img)))\n",
    "      img_list = [[mlp_adv_img, lca_adv_img], [mlp_diff_img, lca_diff_img]]\n",
    "      for i in range(2): # row [adv, pert]\n",
    "        for j in range(2): # col [w/o LCA, w/ LCA]\n",
    "          current_ax = fig.add_subplot(gs_sub[i, j])\n",
    "          current_target_label = None\n",
    "          current_image = img_list[i][j]\n",
    "          if i == 0:\n",
    "            vmin = 0.0\n",
    "            vmax = 1.0\n",
    "            if j == 0: # top left image\n",
    "              if model_idx == 0:\n",
    "                current_ax.set_ylabel(r\"$s^{*}_{T}$\", fontsize=fontsize)\n",
    "              current_target_label = target_labels[j][model_idx][image_idx]\n",
    "              if category_idx == 0: # top category only\n",
    "                x_loc = group_name_loc[0]\n",
    "                y_loc = group_name_loc[1]\n",
    "                text_handle = current_ax.text(x_loc, y_loc, group_names[j+model_idx], fontsize=fontsize,\n",
    "                  horizontalalignment='left', verticalalignment='bottom')\n",
    "          else: # i == 1\n",
    "            vmin = np.round(diff_vmin, 2)\n",
    "            vmax = np.round(diff_vmax, 2)\n",
    "            if j == 0 and model_idx == 0:\n",
    "                current_ax.set_ylabel(r\"$s-s^{*}_{T}$\", fontsize=fontsize)\n",
    "            if j == 0 and category_idx == num_categories-1: # bottom left\n",
    "              current_ax.set_xlabel(\"w/o\\nLCA\", fontsize=fontsize)\n",
    "            elif j == 1 and category_idx == num_categories-1: # bottom right\n",
    "              current_ax.set_xlabel(\"w/\\nLCA\", fontsize=fontsize)\n",
    "          im_handle = show(current_ax, current_image, current_target_label, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "          if j == 1:\n",
    "            pf.add_colorbar_to_im(im_handle, aspect=10, ax=current_ax, ticks=[vmin, vmax], labelsize=fontsize/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv stop confidence\n",
    "stop_conf = .95\n",
    "\n",
    "# path to projects directory\n",
    "projects_path = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "# kurakin analysis path\n",
    "k_file_path = \"/analysis/0.0/savefiles/class_adversary_analysis_test_kurakin_targeted.npz\"\n",
    "k_img_path = \"/analysis/0.0/savefiles/class_adversary_images_analysis_test_kurakin_targeted.npz\"\n",
    "\n",
    "# carlini analysis path\n",
    "c_file_path = \"/analysis/0.0/savefiles/class_adversary_analysis_test_carlini_targeted.npz\"\n",
    "c_img_path = \"/analysis/0.0/savefiles/class_adversary_images_analysis_test_carlini_targeted.npz\"\n",
    "\n",
    "# model names\n",
    "lca_768_2layer = \"slp_lca_768_latent_75_steps_mnist\"\n",
    "lca_768_3layer = \"mlp_lca_768_latent_75_steps_mnist\"\n",
    "lca_1568_2layer = \"slp_lca_1568_latent_75_steps_mnist\"\n",
    "lca_1568_3layer = \"mlp_lca_1568_latent_75_steps_mnist\"\n",
    "mlp_768_2layer = \"mlp_cosyne_mnist\"\n",
    "mlp_768_3layer = \"mlp_3layer_cosyne_mnist\"\n",
    "mlp_1568_2layer = \"mlp_1568_mnist\"\n",
    "mlp_1568_3layer = \"mlp_1568_3layer_mnist\"\n",
    "\n",
    "# bar chart files/parameters\n",
    "lca_1568_files = [projects_path + model_name + k_file_path for model_name in [lca_1568_2layer, lca_1568_3layer]]\n",
    "lca_768_files = [projects_path + model_name + k_file_path for model_name in [lca_768_2layer, lca_768_3layer]]\n",
    "mlp_1568_files = [projects_path + model_name + k_file_path for model_name in [mlp_1568_2layer, mlp_1568_3layer]]\n",
    "mlp_768_files = [projects_path + model_name + k_file_path for model_name in [mlp_768_2layer, mlp_768_3layer]]\n",
    "\n",
    "xtick_labels = ['2-layer', '3-layer']\n",
    "file_lists = [mlp_768_files, mlp_1568_files, lca_768_files, lca_1568_files]\n",
    "metric = \"input_adv_mses\"\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "names = ['w/o LCA_768', 'w/o LCA_1568', 'w/ LCA_768', 'w/ LCA_1568']\n",
    "\n",
    "# adv example image files/parameters\n",
    "mlp_metric_files = [projects_path +  file + k_file_path for file in [mlp_768_2layer, mlp_768_3layer]]\n",
    "lca_metric_files = [projects_path +  file + k_file_path for file in [lca_768_2layer, lca_768_3layer]]\n",
    "mlp_img_files = [projects_path +  file + k_img_path for file in [mlp_768_2layer, mlp_768_3layer]]\n",
    "lca_img_files = [projects_path +  file + k_img_path for file in [lca_768_2layer, lca_768_3layer]]\n",
    "\n",
    "mlp_orig_images, mlp_orig_labels, mlp_adv_images, mlp_target_labels = get_mnist_data(mlp_metric_files, mlp_img_files, stop_conf)\n",
    "mlp_diff_images = [mlp_orig_images[model_idx] - mlp_adv_images[model_idx]\n",
    "  for model_idx in range(len(mlp_img_files))]\n",
    "lca_orig_images, lca_orig_labels, lca_adv_images, lca_target_labels = get_mnist_data(lca_metric_files, lca_img_files, stop_conf)\n",
    "lca_diff_images = [lca_orig_images[model_idx] - lca_adv_images[model_idx]\n",
    "  for model_idx in range(len(lca_img_files))]\n",
    "\n",
    "mnist_mlp_grp = [mlp_orig_images, mlp_adv_images, mlp_diff_images]\n",
    "mnist_lca_grp = [lca_orig_images, lca_adv_images, lca_diff_images]\n",
    "mnist_target_labels = [mlp_target_labels, lca_target_labels] # [mlp/lca][which_model][which_image]\n",
    "mnist_orig_labels = [mlp_orig_labels, lca_orig_labels] # [mlp/lca][which_model][which_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model names\n",
    "mnist_lca_768_2layer = \"slp_lca_768_latent_75_steps_mnist\"\n",
    "mnist_lca_768_3layer = \"mlp_lca_768_latent_75_steps_mnist\"\n",
    "mnist_lca_1568_2layer = \"slp_lca_1568_latent_75_steps_mnist\"\n",
    "mnist_lca_1568_3layer = \"mlp_lca_1568_latent_75_steps_mnist\"\n",
    "mnist_mlp_768_2layer = \"mlp_cosyne_mnist\"\n",
    "mnist_mlp_768_3layer = \"mlp_3layer_cosyne_mnist\"\n",
    "mnist_mlp_1568_2layer = \"mlp_1568_mnist\"\n",
    "mnist_mlp_1568_3layer = \"mlp_1568_3layer_mnist\"\n",
    "\n",
    "all_mnist_model_names = [mnist_lca_768_2layer, mnist_mlp_768_2layer, mnist_lca_768_3layer, mnist_mlp_768_3layer,\n",
    "  mnist_lca_1568_2layer, mnist_mlp_1568_2layer, mnist_lca_1568_3layer, mnist_mlp_1568_3layer]\n",
    "mnist_file_lists = [projects_path + model_name + k_file_path for model_name in all_mnist_model_names]\n",
    "\n",
    "all_cifar_model_names = [\n",
    "    \"mlp_lca_latent_cifar10_gray_2layer\",\n",
    "    \"mlp_cifar10_gray_2layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3layer\",\n",
    "    \"mlp_cifar10_gray_3layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3136_2layer\",\n",
    "    \"mlp_cifar10_gray_3136_2layer\",\n",
    "    \"mlp_lca_latent_cifar10_gray_3136_3layer\",\n",
    "    \"mlp_cifar10_gray_3136_3layer\",\n",
    "    ]\n",
    "\n",
    "#Load data\n",
    "pickle_filename = \"vis/CIFAR10_adv_Sheng.pkl\"\n",
    "with open(pickle_filename, \"rb\") as f:\n",
    "  saved_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_models = [\"mlp_cifar10_gray_2layer\", \"mlp_cifar10_gray_3layer\"]\n",
    "lca_models = [\"mlp_lca_latent_cifar10_gray_2layer\", \"mlp_lca_latent_cifar10_gray_3layer\"]\n",
    "\n",
    "indiv_allowable_indices = []\n",
    "for model in mlp_models+lca_models:\n",
    "  indiv_allowable_indices.append(np.argwhere(saved_info[model][\"target_conf_idx\"] != 0))\n",
    "allowable_indices = reduce(np.intersect1d, indiv_allowable_indices)\n",
    "img_indices = np.random.choice(allowable_indices, 5, replace=False)\n",
    "actual_img_indices = dict()\n",
    "for model in mlp_models+lca_models:\n",
    "  actual_img_indices[model] = []\n",
    "  for index in img_indices:\n",
    "    zero_locs = np.argwhere(saved_info[model][\"target_conf_idx\"][:index] == 0)\n",
    "    actual_img_indices[model].append(index - zero_locs.size)\n",
    "\n",
    "mlp_orig_images = [saved_info[model][\"orig_img\"][actual_img_indices[model], ...] for model in mlp_models]\n",
    "mlp_adv_images = [saved_info[model][\"adv_img\"][actual_img_indices[model], ...] for model in mlp_models]\n",
    "mlp_diff_images = [mlp_orig_images[model_idx] - mlp_adv_images[model_idx]\n",
    "  for model_idx in range(len(mlp_models))]\n",
    "mlp_target_labels = []\n",
    "mlp_orig_labels = []\n",
    "for model in mlp_models:\n",
    "  target_labels = [convert_cifar_label(label) for label in saved_info[model][\"target_label\"][actual_img_indices[model]]]\n",
    "  orig_labels = [convert_cifar_label(label) for label in saved_info[model][\"orig_label\"][actual_img_indices[model]]]\n",
    "  mlp_target_labels.append(target_labels)\n",
    "  mlp_orig_labels.append(orig_labels)\n",
    "\n",
    "lca_orig_images = [saved_info[model][\"orig_img\"][actual_img_indices[model], ...] for model in lca_models]\n",
    "lca_adv_images = [saved_info[model][\"adv_img\"][actual_img_indices[model], ...] for model in lca_models]\n",
    "lca_diff_images = [lca_orig_images[model_idx] - lca_adv_images[model_idx]\n",
    "  for model_idx in range(len(lca_models))]\n",
    "lca_target_labels = []\n",
    "lca_orig_labels = []\n",
    "for model in lca_models:\n",
    "  target_labels = [convert_cifar_label(label) for label in saved_info[model][\"target_label\"][actual_img_indices[model]]]\n",
    "  lca_target_labels.append(target_labels)\n",
    "  orig_labels = [convert_cifar_label(label) for label in saved_info[model][\"orig_label\"][actual_img_indices[model]]]\n",
    "  lca_orig_labels.append(orig_labels)\n",
    "\n",
    "cifar_mlp_grp = [mlp_orig_images, mlp_adv_images, mlp_diff_images]\n",
    "cifar_lca_grp = [lca_orig_images, lca_adv_images, lca_diff_images]\n",
    "cifar_target_labels = [mlp_target_labels, lca_target_labels]\n",
    "cifar_orig_labels = [mlp_orig_labels, lca_orig_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelrotation = 50\n",
    "bar_width = 0.4\n",
    "inner_group_names = [\"w/ LCA\", \"w/o LCA\"]\n",
    "mnist_outer_group_names = [\"2 layers 768\", \"3 layers 768\", \"2 layers 1568\", \"3 layers 1568\"]\n",
    "cifar_outer_group_names = [\"2 layers 1568\", \"3 layers 1568\", \"2 layers 3136\", \"3 layers 3136\"]\n",
    "mnist_img_labels = [mnist_outer_group_names[0], mnist_outer_group_names[2]]\n",
    "cifar_img_labels = [cifar_outer_group_names[0], cifar_outer_group_names[2]]\n",
    "COLORS = [\n",
    "  [1.0, 0.0, 0.0], #\"r\"\n",
    "  [0.0, 0.0, 1.0], #\"b\"\n",
    "]\n",
    "# bar_groups are organized from left to right, with space between inner lists\n",
    "bar_groups = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])\n",
    "num_groups = bar_groups.shape[0]\n",
    "num_per_group = bar_groups.shape[1]\n",
    "\n",
    "mnist_data, mnist_means, mnist_stds = get_flat_mnist_mse_data(mnist_file_lists, metric, stop_conf)\n",
    "cifar_data, cifar_means, cifar_stds = get_cifar_mse_data(saved_info, all_cifar_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_names = all_mnist_model_names+all_cifar_model_names\n",
    "project_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=[figsize[0], figsize[1]/2], dpi=dpi)\n",
    "gs0 = plt.GridSpec(1, 2, figure=fig1, wspace=0.3)\n",
    "\n",
    "ax_mnist_mse = fig1.add_subplot(gs0[0])\n",
    "ax_mnist_mse = plot_mse(ax_mnist_mse, mnist_data, mnist_means, mnist_stds, num_groups, num_per_group,\n",
    "  bar_groups, bar_width, COLORS, inner_group_names, mnist_outer_group_names, \"MNIST\", fontsize)\n",
    "\n",
    "ax_cifar_mse = fig1.add_subplot(gs0[1])\n",
    "ax_cifar_mse = plot_mse(ax_cifar_mse, cifar_data, cifar_means, cifar_stds, num_groups, num_per_group,\n",
    "  bar_groups, bar_width, COLORS, inner_group_names, cifar_outer_group_names, \"Grayscale CIFAR\", fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = [project_dir + model_name + \"/analysis/0.0/vis/adv_mse_comparison_boxplots\" for model_name in all_model_names]\n",
    "for out_name in out_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = out_name+ext\n",
    "    fig1.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 44\n",
    "mnist_start_idx = 44#np.random.randint(90)\n",
    "print(mnist_start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hspace = 0.3\n",
    "wspace = 1.8\n",
    "sub_hspace = 0.2\n",
    "sub_wspace = 0.2\n",
    "orig_y_adj = 1.17\n",
    "img_label_loc = [-8.0, -8.0] # [x, y]\n",
    "fig2 = plt.figure(figsize=[figsize[0], figsize[1]/2], dpi=dpi)\n",
    "gs0 = plt.GridSpec(1, 2, figure=fig2, wspace=0.3)\n",
    "\n",
    "num_categories=3\n",
    "\n",
    "gs_mnist = gridspec.GridSpecFromSubplotSpec(num_categories, 6, gs0[0], hspace=hspace, wspace=wspace)\n",
    "make_grid_subplots(fig2, gs_mnist, mnist_mlp_grp, mnist_lca_grp, mnist_orig_labels,\n",
    "  mnist_target_labels, mnist_img_labels, img_label_loc, orig_y_adj, mnist_start_idx,\n",
    "  num_categories, hspace=sub_hspace, wspace=sub_wspace, cmap=\"Greys\")\n",
    "\n",
    "gs_cifar = gridspec.GridSpecFromSubplotSpec(num_categories, 6, gs0[1], hspace=hspace, wspace=wspace)\n",
    "make_grid_subplots(fig2, gs_cifar, cifar_mlp_grp, cifar_lca_grp, cifar_orig_labels,\n",
    "  cifar_target_labels, cifar_img_labels, img_label_loc, orig_y_adj, 0,\n",
    "  num_categories, hspace=sub_hspace, wspace=sub_wspace, cmap=\"Greys_r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = [project_dir + model_name + \"/analysis/0.0/vis/adv_mse_comparison_example_images\" for model_name in all_model_names]\n",
    "for out_name in out_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = out_name+ext\n",
    "    fig2.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figures/Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram the MSE datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_conf(outputs, labels, index):\n",
    "  return np.mean(np.sum(outputs[index] * labels, axis=1))\n",
    "\n",
    "def find_avg_conf_step(analysis):\n",
    "  outputs = analysis[\"adversarial_outputs\"][0]\n",
    "  target_labels = analysis[\"target_labels\"]\n",
    "  indices = len(outputs)\n",
    "  confs = []\n",
    "  for i in range(indices):\n",
    "    confs.append(mean_conf(outputs, target_labels, i))\n",
    "  return np.array(confs)\n",
    "\n",
    "def plot_average_conf_step(analysis_files, model_names):\n",
    "    stop_conf=.95 \n",
    "    fig, ax = plt.subplots()\n",
    "    for file, name in zip(analysis_files, model_names):\n",
    "        analysis = np.load(file, allow_pickle=True)[\"data\"].item()\n",
    "        ax.plot(find_avg_conf_step(analysis), label=name)\n",
    "    \n",
    "        print(np.max(find_avg_conf_step(analysis)))\n",
    "    ax.legend(loc=\"lower right\", framealpha=1.0)\n",
    "    ax.set_xlabel(\"Attack Step\")\n",
    "    ax.set_ylabel(\"Mean Target-class Confidence\")\n",
    "    ax.set_ylim(0,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_mse_data(file_lists, metric, stop_conf):\n",
    "  \"\"\"\n",
    "  Params\n",
    "  ------\n",
    "  file_lists: list\n",
    "      list of list with organization\n",
    "      inner list: model-type filenames (i.e. lca or mlp)\n",
    "      outer lists: groups across models (i.e. layer depth)\n",
    "  metric: str\n",
    "      the analysis metric to average over\n",
    "  stop_conf: float\n",
    "      the desired classifier confidence for stopping the adversarial attack\n",
    "  \"\"\"\n",
    "  data = []; means = []; stds = []\n",
    "  for file_list in file_lists:\n",
    "    data_step, means_step, stds_step = get_rects(file_list, metric, stop_conf) \n",
    "    means.append(means_step)\n",
    "    data.append(data_step)\n",
    "    stds.append(stds_step)\n",
    "  return (data, means, stds)\n",
    "\n",
    "def multi_model_compare(ax, data, means, stds, colors, names, xtick_labels,\n",
    "                        xlabel, ylabel, ylim, width, title, fontsize):\n",
    "  # orgnaize the data\n",
    "  cmap_gray = cm.get_cmap(\"gray\")\n",
    "  N = len(data[0]) # number of depths\n",
    "  M = len(data) # number of models being compared\n",
    "  # create the bar chart\n",
    "  ind = np.arange(N)  # the x locations for the depths    \n",
    "  rects = []\n",
    "  for i in range(M):\n",
    "    # the bars\n",
    "    x = ind + i * (width+.01)\n",
    "    rect = ax.bar(x, means[i], color=colors[i], yerr=stds[i], width=width, alpha=1.0)\n",
    "    rects.append(rect)\n",
    "    # the data points\n",
    "    bar_data = np.array(data[i])\n",
    "    x_tiled = np.tile(x+(width/4), (bar_data.shape[-1],1)).T\n",
    "    ax.scatter(x_tiled, bar_data, color='black', alpha=1.0, s=1, zorder=2)\n",
    "  ax.set_xticks(ind + ((M-1)*(width+.01))/2)\n",
    "  ax.set_xticklabels(xtick_labels, fontsize=fontsize)\n",
    "  ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "  ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.xaxis.set_ticks_position('bottom')\n",
    "  ax.yaxis.set_ticks_position('left')\n",
    "  ax.yaxis.grid(which=\"major\", color=cmap_gray(.8), linestyle='--', linewidth=1)\n",
    "  ax.tick_params(\"both\", labelsize=fontsize)\n",
    "  ax.set_axisbelow(True)\n",
    "  ax.set_ylim([0, ylim])\n",
    "  ax.set_title(title, fontsize=fontsize)\n",
    "  ax.legend([r[0] for r in rects], names, fontsize=fontsize, loc='upper right', framealpha=1.0)\n",
    "  return data\n",
    "\n",
    "def adv_mse_comparison_plot(ax, file_lists, metric, stop_conf,\n",
    "                            colors, names, xtick_labels, xlabel, ylabel, ylim, width, title, fontsize):\n",
    "  \"\"\"\n",
    "  Bar chart that compares a designated metric for each model in file_lists\n",
    "  \n",
    "  Params\n",
    "  ------\n",
    "  file_lists: list\n",
    "      list of list with organization\n",
    "      inner list: model-type filenames (i.e. lca or mlp)\n",
    "      outer lists: groups across models (i.e. layer depth)\n",
    "  metric: str\n",
    "      the analysis metric to average over\n",
    "  stop_conf: float\n",
    "      the desired classifier confidence for stopping the adversarial attack\n",
    "  colors: list\n",
    "      list of list of matplotlib color codes for each model\n",
    "      has same nested order as file_lists\n",
    "  xtick_labels: list\n",
    "      list of the group labels (i.e. layer depths)\n",
    "  names: list\n",
    "      names of the models (i.e. lca or mlp)\n",
    "  xlabel: str\n",
    "      x axis label\n",
    "  \"\"\"\n",
    "  data, means, stds = get_mnist_mse_data(file_lists, metric, stop_conf)\n",
    "  return multi_model_compare(ax, data, means, stds, colors, names, xtick_labels, xlabel, ylabel, ylim, width, title, fontsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "\n",
    "file_path = k_file_path # kurakin\n",
    "# file_path = c_file_path # carlini\n",
    "lca_files = [path + model_name + file_path for model_name in [lca_768_2layer]]\n",
    "mlp_files = [path + model_name + file_path for model_name in [mlp_768_2layer]]\n",
    "files = mlp_files + lca_files\n",
    "\n",
    "names = ['w/o LCA', 'w/ LCA'] \n",
    "plot_average_conf_step(files, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mnist_mlp_768_2layer#\"mlp_cosyne_mnist\"\n",
    "lca = mnist_lca_768_2layer#\"slp_lca_768_latent_75_steps_mnist\"\n",
    "lista = 'slp_lista_768_5_layers_mnist'\n",
    "lca_file, lista_file, mlp_file = (path + model_name + k_file_path for model_name in [lca, lista, mlp])\n",
    "lca_img_file, lista_img_file, mlp_img_file = (path + model_name + k_img_path for model_name in [lca, lista, mlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [[color_vals['md_blue'], color_vals['md_green'], color_vals['md_red']]]\n",
    "xtick_labels = ['MLP', 'w/ LISTA', 'w/ LCA']\n",
    "file_lists = [[mlp_file, lista_file, lca_file]] #, lca_1568_files]\n",
    "\n",
    "metric = \"input_adv_mses\"\n",
    "names = [None]\n",
    "\n",
    "stop_conf=.95\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "data_points = adv_mse_comparison_plot(ax, file_lists, metric, stop_conf, colors, names,\n",
    "                                     xtick_labels, \"\", \"Mean Squared Distance\", .08, width=.5,\n",
    "                                     title=\"Adversarial MNIST at\\n95% Confidence\", fontsize=fontsize)\n",
    "ax.get_legend().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "out_list = [path + model_name + \"/analysis/0.0/vis/mlp_lista_lca_adv_comparison\"\n",
    "  for model_name in [mnist_mlp_768_2layer, lista, mnist_lca_768_2layer]]\n",
    "for out_name in out_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = out_name+ext\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_data = get_mnist_mse_data([lca_1568_files], metric, stop_conf)[0][0]\n",
    "n_bins = 25\n",
    "\n",
    "plt.figure()\n",
    "hist1, bins = np.histogram(lca_data[0], n_bins)\n",
    "plt.bar(bins[:n_bins],hist1/len(lca_data[0]), width = .003, alpha=.7, label=\"lca_2layer\")\n",
    "\n",
    "hist2, bins = np.histogram(lca_data[1], n_bins)\n",
    "plt.bar(bins[:n_bins],hist2/len(lca_data[1]), width = .003, alpha=.7, label=\"lca_3layer\")\n",
    "\n",
    "plt.xlabel(\"Adversarial MSE\")\n",
    "plt.ylabel(\"Frequency of Images\")\n",
    "plt.legend(framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average target-class confidence per kurakin attack step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average adversarial MSE per kurakin attack step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mse(analysis):\n",
    "  outputs = analysis[\"input_adv_mses\"][0]\n",
    "  indices = len(outputs)\n",
    "  mean_mses = []; std_mses = []\n",
    "  for i in range(indices):\n",
    "    mean_mses.append(np.mean(outputs[i]))\n",
    "    std_mses.append(np.std(outputs[i]))\n",
    "  return np.array(mean_mses), np.array(std_mses)     \n",
    "\n",
    "def plot_average_mse_step(analysis_files, colors, axis_titles, model_names, figsize, dpi, fontsize):\n",
    "    #hatches = [\"x\", \"+\"]\n",
    "    #hatches = [\"o\", \"O\"]\n",
    "    hatches = [\"/\", \"\\\\\"]\n",
    "    #hatches = [\"-\", \"|\"]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "    for ax_idx, (sub_analysis_files, title) in enumerate(zip(analysis_files, axis_titles)):\n",
    "      for file_idx, (file, name) in enumerate(zip(sub_analysis_files, model_names)):\n",
    "        analysis = np.load(file, allow_pickle=True)[\"data\"].item()\n",
    "        mean_mse, std_mse = find_mse(analysis)\n",
    "        axes[ax_idx].plot(range(len(mean_mse)), mean_mse, label=name, lw=3, color=colors[file_idx][0], zorder=1)\n",
    "        axes[ax_idx].fill_between(range(len(mean_mse)), mean_mse + std_mse , mean_mse - std_mse,\n",
    "          edgecolor=colors[file_idx][1], alpha=1.0, zorder=0, facecolor=\"none\", hatch=hatches[file_idx],\n",
    "          rasterized=False)\n",
    "        axes[ax_idx].set_title(title, fontsize=fontsize)\n",
    "        axes[ax_idx].set_xlabel(\"Attack Step\", fontsize=fontsize)\n",
    "        axes[ax_idx].tick_params(\"both\", labelsize=fontsize)\n",
    "    axes[0].legend(loc=\"upper left\", fontsize=fontsize, framealpha=1.0)\n",
    "    axes[0].set_ylabel(\"Adversarial Mean Squared Distance\", fontsize=fontsize)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = [[color_vals['md_blue'], color_vals['lt_blue']], [color_vals['md_red'], color_vals['lt_red']]]\n",
    "axis_titles = [\"Kurakin\", \"Carlini\"]\n",
    "model_names = ['w/o LCA', 'w/ LCA']\n",
    "\n",
    "k_lca_files = [path + model_name + k_file_path for model_name in [mnist_lca_768_2layer]]\n",
    "k_mlp_files = [path + model_name + k_file_path for model_name in [mnist_mlp_768_2layer]]\n",
    "k_files = k_mlp_files + k_lca_files\n",
    "c_lca_files = [path + model_name + c_file_path for model_name in [mnist_lca_768_2layer]]\n",
    "c_mlp_files = [path + model_name + c_file_path for model_name in [mnist_mlp_768_2layer]]\n",
    "c_files = c_mlp_files + c_lca_files\n",
    "\n",
    "fig, ax = plot_average_mse_step([k_files, c_files], colors, axis_titles, model_names, [figsize[0], figsize[1]/2],\n",
    "  dpi, fontsize)\n",
    "\n",
    "out_list = [path + model_name + \"/analysis/0.0/vis/kurakin_carlini_mse_vs_iteration\"\n",
    "  for model_name in [lca_768_2layer, mlp_768_2layer]]\n",
    "for out_name in out_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = out_name+ext\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Differentiable Loss Surface Adversarial Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.version = '0.0'\n",
    "        self.projects_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"     \n",
    "        self.save_info = 'test'\n",
    "        self.overwrite_analysis_log = False\n",
    "        self.do_neuron_visualization=False\n",
    "        \n",
    "def get_label_est(model_name, input_images):\n",
    "    # Get params, set dirs\n",
    "    analysis_params = params(model_name) # construct object\n",
    "\n",
    "    # Load arguments\n",
    "    model_name_list = os.listdir(analysis_params.projects_dir)\n",
    "    analysis_params.model_dir = analysis_params.projects_dir+analysis_params.model_name\n",
    "\n",
    "    model_log_file = (analysis_params.model_dir+\"/logfiles/\"+analysis_params.model_name\n",
    "      +\"_v\"+analysis_params.version+\".log\")\n",
    "    model_logger = Logger(model_log_file, overwrite=False)\n",
    "    model_log_text = model_logger.load_file()\n",
    "    model_params = model_logger.read_params(model_log_text)[-1]\n",
    "    analysis_params.model_type = model_params.model_type\n",
    "\n",
    "    # Initialize & setup analyzer\n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analyzer.setup(analysis_params)\n",
    "    analysis_params.data_type = analyzer.model_params.data_type\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "    \n",
    "    # run forward pass\n",
    "    with tf.Session(graph=analyzer.model.graph) as sess:\n",
    "        feed_dict = analyzer.model.get_feed_dict(input_images, is_test=True)\n",
    "        sess.run(analyzer.model.init_op, feed_dict)\n",
    "        analyzer.model.load_full_model(sess, analyzer.analysis_params.cp_loc)\n",
    "        label_est = sess.run(analyzer.model.label_est, feed_dict)\n",
    "        \n",
    "    return label_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare adv. MSE for more differentiable loss surface\n",
    " LCA vs LISTA\n",
    " \n",
    "### See if LISTA adv. examples translate to LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_stop_conf = .95\n",
    "# get lista adv images\n",
    "input_images, input_clf, adv_images, adv_clf = get_results([lista_file], [lista_img_file], lista_stop_conf)\n",
    "# pass through the models\n",
    "lca_softmax_labels = get_label_est(lca, adv_images[0])\n",
    "lista_softmax_labels = get_label_est(lista, adv_images[0])\n",
    "mlp_softmax_labels = get_label_est(mlp, adv_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize the data\n",
    "lca_confs_lista_adv = [out[cls] for out, cls in zip(lca_softmax_labels, adv_clf[0])]\n",
    "lca_confs_input = [out[cls] for out, cls in zip(lca_softmax_labels, input_clf[0])]\n",
    "\n",
    "mlp_confs_lista_adv = [out[cls] for out, cls in zip(mlp_softmax_labels, adv_clf[0])]\n",
    "mlp_confs_input = [out[cls] for out, cls in zip(mlp_softmax_labels, input_clf[0])]\n",
    "\n",
    "lista_confs_lista_adv = [out[cls] for out, cls in zip(lista_softmax_labels, adv_clf[0])]\n",
    "lista_confs_input = [out[cls] for out, cls in zip(lista_softmax_labels, input_clf[0])]\n",
    "\n",
    "filter_indices = np.where(np.array(lista_confs_lista_adv) > .8)[0]\n",
    "\n",
    "data = [[lista_confs_input, lista_confs_lista_adv],\n",
    "        [mlp_confs_input, mlp_confs_lista_adv],\n",
    "        [lca_confs_input, lca_confs_lista_adv]]\n",
    "\n",
    "data = [[np.array(confs)[filter_indices] for confs in model_confs] for model_confs in data]\n",
    "means = [[np.mean(confs) for confs in model_confs] for model_confs in data]\n",
    "stds = [np.array([[0,0],[np.std(confs) for confs in model_confs]]) for model_confs in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [color_vals['md_green'], color_vals['md_blue'], color_vals['md_red']]\n",
    "xtick_labels = [\"Original Label\", \"Adv Target Label\"]\n",
    "xlabel = None#\"Class Position\"\n",
    "ylabel = \"Softmax Confidence\"\n",
    "names = ['w/ LISTA', 'MLP', 'w/ LCA']\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "multi_model_compare(ax, data, means, stds, colors, names, xtick_labels, xlabel, ylabel, 1, width=.25,\n",
    "                   title=\"Transferability of LISTA\\nAdversarial Images\", fontsize=fontsize);\n",
    "legend = ax.get_legend()\n",
    "legend.set_bbox_to_anchor([1.28,0.94,0,0], transform=fig.transFigure)\n",
    "plt.show()\n",
    "\n",
    "out_list += [path + lista + \"/analysis/0.0/vis/lista_adv_transferability\"]\n",
    "for out_name in out_list:\n",
    "  for ext in [\".png\", \".eps\"]:\n",
    "    save_name = out_name+ext\n",
    "    fig.savefig(save_name, transparent=False, bbox_inches=\"tight\", pad_inches=0.01, dpi=dpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
