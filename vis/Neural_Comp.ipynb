{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Computation Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (10, 10)\n",
    "fontsize = 16\n",
    "dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lca_512_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_512_vh\"\n",
    "    self.display_name = \"Sparse Coding 512\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_vh\"\n",
    "    self.display_name = \"Sparse Coding 768\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_1024_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_1024_vh\"\n",
    "    self.display_name = \"Sparse Coding 1024\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_vh\"\n",
    "    self.display_name = \"Sparse Autoencoder\"\n",
    "    self.version = \"1.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class rica_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"rica\"\n",
    "    self.model_name = \"rica_768_vh\"\n",
    "    self.display_name = \"Linear Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_768_vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_vh\"\n",
    "    self.display_name = \"ReLU Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_mnist\"\n",
    "    self.display_name = \"Sparse Coding 768\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_1536_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_1536_mnist\"\n",
    "    self.display_name = \"Sparse Coding 1536\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.display_name = \"ReLU Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_mnist\"\n",
    "    self.display_name = \"Sparse Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class rica_768_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"rica\"\n",
    "    self.model_name = \"rica_768_mnist\"\n",
    "    self.display_name = \"Linear Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_deep_mnist_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_deep_mnist\"\n",
    "    self.display_name = \"ReLU Autoencoder\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iso-contour activations comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_list = [rica_768_vh_params(), ae_768_vh_params(), sae_768_vh_params(), lca_768_vh_params()]\n",
    "params_list = [rica_768_mnist_params(), ae_768_mnist_params(), sae_768_mnist_params(), lca_768_mnist_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  run_params = np.load(analyzer.analysis_out_dir+\"savefiles/iso_params_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()\n",
    "  min_angle = run_params[\"min_angle\"]\n",
    "  max_angle = run_params[\"max_angle\"]\n",
    "  num_neurons = run_params[\"num_neurons\"]\n",
    "  use_bf_stats = run_params[\"use_bf_stats\"]\n",
    "  num_comparison_vectors = run_params[\"num_comparison_vects\"]\n",
    "  use_random_orth_vects = run_params[\"use_random_orth_vects\"]\n",
    "  x_range = run_params[\"x_range\"]\n",
    "  y_range = run_params[\"y_range\"]\n",
    "  num_images = run_params[\"num_images\"]\n",
    "  analyzer.comp_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"]\n",
    "  analyzer.comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()\n",
    "  analyzer.rand_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_activations_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"]\n",
    "  analyzer.rand_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_contour_dataset_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_goup_iso_contours(analyzer_list, neuron_indices, orth_indices, num_levels):\n",
    "  num_neurons = len(neuron_indices)\n",
    "  num_plots_y = np.int32(np.ceil(np.sqrt(num_neurons)))\n",
    "  num_plots_x = np.int32(np.ceil(np.sqrt(num_neurons)))+1 # +cbar col\n",
    "  gs_widths = [1 for _ in range(num_plots_x-1)]+[0.1]\n",
    "  gs0 = gridspec.GridSpec(num_plots_y, num_plots_x, width_ratios=gs_widths, hspace=-0.1, wspace=-0.3)\n",
    "  \n",
    "  vmin = np.min([analyzer.comp_activations for analyzer in analyzer_list])\n",
    "  vmax = np.max([analyzer.comp_activations for analyzer in analyzer_list])\n",
    "  levels = np.linspace(vmin, vmax, num_levels)\n",
    "  \n",
    "  cmap = plt.get_cmap(\"cividis\")#\"Greys_r\")#\"viridis\")\n",
    "  cNorm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "  scalarMap = matplotlib.cm.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "  \n",
    "\n",
    "  fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "  analyzer_index = 0\n",
    "  for plot_id in  np.ndindex((num_plots_y, num_plots_x-1)):\n",
    "    (y_id, x_id) = plot_id\n",
    "    if type(neuron_indices) == list:\n",
    "      analyzer_neuron_index = neuron_indices[analyzer_index]\n",
    "    else:\n",
    "      analyzer_neuron_index = neuron_indices\n",
    "    if type(orth_indices) == list:\n",
    "      analyzer_orth_index = orth_indices[analyzer_index]\n",
    "    else:\n",
    "      analyzer_orth_index = orth_indices\n",
    "    analyzer = analyzer_list[analyzer_index]\n",
    "    gs1 = gridspec.GridSpecFromSubplotSpec(1, 2, gs0[plot_id], wspace=-0.15, hspace=0.1)\n",
    "    curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "    curve_ax.set_title(analyzer.analysis_params.display_name, fontsize=fontsize)\n",
    "\n",
    "    norm_activity = analyzer.comp_activations[analyzer_neuron_index, analyzer_orth_index, ...]\n",
    "    x_mesh, y_mesh = np.meshgrid(analyzer.comp_contour_dataset[\"x_pts\"], analyzer.comp_contour_dataset[\"y_pts\"])\n",
    "    contsf = curve_ax.contourf(x_mesh, y_mesh, norm_activity,\n",
    "      levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "\n",
    "    proj_target = analyzer.comp_contour_dataset[\"proj_target_neuron\"][analyzer_neuron_index][analyzer_orth_index]\n",
    "    target_vector_x = proj_target[0].item()\n",
    "    target_vector_y = proj_target[1].item()\n",
    "    curve_ax.arrow(0, 0, target_vector_x, target_vector_y,\n",
    "      width=0.00, head_width=0.15, head_length=0.15, fc='k', ec='k',\n",
    "      linestyle='-', linewidth=3)\n",
    "    \n",
    "    tenth_range_shift = ((max(x_range) - min(x_range))/10)\n",
    "    text_handle = curve_ax.text(target_vector_x+(tenth_range_shift*0.3),\n",
    "      target_vector_y+(tenth_range_shift*0.7),\n",
    "      r\"$\\Phi_{k}$\",\n",
    "      fontsize=fontsize,\n",
    "      horizontalalignment='center',\n",
    "      verticalalignment='center',\n",
    "      #bbox=dict(boxstyle=\"tightbox,pad=0.,rounding_size=0.2,rescale=1.0\",\n",
    "      #  ec=(1., 1.0, 1.0),\n",
    "      #  fc=(1., 1.0, 1.0),\n",
    "      #  alpha=0.4),\n",
    "      )\n",
    "\n",
    "    proj_comparison = analyzer.comp_contour_dataset[\"proj_comparison_neuron\"][analyzer_neuron_index][analyzer_orth_index]\n",
    "    comparison_vector_x = proj_comparison[0].item()\n",
    "    comparison_vector_y = proj_comparison[1].item()\n",
    "    curve_ax.arrow(0, 0, comparison_vector_x, comparison_vector_y,\n",
    "      width=0.00, head_width=0.15, head_length=0.15, fc='k', ec='k',\n",
    "      linestyle=\"dotted\", linewidth=1.0)\n",
    "    text_handle = curve_ax.text(comparison_vector_x+(tenth_range_shift*0.3),\n",
    "      comparison_vector_y+(tenth_range_shift*0.7),\n",
    "      r\"$\\Phi_{j}$\",\n",
    "      fontsize=fontsize,\n",
    "      horizontalalignment='center',\n",
    "      verticalalignment='center',\n",
    "      #bbox=dict(boxstyle=\"tightbox,pad=0.,rounding_size=0.2,rescale=1.0\",\n",
    "      #  ec=(1., 1., 1.),\n",
    "      #  fc=(1., 1., 1.)),\n",
    "      )\n",
    "\n",
    "    #for proj_alt in analyzer.comp_contour_dataset[\"proj_comparison_neuron\"][analyzer_neuron_index]:\n",
    "    #  if not np.all(proj_alt == proj_comparison):\n",
    "    #    curve_ax.arrow(0, 0, proj_alt[0].item(), proj_alt[1].item(),\n",
    "    #      width=0.00, head_width=0.15, head_length=0.15, fc='w', ec='w',\n",
    "    #      linestyle=\"dashed\", linewidth=1.0, alpha=0.9)\n",
    "\n",
    "    proj_orth = analyzer.comp_contour_dataset[\"proj_orth_vect\"][analyzer_neuron_index][analyzer_orth_index]\n",
    "    orth_vector_x = proj_orth[0].item()\n",
    "    orth_vector_y = proj_orth[1].item()\n",
    "    curve_ax.arrow(0, 0, orth_vector_x, orth_vector_y,\n",
    "      width=0.00, head_width=0.10, head_length=0.10, fc='k', ec='k',\n",
    "      linestyle=\"-\", linewidth=3)\n",
    "    text_handle = curve_ax.text(orth_vector_x+(tenth_range_shift*0.3),\n",
    "      orth_vector_y+(tenth_range_shift*0.7),\n",
    "      #r\"$\\mathbf{\\nu}$\",\n",
    "      r\"$\\nu$\",\n",
    "      fontsize=fontsize,\n",
    "      horizontalalignment='center',\n",
    "      verticalalignment='center',\n",
    "      #bbox=dict(boxstyle=\"tightbox,pad=0.,rounding_size=0.2,rescale=1.0\",\n",
    "      #  ec=(1., 1.0, 1.0),\n",
    "      #  fc=(1., 1.0, 1.0),\n",
    "      #  alpha=0.4),\n",
    "      )\n",
    "\n",
    "    curve_ax.plot(x_range, [0,0], color='k')\n",
    "    curve_ax.plot([0,0], y_range, color='k')\n",
    "    #curve_ax.set_xticks(x_range)\n",
    "    #curve_ax.set_yticks([0])\n",
    "    #curve_ax.set_yticks(y_range)\n",
    "    #curve_ax.tick_params(axis=\"both\", bottom=True, top=False, left=True, right=False)\n",
    "    #curve_ax.get_xaxis().set_visible(True)\n",
    "    #curve_ax.get_yaxis().set_visible(True)\n",
    "    #curve_ax.set_xticklabels(x_range, fontsize=fontsize)\n",
    "    #curve_ax.set_yticklabels(y_range, fontsize=fontsize)\n",
    "    \n",
    "    curve_ax.set_aspect(\"equal\")\n",
    "\n",
    "    #gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], wspace=0.0, hspace=0.5)#-0.55)\n",
    "    #target_vect_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "    #target_vect_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.target_neuron_ids[0]], cmap=\"Greys_r\")\n",
    "    #target_vect_ax.set_title(\"Primary\\nBasis Function\", color='r', fontsize=16)\n",
    "    #comparison_vect_ax = pf.clear_axis(fig.add_subplot(gs2[1]))\n",
    "    #comparison_vect_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.comparison_neuron_ids[0][0]], cmap=\"Greys_r\")\n",
    "    #comparison_vect_ax.set_title(\"Comparison\\nBasis Function\", color='k', fontsize=16)\n",
    "\n",
    "    analyzer_index += 1\n",
    "    \n",
    "  #cbar = pf.add_colorbar_to_ax(contsf, curve_ax, aspect=20, pad_fraction=0.5, labelsize=fontsize, ticks=[vmin, vmax])\n",
    "  #cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "  scalarMap._A = []\n",
    "  #aspect=((xmax-xmin)/(ymax-ymin))\n",
    "  #ax = pf.clear_axis(fig.add_subplot(gs0[0, -1]))\n",
    "  #TODO: Get y_id=0; y_id=-1 axis coordinates to calulate top & extent of colorbar\n",
    "  ax = pf.clear_axis(fig.add_axes([0.0, 0.33, 0.11, 0.70]))\n",
    "  cbar = ax.figure.colorbar(scalarMap, ax=ax, ticks=[vmin, vmax], aspect=10)\n",
    "  cbar.ax.tick_params(labelleft=True, labelright=False, left=True, right=False, labelsize=fontsize)\n",
    "  cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "  \n",
    "  plt.show()\n",
    "  for analyzer in analyzer_list:\n",
    "    fig.savefig(analyzer.analysis_out_dir+\"/vis/iso_contour_comparison\"+analyzer.analysis_params.save_info+\".eps\",\n",
    "      dpi=dpi, transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_indices = [0, 0, 0, 0]\n",
    "orth_indices = [0, 0, 0, 0]\n",
    "num_plots_y = 2\n",
    "num_plots_x = 2\n",
    "num_levels = 10\n",
    "\n",
    "fig = plot_goup_iso_contours(analyzer_list, neuron_indices, orth_indices, num_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvature histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_list = [lca_512_vh_params(), lca_768_vh_params(), lca_1024_vh_params()]\n",
    "params_list = [lca_768_mnist_params(), lca_1536_vh_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  run_params = np.load(analyzer.analysis_out_dir+\"savefiles/iso_params_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()\n",
    "  min_angle = run_params[\"min_angle\"]\n",
    "  max_angle = run_params[\"max_angle\"]\n",
    "  num_neurons = run_params[\"num_neurons\"]\n",
    "  use_bf_stats = run_params[\"use_bf_stats\"]\n",
    "  num_comparison_vectors = run_params[\"num_comparison_vects\"]\n",
    "  x_range = run_params[\"x_range\"]\n",
    "  y_range = run_params[\"y_range\"]\n",
    "  num_images = run_params[\"num_images\"]\n",
    "  analyzer.comp_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_activations_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"]\n",
    "  analyzer.comp_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_comp_contour_dataset_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()\n",
    "  analyzer.rand_activations = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_activations_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"]\n",
    "  analyzer.rand_contour_dataset = np.load(analyzer.analysis_out_dir+\"savefiles/iso_rand_contour_dataset_\"+analyzer.analysis_params.save_info+\".npz\")[\"data\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzer = analyzer_list[0]\n",
    "analyzer_neuron_index = 0\n",
    "y_start_index = 10 # set to 1/2 of sqrt(num_y_imgs) to use only positive quadrant\n",
    "slice_scale = 0.8\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.neuron_index = analyzer_neuron_index\n",
    "  analyzer.num_neurons = analyzer.bf_stats[\"num_outputs\"]\n",
    "  analyzer.num_pixels = analyzer.bf_stats[\"num_inputs\"]\n",
    "  \n",
    "  comp_x_pts = analyzer.comp_contour_dataset[\"x_pts\"]\n",
    "  rand_x_pts = analyzer.rand_contour_dataset[\"x_pts\"]\n",
    "  assert(np.all(comp_x_pts == rand_x_pts)) # This makes sure we don't need to recompute proj_datapoints for each case\n",
    "  num_x_imgs = len(comp_x_pts)\n",
    "  x_target = comp_x_pts[int(slice_scale * num_x_imgs)] # find a location to take a slice\n",
    "  proj_datapoints = analyzer.comp_contour_dataset[\"proj_datapoints\"]\n",
    "  slice_indices = np.where(proj_datapoints[:, 0] == x_target)[0]\n",
    "  analyzer.sliced_datapoints = proj_datapoints[slice_indices, :][y_start_index:, :] # slice grid\n",
    "  \n",
    "  analyzer.comp_curvatures = []\n",
    "  analyzer.comp_fits = []\n",
    "  analyzer.comp_sliced_activity = []\n",
    "  analyzer.rand_curvatures = []\n",
    "  analyzer.rand_fits = []\n",
    "  analyzer.rand_sliced_activity = []\n",
    "  for orth_index in range(analyzer.num_neurons-1):\n",
    "    comp_activity = analyzer.comp_activations[analyzer.neuron_index, orth_index, ...].reshape([-1])\n",
    "    analyzer.comp_sliced_activity.append(comp_activity[slice_indices][y_start_index:])\n",
    "    coeff = np.polynomial.polynomial.polyfit(analyzer.sliced_datapoints[:, 1],\n",
    "      analyzer.comp_sliced_activity[-1], deg=2) # [c0, c1, c2], where p = c0 + c1x + c2x^2\n",
    "    analyzer.comp_curvatures.append(coeff[2])\n",
    "    analyzer.comp_fits.append(np.polynomial.polynomial.polyval(analyzer.sliced_datapoints[:, 1], coeff))\n",
    "    \n",
    "  for orth_index in range(analyzer.num_pixels-1):\n",
    "    rand_activity = analyzer.rand_activations[analyzer.neuron_index, orth_index, ...].reshape([-1])\n",
    "    analyzer.rand_sliced_activity.append(rand_activity[slice_indices][y_start_index:])\n",
    "    coeff = np.polynomial.polynomial.polyfit(analyzer.sliced_datapoints[:, 1],\n",
    "      analyzer.rand_sliced_activity[-1], deg=2)\n",
    "    analyzer.rand_curvatures.append(coeff[2])\n",
    "    analyzer.rand_fits.append(np.polynomial.polynomial.polyval(analyzer.sliced_datapoints[:, 1], coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_alpha = 0.03\n",
    "for analyzer in analyzer_list:\n",
    "  fig = plt.figure(figsize=(figsize[0], 2*figsize[1]), dpi=dpi)\n",
    "  gs0 = gridspec.GridSpec(1, 2, hspace=0.0, wspace=0.5)\n",
    "  axes = [fig.add_subplot(gs0[idx]) for idx in range(2)]\n",
    "  for orth_index in range(analyzer.num_neurons-1):\n",
    "    #if comp_curvatures[orth_index] > 0:\n",
    "      axes[0].plot(analyzer.sliced_datapoints[:, 1], analyzer.comp_sliced_activity[orth_index],\n",
    "        color='b', alpha=line_alpha)\n",
    "  for orth_index in range(analyzer.num_pixels-1):\n",
    "    #if rand_curvatures[orth_index] > 0:\n",
    "      axes[1].plot(analyzer.sliced_datapoints[:, 1], analyzer.rand_sliced_activity[orth_index],\n",
    "        color='b', alpha=line_alpha)\n",
    "  for ax, title in zip(axes, [\"Basis Projection\", \"Random Projection\"]):\n",
    "    ax.set_title(title, y=1.05, fontsize=fontsize)\n",
    "    ax.set_ylabel(\"Normalized Activation\", fontsize=fontsize)\n",
    "    ax.set_xlabel(\"Distance from Basis Function\", fontsize=fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    x_vals = analyzer.sliced_datapoints[:,1]\n",
    "    ax.set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "      tick.label.set_fontsize(14) \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "      tick.label.set_fontsize(14) \n",
    "    ax.set_aspect((np.max(x_vals)-np.min(x_vals)))\n",
    "    ax.tick_params(labelsize=14)\n",
    "  fig.suptitle(\"Normalized Responses to Orthogonal Inputs\\n\"+analyzer.analysis_params.display_name,\n",
    "    y=0.63, x=0.5, fontsize=fontsize)\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/bf_curvatures_bf0id\"+str(analyzer.neuron_index)+\".eps\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_alpha = 0.05\n",
    "for analyzer in analyzer_list:\n",
    "  fig = plt.figure(figsize=(figsize[0], 2*figsize[1]), dpi=dpi)\n",
    "  gs0 = gridspec.GridSpec(1, 2, hspace=0.0, wspace=0.5)\n",
    "  axes = [fig.add_subplot(gs0[idx]) for idx in range(2)]\n",
    "  for orth_index in range(analyzer.num_neurons-1):\n",
    "    axes[0].plot(analyzer.sliced_datapoints[:,1], analyzer.comp_fits[orth_index], color='r', alpha=0.05)\n",
    "  for orth_index in range(analyzer.num_pixels-1):\n",
    "    axes[1].plot(analyzer.sliced_datapoints[:,1], analyzer.rand_fits[orth_index], color='r', alpha=0.05)\n",
    "  for ax, title in zip(axes, [\"Basis Projection\", \"Random Projection\"]):\n",
    "    ax.set_title(title, y=1.05, fontsize=fontsize)\n",
    "    ax.set_ylabel(\"Normalized Activation\", fontsize=fontsize)\n",
    "    ax.set_xlabel(\"Distance from Basis Function\", fontsize=fontsize)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    x_vals = analyzer.sliced_datapoints[:,1]\n",
    "    ax.set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "      tick.label.set_fontsize(14) \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "      tick.label.set_fontsize(14) \n",
    "    ax.set_aspect((np.max(x_vals)-np.min(x_vals)))\n",
    "    ax.tick_params(labelsize=14)\n",
    "  fig.suptitle(\"Polynomial Fit to Orthogonal Inputs\\n\"+analyzer.analysis_params.display_name,\n",
    "    y=0.63, x=0.5, fontsize=fontsize)\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/bf_fit_curvatures_bf0id\"+str(analyzer.neuron_index)+\".eps\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar_alpha = 0.3\n",
    "num_bins = 100\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  bins = np.linspace(np.amin(analyzer.comp_curvatures+analyzer.rand_curvatures),\n",
    "    np.amax(analyzer.comp_curvatures+analyzer.rand_curvatures), num_bins)\n",
    "  bar_width = np.diff(bins).min() #0.002\n",
    "  \n",
    "  comp_hist, bin_edges = np.histogram(analyzer.comp_curvatures, bins)\n",
    "  comp_hist = comp_hist / np.sum(comp_hist)\n",
    "  \n",
    "  rand_hist, _ = np.histogram(analyzer.rand_curvatures, bins)\n",
    "  rand_hist = rand_hist / np.sum(rand_hist)\n",
    "  \n",
    "  bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "  bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "  \n",
    "  fig, ax = plt.subplots(1, figsize=(figsize[0], figsize[1]), dpi=dpi)\n",
    "  \n",
    "  ax.bar(bin_centers, comp_hist, width=bar_width, log=False, color=\"r\", alpha=bar_alpha,\n",
    "    align=\"center\", label=\"Basis Projection\")\n",
    "  ax.bar(bin_centers, rand_hist, width=bar_width, log=False, color=\"b\", alpha=bar_alpha,\n",
    "    align=\"center\", label=\"Random Projection\")\n",
    "  \n",
    "  ax.set_ylim([0.0, 1.0])\n",
    "  ax.set_xticks(bin_left, minor=True)\n",
    "  #ax.set_xticks(bin_left[::10], minor=False)\n",
    "  ax.set_xticks([bin_left[0], bin_left[len(bin_left)//3], 0.0, bin_left[-1]], minor=False)\n",
    "  ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.3f\"))\n",
    "  for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(fontsize) \n",
    "  for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(fontsize) \n",
    "  \n",
    "  ax.set_title(\"Histogram of Curvatures\\n\"+analyzer.analysis_params.display_name, fontsize=fontsize)\n",
    "  #ax.set_xlabel(\"Second Order Polyfit Coefficient\\n(Negative Indicates Exo-Origin)\", fontsize=fontsize)\n",
    "  ax.set_xlabel(\"Curvature\", fontsize=fontsize)\n",
    "  ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  ax.legend(loc=2, fontsize=fontsize)\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/histogram_of_curvatures_bf0id\"+str(analyzer.neuron_index)+\".eps\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation Selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [rica_768_vh_params(), sae_768_vh_params(), lca_768_vh_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rads = []\n",
    "max_rads = []\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_spatial_freq_rads = [np.sqrt(x**2+y**2) for (y,x) in analyzer.bf_stats[\"fourier_centers\"]]\n",
    "  min_rads.append(np.min(analyzer.bf_spatial_freq_rads))\n",
    "  max_rads.append(np.max(analyzer.bf_spatial_freq_rads))\n",
    "  \n",
    "num_bins = 10\n",
    "min_rad = np.min(min_rads)\n",
    "max_rad = np.max(max_rads)\n",
    "bins = np.linspace(min_rad, max_rad, num_bins)\n",
    "fig, ax = plt.subplots(1, figsize=figsize, dpi=dpi)\n",
    "hist_max = []\n",
    "for analyzer in analyzer_list:\n",
    "  hist, bin_edges = np.histogram(analyzer.bf_spatial_freq_rads, bins, density=True)\n",
    "  bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "  bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "  \n",
    "  label = analyzer.model.params.model_type.upper() + \" \" + str(analyzer.model.get_num_latent())# + \" van Hateren\"\n",
    "  #label = re.sub(\"_\", \" \", analyzer.model_name)\n",
    "  ax.plot(bin_centers, hist, alpha=1.0, linestyle=\"-\", drawstyle=\"steps-mid\", label=label)\n",
    "  hist_max.append(np.max(hist))\n",
    "  \n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::4], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.0f\"))\n",
    "ax.tick_params(\"both\", labelsize=16)\n",
    "ax.set_xlim([min_rad, max_rad])\n",
    "ax.set_xticks([0, int(np.floor(max_rad/4)), int(2*np.floor(max_rad/4)),\n",
    "  int(3*np.floor(max_rad/4)), max_rad])\n",
    "ax.set_ylim([0, 0.6])\n",
    "ax.set_xlabel(\"Spatial Frequency\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Density\", fontsize=fontsize)\n",
    "ax.set_title(\"Neuron Weight Spatial Frequency Histogram\", fontsize=fontsize)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legend = ax.legend(handles, labels, fontsize=fontsize, ncol=3,\n",
    "  borderaxespad=0., bbox_to_anchor=[0.01, 0.99], fancybox=True, loc=\"upper left\")\n",
    "for line in legend.get_lines():\n",
    "  line.set_linewidth(3)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_heatmap_fig = pf.plot_weight_angle_heatmap(analyzer.plot_matrix, angle_min=0, angle_max=180,\n",
    "  title=\"Angles Between Neurons\", figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRAE Iso-Response Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [ae_deep_mnist_params()]#,lca_768_vh_params()]#, rica_768_vh_params(), sae_768_vh_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_angle = 20\n",
    "max_angle = 55\n",
    "num_neurons = 2 # How many neurons to plot\n",
    "use_bf_stats = True # If false, then use optimal stimulus\n",
    "num_comparison_vects = 10\n",
    "use_random_orth_vects = False\n",
    "x_range = [-2, 2]\n",
    "y_range = [-2, 2]\n",
    "num_images = int(10**2)\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  compute_iso_vectors(analyzer, min_angle, max_angle, num_neurons, use_bf_stats)\n",
    "  contour_dataset = get_contour_dataset(analyzer, num_comparison_vects,\n",
    "    use_random_orth_vects, x_range, y_range, num_images)\n",
    "  analyzer.activations = get_normalized_activations(analyzer, contour_dataset[\"datapoints\"])\n",
    "  contour_dataset.pop(\"datapoints\")\n",
    "  analyzer.contour_dataset = contour_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots_y = num_neurons + 1 # extra dimension for example image\n",
    "num_plots_x = num_neurons + 1 # extra dimension for example image\n",
    "\n",
    "gs0 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.1, hspace=0.1)\n",
    "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "orth_vectors = []\n",
    "for neuron_loop_index in range(num_neurons): # rows\n",
    "  for orth_loop_index in range(num_neurons): # columns\n",
    "    norm_activity = analyzer.activations[neuron_loop_index][orth_loop_index]\n",
    "    proj_target = analyzer.contour_dataset[\"proj_target_neuron\"][neuron_loop_index][orth_loop_index]\n",
    "    proj_comparison = analyzer.contour_dataset[\"proj_comparison_neuron\"][neuron_loop_index][orth_loop_index]\n",
    "    proj_orth = analyzer.contour_dataset[\"proj_orth_vect\"][neuron_loop_index][orth_loop_index]\n",
    "    orth_vectors.append(analyzer.contour_dataset[\"orth_vect\"][neuron_loop_index][orth_loop_index])\n",
    "\n",
    "    curve_plot_y_idx = neuron_loop_index + 1\n",
    "    curve_plot_x_idx = orth_loop_index + 1\n",
    "    curve_ax = pf.clear_axis(fig.add_subplot(gs0[curve_plot_y_idx, curve_plot_x_idx]))\n",
    "\n",
    "    # NOTE: each subplot has a renormalized color scale\n",
    "    # TODO: Add scale bar like in the lca inference plots\n",
    "    vmin = np.min(norm_activity)\n",
    "    vmax = np.max(norm_activity)\n",
    "\n",
    "    levels = 5\n",
    "    x_mesh, y_mesh = np.meshgrid(analyzer.contour_dataset[\"x_pts\"], analyzer.contour_dataset[\"y_pts\"])\n",
    "    contsf = curve_ax.contourf(x_mesh, y_mesh, norm_activity,\n",
    "      levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "\n",
    "    curve_ax.arrow(0, 0, proj_target[0].item(), proj_target[1].item(),\n",
    "      width=0.05, head_width=0.15, head_length=0.15, fc='r', ec='r')\n",
    "    curve_ax.arrow(0, 0, proj_comparison[0].item(), proj_comparison[1].item(),\n",
    "      width=0.05, head_width=0.15, head_length=0.15, fc='w', ec='w')\n",
    "    curve_ax.arrow(0, 0, proj_orth[0].item(), proj_orth[1].item(),\n",
    "      width=0.05, head_width=0.15, head_length=0.15, fc='k', ec='k')\n",
    "\n",
    "    curve_ax.set_xlim(x_range)\n",
    "    curve_ax.set_ylim(y_range)\n",
    "    \n",
    "for plot_y_id in range(num_plots_y):\n",
    "  for plot_x_id in range(num_plots_x):\n",
    "    if plot_y_id > 0 and plot_x_id == 0:\n",
    "      bf_ax = pf.clear_axis(fig.add_subplot(gs0[plot_y_id, plot_x_id]))\n",
    "      bf_resh = analyzer.target_vectors[plot_y_id-1].reshape((int(np.sqrt(np.prod(analyzer.model.params.data_shape))),\n",
    "        int(np.sqrt(np.prod(analyzer.model.params.data_shape)))))\n",
    "      bf_ax.imshow(bf_resh, cmap=\"Greys_r\")\n",
    "      if plot_y_id == 1:\n",
    "        bf_ax.set_title(\"Target vectors\", color=\"r\", fontsize=16)\n",
    "    if plot_y_id == 0 and plot_x_id > 0:\n",
    "      orth_img = orth_vectors[plot_x_id-1].reshape(int(np.sqrt(np.prod(analyzer.model.params.data_shape))),\n",
    "        int(np.sqrt(np.prod(analyzer.model.params.data_shape))))\n",
    "      orth_ax = pf.clear_axis(fig.add_subplot(gs0[plot_y_id, plot_x_id]))\n",
    "      orth_ax.imshow(orth_img, cmap=\"Greys_r\")\n",
    "      if plot_x_id == 1:\n",
    "        orth_ax.set_title(\"Orthogonal vectors\", color=\"k\", fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig(analyzer.analysis_out_dir+\"/vis/iso_contour_grid_04.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
