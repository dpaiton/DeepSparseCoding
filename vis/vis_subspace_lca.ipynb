{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                              \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import tensorflow as tf                                                         \n",
    "import data.data_selector as ds                                                   \n",
    "import analysis.analysis_picker as ap\n",
    "import utils.plot_functions as pf                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analysis_params(object):\n",
    "  model_type = \"lca_subspace\"\n",
    "  model_name = \"lca_subspace\"\n",
    "  version = \"0.0\"\n",
    "  save_info = \"analysis\"\n",
    "\n",
    "# Computed params\n",
    "analysis_params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+analysis_params.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LcaSubspaceAnalyzer' object has no attribute 'model_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-45637b0268fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalysis_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LcaSubspaceAnalyzer' object has no attribute 'model_params'"
     ]
    }
   ],
   "source": [
    "analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "analyzer.setup(analyzer.model_params)\n",
    "analyzer.load_analysis(save_info=analysis_params.save_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.get_data(analyzer.model_params)\n",
    "data = analyzer.model.preprocess_dataset(data, analyzer.model_params)\n",
    "data = analyzer.model.reshape_dataset(data, analyzer.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 10000#data[\"train\"].images.shape[0]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config, graph=analyzer.model.graph) as sess:\n",
    "  feed_dict = analyzer.model.get_feed_dict(data[\"train\"].images[0:num_imgs,...])\n",
    "  sess.run(analyzer.model.init_op, feed_dict)\n",
    "  analyzer.model.load_weights(sess, analyzer.cp_loc)\n",
    "  run_list = [analyzer.model.a, analyzer.model.group_activity, analyzer.model.group_angles]\n",
    "  neuron_activations, group_activations, group_angles = sess.run(run_list, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([np.nonzero(data[\"train\"].labels[label_index,:])[0].item()\n",
    "  for label_index in range(data[\"train\"].labels.shape[0])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rank groupings by label category\n",
    "# grab input samples where labels match a category\n",
    "# sort activations of groups for those samples with the most active first\n",
    "# compute mode of top groups\n",
    "# repeat, excluding previous mode\n",
    "\n",
    "#np.argwhere(labels==0)\n",
    "\n",
    "get_mode = lambda x : scipy.stats.mode(x)[0].item()\n",
    "\n",
    "# Need to exclude groups that were never active for this label\n",
    "\n",
    "#include_indices = np.arange(analyzer.model.num_groups, dtype=int) # startout looking across all groups\n",
    "#modes = []\n",
    "#for neuron_index in range(analyzer.model.num_groups):\n",
    "#  mode = get_mode([np.argsort(np.squeeze(group_activations)[batch_index, include_indices])[-1]\n",
    "#    for batch_index in np.argwhere(labels==0)])\n",
    "#  modes.append(mode)\n",
    "#  print(include_indices.size)\n",
    "#  include_indices = include_indices[include_indices!=mode]\n",
    "#print(modes)\n",
    "\n",
    "#get_mode([sorted_activations(group_activations[batch_index, include_indices])[0]\n",
    "#  for batch_index in np.argwhere(labels==0)])\n",
    "[np.argsort(np.squeeze(group_activations[batch_index,:]))[::-1]\n",
    "  for batch_index in np.argwhere(labels==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VanHateren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_group_activations = np.zeros_like(group_activations)\n",
    "for group_id in range(analyzer.model.num_groups):\n",
    "  cent_group_activations[:,group_id] = group_activations[:,group_id] - np.mean(group_activations[:,group_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cov = 1/num_imgs * np.dot(group_activations.T, group_activations)\n",
    "cov = 1/num_imgs * np.dot(np.squeeze(cent_group_activations).T, np.squeeze(cent_group_activations))\n",
    "np.fill_diagonal(cov, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cov, cmap=\"Greys_r\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "group_idx = 1\n",
    "num_bins = 1000\n",
    "figsize = None\n",
    "indiv_group_act = group_activations[:, group_idx]\n",
    "bins = np.linspace(np.min(indiv_group_act), np.max(indiv_group_act), num_bins)\n",
    "hist, bin_edges = np.histogram(indiv_group_act.flatten(), bins)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "fig, ax = plt.subplots(1, figsize=figsize)\n",
    "ax.bar(bin_centers, hist, width=2.0, log=True, align=\"center\")\n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::10], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.0f\"))\n",
    "ax.set_xlim([np.min(indiv_group_act), np.max(indiv_group_act)])\n",
    "ax.set_title(\"Group \"+str(group_idx))\n",
    "ax.set_xlabel(\"Activation\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(neuron_activations.size), neuron_activations.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(neuron_activations.flatten())/neuron_activations.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(group_angles), np.mean(group_angles), np.max(group_angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = analyzer.evals[\"weights/phi:0\"]\n",
    "active_idx = np.random.choice(analyzer.model.num_groups)\n",
    "group_activity_vector = np.zeros((1, analyzer.model.num_groups))\n",
    "group_activity_vector[0, active_idx] = 1\n",
    "group_direction = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct analysis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pf.plot_loc_freq_summary(analyzer.bf_stats)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"vis/location_frequency_centers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_angles = analyzer.neuron_angles(analyzer.bf_stats) * (180/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_hist_fig = pf.plot_weight_angle_histogram(neuron_angles, num_bins=50, angle_min=0, angle_max=180, figsize=(8,8))\n",
    "angle_hist_fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_angle_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_indices = np.stack([np.array(id_list) for id_list in analyzer.model.group_ids], axis=0)\n",
    "pooling_weights = np.stack([analyzer.evals[\"weights/phi:0\"][:, id_list] for id_list in analyzer.model.group_ids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_filter_id = 135#28\n",
    "input_id0 = 0\n",
    "input_id1 = 2\n",
    "bf_id0 = 331#weight_indices[pooling_filter_id, input_id0]\n",
    "bf_id1 = 645#weight_indices[pooling_filter_id, input_id1]\n",
    "print(\"BF indices = [\",bf_id0,\", \",bf_id1,\"]\")\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0] = pf.clear_axis(ax[0])\n",
    "ax[0].imshow(analyzer.bf_stats[\"basis_functions\"][bf_id0], cmap=\"Greys_r\")\n",
    "ax[0].set_title(str(bf_id0))\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][bf_id1], cmap=\"Greys_r\")\n",
    "ax[1].set_title(str(bf_id1))\n",
    "plt.show()\n",
    "print(\"vector angle\\t= \", neuron_angles[bf_id0, bf_id1], \" rad\\n\\t\\t= \", neuron_angles[bf_id0, bf_id1]*(180/np.pi), \" deg\")\n",
    "bf1 = analyzer.bf_stats[\"basis_functions\"][bf_id0].reshape((analyzer.model_params.patch_edge_size**2))\n",
    "bf2 = analyzer.bf_stats[\"basis_functions\"][bf_id1].reshape((analyzer.model_params.patch_edge_size**2))\n",
    "bf1_norm = np.linalg.norm(bf1)\n",
    "bf2_norm = np.linalg.norm(bf2)\n",
    "print(\"bf1 norm = \", bf1_norm)\n",
    "print(\"bf2 norm = \", bf2_norm)\n",
    "bf1 /= bf1_norm\n",
    "bf2 /= bf2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_processing as dp\n",
    "from data.dataset import Dataset\n",
    "num_imgs = 10000\n",
    "\n",
    "x_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "y_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "X, Y = np.meshgrid(x_pts, y_pts)\n",
    "proj_datapoints = np.stack([X.reshape(num_imgs), Y.reshape(num_imgs)], axis=1)\n",
    "\n",
    "proj_matrix, v = analyzer.bf_projections(bf1, bf2)\n",
    "proj_neuron1 = np.dot(proj_matrix, bf1).T\n",
    "proj_neuron2 = np.dot(proj_matrix, bf2).T\n",
    "proj_v = np.dot(proj_matrix, v).T\n",
    "\n",
    "datapoints = np.stack([np.dot(proj_matrix.T, proj_datapoints[data_id,:]) for data_id in range(num_imgs)]) #inject\n",
    "datapoints, orig_shape = dp.reshape_data(datapoints, flatten=False)[:2]\n",
    "datapoints = {\"test\": Dataset(datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "datapoints = analyzer.model.preprocess_dataset(datapoints,\n",
    "  params={\"whiten_data\":analyzer.model_params.whiten_data,\n",
    "  \"whiten_method\":analyzer.model_params.whiten_method})\n",
    "datapoints = analyzer.model.reshape_dataset(datapoints, analyzer.model_params)\n",
    "datapoints[\"test\"].images /= np.max(np.abs(datapoints[\"test\"].images))\n",
    "datapoints[\"test\"].images *= analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = analyzer.compute_pooled_activations(datapoints[\"test\"].images)\n",
    "activity_max = np.amax(np.abs(activations))\n",
    "norm_activity = activations / (activity_max+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "#def plot_iso_response_contours(cmap, save_filename)\n",
    "num_plots_y = 1\n",
    "num_plots_x = 2\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5, width_ratios=[4, 1])\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "#cmap = plt.get_cmap('tab20b')\n",
    "cmap = plt.get_cmap('viridis')\n",
    "#cmap = plt.get_cmap('jet')\n",
    "vmin = np.floor(np.min(norm_activity))#0.0\n",
    "vmax = np.ceil(np.max(norm_activity))#1.0\n",
    "rank_indices = np.argsort(norm_activity[:, pooling_filter_id])\n",
    "\n",
    "pts = curve_ax.scatter(proj_datapoints[:,0][rank_indices], proj_datapoints[:,1][rank_indices],\n",
    "  vmin=vmin, vmax=vmax, cmap=cmap, c=norm_activity[:, pooling_filter_id][rank_indices], s=5.0)\n",
    "curve_ax.arrow(0, 0, proj_neuron1[0].item(), proj_neuron1[1].item(), width=0.05, head_width=0.15,\n",
    "  head_length=0.15, fc='b', ec='b')\n",
    "curve_ax.arrow(0, 0, proj_neuron2[0].item(), proj_neuron2[1].item(), width=0.05, head_width=0.15,\n",
    "  head_length=0.15, fc='k', ec='k')\n",
    "#curve_ax.set_title(\"Angle = \"+\"{:.2f}\".format(neuron_angles[bf_id0, bf_id1])+\" deg\")\n",
    "curve_ax.set_title(\"Response from pooling neuron \"+\"{:.0f}\".format(pooling_filter_id))\n",
    "curve_ax.set_ylim([-2, 2.0])\n",
    "curve_ax.set_xlim([-2, 2.0])\n",
    "curve_ax.set_aspect(\"equal\")\n",
    "cbar = pf.add_colorbar_to_im(pts, aspect=20, pad_fraction=0.5, labelsize=16, ticks=[vmin, vmax])\n",
    "cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "\n",
    "gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], wspace=2, hspace=-0.2)\n",
    "bf1_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "bf1_ax.imshow(analyzer.bf_stats[\"basis_functions\"][bf_id0], cmap=\"Greys_r\")\n",
    "bf1_ax.set_title(\"Input\\nNeuron {:.0f}\".format(bf_id0), color='b')\n",
    "bf2_ax = pf.clear_axis(fig.add_subplot(gs2[1]))\n",
    "bf2_ax.imshow(analyzer.bf_stats[\"basis_functions\"][bf_id1], cmap=\"Greys_r\")\n",
    "bf2_ax.set_title(\"Input\\nNeuron {:.0f}\".format(bf_id1), color='k')\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/l2_neuron_response_contours_pid\"+str(pooling_filter_id)+\"_bf0id\"+str(bf_id0)+\"_bf1id\"+str(bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target = x_pts[int(6*np.sqrt(num_imgs)/8)] # find a location to take a slice\n",
    "slice_indices = np.where(proj_datapoints[:,0]==x_target)[0]\n",
    "x_vals = proj_datapoints[slice_indices,:][:,1] # slice grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_num_imgs = 100\n",
    "\n",
    "orthogonal_list = [idx for idx in range(analyzer.bf_stats[\"num_outputs\"]) if idx != bf_id0]#[bf_id1]\n",
    "num_orthogonal = len(orthogonal_list)\n",
    "\n",
    "pop_x_pts = np.linspace(-2.0, 2.0, int(pop_num_imgs))\n",
    "pop_y_pts = np.linspace(-2.0, 2.0, int(pop_num_imgs))\n",
    "pop_X, pop_Y = np.meshgrid(pop_x_pts, pop_y_pts)\n",
    "pop_proj_datapoints = np.stack([pop_X.reshape(pop_num_imgs**2), pop_Y.reshape(pop_num_imgs**2)], axis=1) # construct a grid\n",
    "x_target = pop_x_pts[int(6*pop_num_imgs/8)] # find a location to take a slice\n",
    "slice_indices = np.where(pop_proj_datapoints[:,0]==x_target)[0]\n",
    "pop_proj_datapoints = pop_proj_datapoints[slice_indices,:] # slice grid\n",
    "\n",
    "pop_datapoints = [None,]*num_orthogonal\n",
    "pop_proj_neurons = [None,]*num_orthogonal\n",
    "for pop_idx, tmp_bf_id1 in enumerate(orthogonal_list):\n",
    "  tmp_bf2 = analyzer.bf_stats[\"basis_functions\"][tmp_bf_id1].reshape((analyzer.model_params.patch_edge_size**2))\n",
    "  tmp_bf2 /= np.linalg.norm(tmp_bf2)\n",
    "  tmp_proj_matrix, tmp_proj_v = analyzer.bf_projections(bf1, tmp_bf2) \n",
    "  pop_proj_neurons[pop_idx] = (np.dot(tmp_proj_matrix, bf1).T, np.dot(tmp_proj_matrix, tmp_bf2).T)\n",
    "  pop_datapoints[pop_idx] = np.dot(pop_proj_datapoints, tmp_proj_matrix)#[slice_indices,:]\n",
    "\n",
    "pop_datapoints = np.reshape(np.stack(pop_datapoints, axis=0),\n",
    "  [num_orthogonal*pop_num_imgs, analyzer.model_params.patch_edge_size**2])\n",
    "\n",
    "pop_datapoints = dp.reshape_data(pop_datapoints, flatten=False)[0]\n",
    "pop_datapoints = {\"test\": Dataset(pop_datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "pop_datapoints = analyzer.model.preprocess_dataset(pop_datapoints,\n",
    "  params={\"whiten_data\":analyzer.model_params.whiten_data,\n",
    "  \"whiten_method\":analyzer.model_params.whiten_method})\n",
    "pop_datapoints = analyzer.model.reshape_dataset(pop_datapoints, analyzer.model_params)\n",
    "pop_datapoints[\"test\"].images /= np.max(np.abs(pop_datapoints[\"test\"].images))\n",
    "pop_datapoints[\"test\"].images *= analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_activations = analyzer.compute_pooled_activations(pop_datapoints[\"test\"].images)\n",
    "pop_activations = pop_activations.reshape([num_orthogonal, pop_num_imgs, analyzer.model.num_groups])[:,:,pooling_filter_id]\n",
    "pop_norm_activity = pop_activations / np.amax(np.abs(pop_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "for orthog_idx in range(num_orthogonal):\n",
    " ax.plot(pop_proj_datapoints[:,1], pop_norm_activity[orthog_idx, :], color='b', alpha=0.3)\n",
    "ax.set_title(\"Normalized Responses to Orthogonal Inputs\", y=1.08)\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0.0, 2.0])\n",
    "ax.set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "#ax.set_aspect((np.max(x_vals)-np.min(x_vals)))#/(np.max(pop_norm_activity)-np.min(pop_norm_activity)))\n",
    "ax.tick_params(labelsize=14)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/l2_bf_curvatures_pid\"+str(pooling_filter_id)+\"_bf0id\"+str(bf_id0)+\"_bf1id\"+str(bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = [np.polynomial.polynomial.polyfit(pop_proj_datapoints[:,1], pop_norm_activity[orthog_idx,:], deg=2)\n",
    "  for orthog_idx in range(num_orthogonal)]\n",
    "fits = [np.polynomial.polynomial.polyval(pop_proj_datapoints[:,1], coeff) for coeff in coeffs]\n",
    "curvatures = [np.polyder(fit, m=2) for fit in fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "for orthog_idx in range(num_orthogonal):\n",
    "  ax.plot(pop_proj_datapoints[:,1], fits[orthog_idx], color='r', alpha=0.3)\n",
    "ax.set_title(\"Polynomial Fit Responses to Orthogonal Inputs\", y=1.08)\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlim([np.min(pop_proj_datapoints[:,1]), np.max(pop_proj_datapoints[:,1])])\n",
    "ax.set_aspect((np.max(pop_proj_datapoints[:,1])-np.min(pop_proj_datapoints[:,1])))\n",
    "ax.tick_params(labelsize=14)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/l2_fit_curvatures_pid\"+str(pooling_filter_id)+\"_bf0id\"+str(bf_id0)+\"_bf1id\"+str(bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "curvatures = np.stack(coeffs, axis=0)[:,2]\n",
    "\n",
    "num_bins = 50\n",
    "bins = np.linspace(np.amin(curvatures), np.amax(curvatures), num_bins)\n",
    "hist, bin_edges = np.histogram(curvatures.flatten(), bins)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "ax.bar(bin_centers, hist, width=0.001, log=False, align=\"center\")\n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::8], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.2f\"))\n",
    "\n",
    "ax.set_title(\"Histogram of Curvatures for neuron \"+str(pooling_filter_id))\n",
    "ax.set_xlabel(\"Second Order Polyfit Coefficient\\n(Negative Indicates Exo-Origin)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/l2_histogram_of_curvatures_pid\"+str(pooling_filter_id)+\"_bf0id\"+str(bf_id0)+\"_bf1id\"+str(bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concavity = np.asarray([np.sign(coeffs[idx][2]) for idx in range(len(coeffs))])\n",
    "num_endo = np.sum(concavity>0)\n",
    "endo_indices = np.argwhere(concavity>0)\n",
    "num_exo = np.sum(concavity<0)\n",
    "exo_indices = np.argwhere(concavity<0)\n",
    "print(\"num >0 (tolerant/invariant/endo-origin):\", num_endo,\n",
    "  \"\\nnum <0 (selective/equivariant/exo-origin):\", num_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = np.argwhere(curvatures>0.08)\n",
    "high = np.argwhere(curvatures<0.09)\n",
    "np.intersect1d(list(low), list(high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthog_idx = 110\n",
    "curvatures[orthog_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.plot(pop_proj_datapoints[:,1], pop_norm_activity[orthog_idx, :], color='b', alpha=0.3)\n",
    "ax.set_title(\"Normalized Responses to Orthogonal Inputs\", y=1.08)\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax.grid(True)\n",
    "#ax.set_ylim([0.0, 1.0])\n",
    "#ax.set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "ax.set_aspect((np.max(x_vals)-np.min(x_vals)))#/(np.max(pop_norm_activity)-np.min(pop_norm_activity)))\n",
    "ax.tick_params(labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "for idx in endo_indices:\n",
    "  ax.plot(pop_proj_datapoints[:,1], fits[idx], color=\"g\", alpha=0.3)\n",
    "ax.set_title(\"Normalized Responses to Invariant Inputs\")\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlim([np.min(pop_proj_datapoints[:,1]), np.max(pop_proj_datapoints[:,1])])\n",
    "ax.set_aspect((np.max(pop_proj_datapoints[:,1])-np.min(pop_proj_datapoints[:,1])))\n",
    "ax.tick_params(labelsize=14)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/l2_fit_invariant_curvatures_pid\"+str(pooling_filter_id)+\"_bf0id\"+str(bf_id0)+\"_bf1id\"+str(bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
