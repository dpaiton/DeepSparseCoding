{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep net RAE attack\n",
    "\n",
    "deep net RAE iso-contours\n",
    "\n",
    "denoising VAE preprocessor + MLP vs LCA + MLP\n",
    "\n",
    "the single unit marzi attack\n",
    "\n",
    "----------------------------\n",
    "*network marzi attack*:\n",
    "* Orthogonal to Marzi Untargeted should be the best iso-response direction\n",
    "  * measure the curvature for all neurons in this direction\n",
    "  * give avg for the marzi untargeted orthogonal direction vs random directions\n",
    "\n",
    "*single layer marzi attack*:\n",
    "\n",
    "v: user-provided (possibly unit) vector\n",
    "\n",
    "a: activation vector of targeted layer\n",
    "\n",
    "$max |v^Ta - v^T \\tilde{a}|$\n",
    "\n",
    "single unit: $v = e_i$\n",
    "\n",
    "full layer: $v = \\frac{1}{\\sqrt(n)} \\mathbb{1}$ (ones vector)\n",
    "\n",
    "\n",
    "now we can do anything inbetween, e.g. attack only two neurons with high inner product\n",
    "inspired from deep dreem lucid framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap\n",
    "#from modules.recon_adversarial_module import ReconAdversarialModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "params_list = [ae_params(), lca_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.setup_model(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_type = \"train\"\n",
    "data = ds.get_data(analyzer_list[0].model_params)\n",
    "data = analyzer_list[0].model.preprocess_dataset(data, analyzer.model_params)\n",
    "data = analyzer_list[0].model.reshape_dataset(data, analyzer.model_params)\n",
    "data_min = data[dataset_type].images.min()\n",
    "data_max = data[dataset_type].images.max()\n",
    "dataset_size = data[dataset_type].images.shape[0]\n",
    "print(\"NUM DATA\", dataset_size, 'DATA MIN', data_min, 'DATA MAX', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = 5\n",
    "adv_id = 1\n",
    "\n",
    "all_adv_inputs = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == input_id])\n",
    "              \n",
    "all_adv_targets = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == adv_id])\n",
    "\n",
    "if all_adv_inputs.shape[0] > all_adv_targets.shape[0]:\n",
    "  all_adv_inputs = all_adv_inputs[:all_adv_targets.shape[0],...]\n",
    "else:\n",
    "  all_adv_targets = all_adv_targets[:all_adv_inputs.shape[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "adv_inputs = all_adv_inputs[img_id,...][None,...]\n",
    "adv_targets = all_adv_targets[img_id,...][None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(adv_inputs.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax = pf.clear_axis(axes[1])\n",
    "ax.imshow(adv_targets.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Adv target image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzer_list[0].analysis_params.adversarial_num_steps = int(1e2)\n",
    "#analyzer_list[0].analysis_params.adversarial_attack_method = \"kurakin_targeted\"\n",
    "#analyzer_list[0].analysis_params.adversarial_step_size = 1e-3\n",
    "\n",
    "analyzer_list[0].analysis_params.adversarial_max_change = 1\n",
    "\n",
    "#analyzer_list[0].analysis_params.adversarial_clip = False\n",
    "#analyzer_list[0].analysis_params.adversarial_clip_range = [0.0, 1.0]\n",
    "#analyzer_list[0].analysis_params.carlini_recon_mult = 2.6\n",
    "#analyzer_list[0].analysis_params.carlini_change_variable = True\n",
    "#analyzer_list[0].analysis_params.carlini_optimizer = \"sgd\"\n",
    "#analyzer_list[0].analysis_params.adversarial_save_int = 1\n",
    "  \n",
    "analyzer_list[0].model.reset_graph()\n",
    "analyzer_list[0].setup_model(analyzer_list[0].model_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feed_dict = analyzer_list[0].model.get_feed_dict(adv_inputs, is_test=True)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config, graph=analyzer_list[0].model.graph) as sess:\n",
    "  sess.run(analyzer_list[0].model.init_op, feed_dict)\n",
    "  analyzer_list[0].model.load_full_model(sess, analyzer_list[0].analysis_params.cp_loc)\n",
    "  tensors = [analyzer_list[0].model.reconstruction]\n",
    "  eval_list = sess.run(tensors, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6,6))\n",
    "ax = pf.clear_axis(ax)\n",
    "ax.imshow(eval_list[0].reshape(28,28), cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"recon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_recons = analyzer_list[0].evaluate_model(adv_inputs, [\"output/reconstruction:0\"])[\"output/reconstruction:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6,6))\n",
    "ax = pf.clear_axis(ax)\n",
    "ax.imshow(orig_recons.reshape(28,28), cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"recon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.adv_loss =  input_pert_loss + self.recon_mult * adv_recon_loss\n",
    "\n",
    "#AE\n",
    "params_list[0].adversarial_num_steps = int(1e2)\n",
    "params_list[0].adversarial_attack_method = \"kurakin_targeted\"#\"marzi_untargeted\"\n",
    "params_list[0].adversarial_step_size = 1e-3\n",
    "params_list[0].adversarial_max_change = None#0.3\n",
    "params_list[0].adversarial_clip = False\n",
    "params_list[0].adversarial_clip_range = [0.0, 1.0]\n",
    "params_list[0].carlini_recon_mult = 2.6\n",
    "params_list[0].carlini_change_variable = True\n",
    "params_list[0].carlini_optimizer = \"sgd\"\n",
    "params_list[0].adversarial_save_int = 1\n",
    "\n",
    "#LCA\n",
    "params_list[1].adversarial_num_steps = params_list[0].adversarial_num_steps#10\n",
    "params_list[1].adversarial_attack_method = params_list[0].adversarial_attack_method#\"carlini_targeted\"\n",
    "params_list[1].adversarial_step_size = params_list[0].adversarial_step_size#1e-5\n",
    "params_list[1].adversarial_max_change = params_list[0].adversarial_max_change#0.2\n",
    "params_list[1].adversarial_clip = params_list[0].adversarial_clip#False\n",
    "params_list[1].adversarial_clip_range = params_list[0].adversarial_clip_range#[0.0, 1.0]\n",
    "params_list[1].carlini_recon_mult = params_list[0].carlini_recon_mult#10\n",
    "params_list[1].carlini_change_variable = params_list[0].carlini_change_variable#True\n",
    "params_list[1].carlini_optimizer = params_list[0].carlini_optimizer#\"adam\"\n",
    "params_list[1].adversarial_save_int = params_list[0].adversarial_save_int#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.analysis_params.adversarial_num_steps = params.adversarial_num_steps\n",
    "  analyzer.analysis_params.adversarial_attack_method = params.adversarial_attack_method\n",
    "  analyzer.analysis_params.adversarial_step_size = params.adversarial_step_size\n",
    "  analyzer.analysis_params.adversarial_max_change = params.adversarial_max_change\n",
    "  analyzer.analysis_params.adversarial_clip = params.adversarial_clip\n",
    "  analyzer.analysis_params.adversarial_clip_range = params.adversarial_clip_range\n",
    "  analyzer.analysis_params.carlini_recon_mult = params.carlini_recon_mult\n",
    "  analyzer.analysis_params.carlini_change_variable = params.carlini_change_variable\n",
    "  analyzer.analysis_params.carlini_optimizer = params.carlini_optimizer\n",
    "  analyzer.analysis_params.adversarial_save_int = params.adversarial_save_int\n",
    "  analyzer.model.reset_graph()\n",
    "  analyzer.setup_model(analyzer.model_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_adversarial_images is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "all_recons is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "For Marzi attack, we need to compute original recons for every image\n",
    "\"\"\"\n",
    "for analyzer in analyzer_list:\n",
    "  orig_recons = analyzer.evaluate_model(adv_inputs, [\"output/reconstruction:0\"])[\"output/reconstruction:0\"]\n",
    "  #analyzer.steps, analyzer.all_adversarial_images, analyzer.all_recons, analyzer.distances = \\\n",
    "  #  analyzer.construct_recon_adversarial_stimulus(adv_inputs, adv_targets, orig_recons.copy())\n",
    "  #analyzer.all_adversarial_perturbations = []\n",
    "  #for recon_mult_idx, adv_image_list in enumerate(analyzer.all_adversarial_images):\n",
    "  #  analyzer.all_adversarial_perturbations.append([])\n",
    "  #  for step_idx, adv_images in enumerate(adv_image_list):\n",
    "  #    analyzer.all_adversarial_perturbations[recon_mult_idx].append(adv_images - adv_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzer_idx = 0\n",
    "batch_idx = 0\n",
    "step_idx = -1\n",
    "recon_idx = 0\n",
    "fig, axes = plt.subplots(1, 7, figsize=(20,4))\n",
    "\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(adv_inputs[batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\ninput image\")\n",
    "#ax = pf.clear_axis(axes[1])\n",
    "#ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][0][batch_idx,...].reshape(28,28),\n",
    "#  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "#ax.set_title(\"Original\\ninput image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[2])\n",
    "ax.imshow(orig_recons[batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\ninput recon image\")\n",
    "#ax = pf.clear_axis(axes[3])\n",
    "#ax.imshow(analyzer_list[analyzer_idx].all_recons[0][0][batch_idx,...].reshape(28,28),\n",
    "#  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "#ax.set_title(\"Original\\nrecon image\")\n",
    "#\n",
    "#ax = pf.clear_axis(axes[4])\n",
    "#ax.imshow(analyzer_list[analyzer_idx].all_adversarial_perturbations[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "#  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "#ax.set_title(\"Adversarial\\nperturbation image\")\n",
    "#\n",
    "#ax = pf.clear_axis(axes[5])\n",
    "#ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "#  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "#ax.set_title(\"Adversarial\\ninput image\")\n",
    "#\n",
    "#ax = pf.clear_axis(axes[6])\n",
    "#ax.imshow(analyzer_list[analyzer_idx].all_recons[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "#  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "#ax.set_title(\"Adversarial\\nrecon image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These mses are in shape [num_recon_mults, num_iterations, num_batch]\n",
    "fig, ax = plt.subplots(1, figsize=(4,4))\n",
    "\n",
    "offset = 1\n",
    "steps = analyzer_list[analyzer_idx].steps[offset:]\n",
    "\n",
    "ax.plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_adv_mses\"])[recon_idx, offset:, batch_idx],\n",
    "  label='input to perturbed', color='r')\n",
    "\n",
    "#ax.plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"target_adv_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='target to perturbed', color='b')\n",
    "\n",
    "#ax.plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"target_recon_mses\"])[recon_idx, offset:, batch_idx],\n",
    "#  label='target to recon', color='g')\n",
    "\n",
    "#ax.plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"adv_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='perturbed to recon', color='k')\n",
    "\n",
    "ax.plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "  label='input to recon', color='c')\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1.42, 0.86))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "similarities = []\n",
    "for analyzer in analyzer_list:\n",
    "  similarities.append(analyzer.adversarial_target_adv_cos_similarities[0][-1])\n",
    "min_dist = np.minimum(0.0, np.min(similarities))\n",
    "max_dist = np.maximum(1.0, np.max(similarities))\n",
    "bins = np.linspace(min_dist, max_dist, num_bins)\n",
    "fontsize = 18\n",
    "line_alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "for analyzer_idx, analyzer in enumerate(analyzer_list):\n",
    "  cos_similarity = similarities[analyzer_idx]\n",
    "  analyzer.dist_hist, bin_edges = np.histogram(cos_similarity, bins=bins)\n",
    "  bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "  bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "  \n",
    "for analyzer_idx, analyzer in enumerate(analyzer_list):\n",
    "  analyzer.dist_hist = analyzer.dist_hist / np.max([analyzer.dist_hist for analyzer in analyzer_list])\n",
    "  ax.plot(bin_left, analyzer.dist_hist, alpha=line_alpha, linestyle=\"--\", #color = 'k',\n",
    "    drawstyle=\"steps-mid\", label=analyzer.model_params.model_type.upper())\n",
    "  \n",
    "title = (\"Cosine Similarity Between Target Image and Perturbation\")\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "ax.legend(fontsize=fontsize, fancybox=True, shadow=True, bbox_to_anchor=(0.8, 0.8))\n",
    "plt.show()\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/cosyne_similarity.png\", transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = similarities[1] - similarities[0]\n",
    "\n",
    "bins = np.linspace(np.min(diff_list), np.max(diff_list), num_bins)\n",
    "dist_hist, bin_edges = np.histogram(diff_list, bins=bins)\n",
    "dist_hist = dist_hist / np.max(dist_hist)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "ax.bar(bin_centers, dist_hist, width=bin_right-bin_left, edgecolor='k')\n",
    "ax.set_xlabel(\"\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  \n",
    "title = (\"Difference between Cosine Similarity Between Target Image and Perturbation\")\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity Difference\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...] == 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
