{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAE untargeted Marzi attack\n",
    "\n",
    "latent marzi attack\n",
    "\n",
    "deep net RAE attack\n",
    "\n",
    "deep net RAE iso-contours\n",
    "\n",
    "denoising VAE preprocessor + MLP vs LCA + MLP\n",
    "\n",
    "----------------------------\n",
    "*network marzi attack*:\n",
    "* Orthogonal to Marzi Untargeted should be the best iso-response direction\n",
    "  * measure the curvature for all neurons in this direction\n",
    "  * give avg for the marzi untargeted orthogonal direction vs random directions\n",
    "\n",
    "*single unit marzi attack*:\n",
    "\n",
    "v: user-provided (possibly unit) vector\n",
    "\n",
    "a: activation vector of targeted layer\n",
    "\n",
    "$max |v^Ta - v^T \\tilde{a}|$\n",
    "\n",
    "single unit: $v = e_i$\n",
    "\n",
    "full layer: $v = \\frac{1}{\\sqrt(n)} \\mathbb{1}$ (ones vector)\n",
    "\n",
    "\n",
    "now we can do anything inbetween, e.g. attack only two neurons with high inner product\n",
    "inspired from deep dreem lucid framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap\n",
    "#from modules.recon_adversarial_module import ReconAdversarialModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "    \n",
    "class sae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "params_list = [ae_params(), sae_params(), lca_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.setup_model(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_type = \"train\"\n",
    "data = ds.get_data(analyzer_list[0].model_params)\n",
    "data = analyzer_list[0].model.preprocess_dataset(data, analyzer.model_params)\n",
    "data = analyzer_list[0].model.reshape_dataset(data, analyzer.model_params)\n",
    "data_min = data[dataset_type].images.min()\n",
    "data_max = data[dataset_type].images.max()\n",
    "dataset_size = data[dataset_type].images.shape[0]\n",
    "print(\"NUM DATA\", dataset_size, 'DATA MIN', data_min, 'DATA MAX', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = 5\n",
    "adv_id = 1\n",
    "\n",
    "all_adv_inputs = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == input_id])\n",
    "              \n",
    "all_adv_targets = np.stack([data[dataset_type].images[img_id,...]\n",
    "  for img_id in range(dataset_size)\n",
    "  if dp.one_hot_to_dense(data[dataset_type].labels[img_id][None,...]) == adv_id])\n",
    "\n",
    "if all_adv_inputs.shape[0] > all_adv_targets.shape[0]:\n",
    "  all_adv_inputs = all_adv_inputs[:all_adv_targets.shape[0],...]\n",
    "else:\n",
    "  all_adv_targets = all_adv_targets[:all_adv_inputs.shape[0],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "adv_inputs = all_adv_inputs[img_id,...][None,...]\n",
    "adv_targets = all_adv_targets[img_id,...][None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(adv_inputs.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax = pf.clear_axis(axes[1])\n",
    "ax.imshow(adv_targets.reshape(28,28), cmap=\"Greys_r\")\n",
    "ax.set_title(\"Adv target image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carlini_adv_loss =  input_pert_loss + recon_mult * adv_recon_loss\n",
    "\n",
    "for params in params_list:\n",
    "  params.adversarial_num_steps = int(5e4)\n",
    "  params.adversarial_attack_method = \"marzi_untargeted\"\n",
    "  params.adversarial_step_size = 1e-4\n",
    "  params.adversarial_max_change = 0.3\n",
    "  params.adversarial_clip = True\n",
    "  params.adversarial_clip_range = [0.0, 1.0]\n",
    "  params.carlini_recon_mult = 100.0\n",
    "  params.carlini_change_variable = False\n",
    "  params.optimizer = \"sgd\"\n",
    "  params.adversarial_save_int = 1\n",
    "  #TODO: compute this\n",
    "  #params.selection_vector = np.zeros(768)\n",
    "  #params.selection_vector[17] = 1\n",
    "\n",
    "#LCA\n",
    "#params_list[1].adversarial_num_steps = params_list[0].adversarial_num_steps\n",
    "#params_list[1].adversarial_attack_method = params_list[0].adversarial_attack_method\n",
    "#params_list[1].adversarial_step_size = params_list[0].adversarial_step_size#1e-3\n",
    "#params_list[1].adversarial_max_change = params_list[0].adversarial_max_change\n",
    "#params_list[1].adversarial_clip = params_list[0].adversarial_clip\n",
    "#params_list[1].adversarial_clip_range = params_list[0].adversarial_clip_range\n",
    "#params_list[1].carlini_recon_mult = params_list[0].carlini_recon_mult\n",
    "#params_list[1].carlini_change_variable = params_list[0].carlini_change_variable\n",
    "#params_list[1].optimizer = params_list[0].optimizer\n",
    "#params_list[1].adversarial_save_int = params_list[0].adversarial_save_int\n",
    "#TODO: compute this\n",
    "#params_list[1].selection_vector = np.zeros(768)\n",
    "#params_list[1].selection_vector[17] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.analysis_params.adversarial_num_steps = params.adversarial_num_steps\n",
    "  analyzer.analysis_params.adversarial_attack_method = params.adversarial_attack_method\n",
    "  analyzer.analysis_params.adversarial_step_size = params.adversarial_step_size\n",
    "  analyzer.analysis_params.adversarial_max_change = params.adversarial_max_change\n",
    "  analyzer.analysis_params.adversarial_clip = params.adversarial_clip\n",
    "  analyzer.analysis_params.adversarial_clip_range = params.adversarial_clip_range\n",
    "  analyzer.analysis_params.carlini_recon_mult = params.carlini_recon_mult\n",
    "  analyzer.analysis_params.carlini_change_variable = params.carlini_change_variable\n",
    "  analyzer.analysis_params.optimizer = params.optimizer\n",
    "  analyzer.analysis_params.adversarial_save_int = params.adversarial_save_int\n",
    "  #TODO:How to get access to the number of latent neurons in the model?\n",
    "  #analyzer.analysis_params.selection_vector = params.selection_vector\n",
    "\n",
    "  analyzer.model.reset_graph()\n",
    "  analyzer.setup_model(analyzer.model_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_adversarial_images is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "all_recons is a nested list [num_recon_mults][num_steps] and then an ndarray of shape (1, 784)\n",
    "For Marzi attack, we need to compute original recons for every image\n",
    "\"\"\"\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.steps, analyzer.all_adversarial_images, analyzer.all_recons, analyzer.distances = \\\n",
    "    analyzer.construct_recon_adversarial_stimulus(adv_inputs, adv_targets)\n",
    "  analyzer.all_adversarial_perturbations = []\n",
    "  for recon_mult_idx, adv_image_list in enumerate(analyzer.all_adversarial_images):\n",
    "    analyzer.all_adversarial_perturbations.append([])\n",
    "    for step_idx, adv_images in enumerate(adv_image_list):\n",
    "      analyzer.all_adversarial_perturbations[recon_mult_idx].append(adv_images - adv_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzer_idx = 1\n",
    "batch_idx = 0\n",
    "step_idx = -1\n",
    "recon_idx = 0\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20,4))\n",
    "\n",
    "ax = pf.clear_axis(axes[0])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][0][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\ninput image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[1])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_recons[0][0][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Original\\nrecon image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[2])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_perturbations[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\nperturbation image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[3])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\ninput image\")\n",
    "\n",
    "ax = pf.clear_axis(axes[4])\n",
    "ax.imshow(analyzer_list[analyzer_idx].all_recons[0][step_idx][batch_idx,...].reshape(28,28),\n",
    "  cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
    "ax.set_title(\"Adversarial\\nrecon image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These mses are in shape [num_recon_mults, num_iterations, num_batch]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "offset = 0\n",
    "steps = analyzer_list[analyzer_idx].steps[offset:]\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_adv_mses\"])[recon_idx, offset:, batch_idx],\n",
    "  label='input to perturbed', color='r')\n",
    "\n",
    "#ax[0].plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"target_adv_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='target to perturbed', color='b')\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"target_recon_mses\"])[recon_idx, offset:, batch_idx],\n",
    "  label='target to recon', color='g')\n",
    "\n",
    "#ax[0].plot(steps,\n",
    "#  np.array(analyzer_list[analyzer_idx].distances[\"adv_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "#  label='perturbed to recon', color='k')\n",
    "\n",
    "ax[0].plot(steps,\n",
    "  np.array(analyzer_list[analyzer_idx].distances[\"input_recon_mses\"])[recon_idx, :, batch_idx][offset:],\n",
    "  label='input to recon', color='c')\n",
    "\n",
    "ax[1].plot(steps, analyzer_list[analyzer_idx].distances[\"adv_loss\"][recon_idx][offset:], label=\"Adversarial Loss\")\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.845, 0.855))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = similarities[1] - similarities[0]\n",
    "\n",
    "bins = np.linspace(np.min(diff_list), np.max(diff_list), num_bins)\n",
    "dist_hist, bin_edges = np.histogram(diff_list, bins=bins)\n",
    "dist_hist = dist_hist / np.max(dist_hist)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "ax.bar(bin_centers, dist_hist, width=bin_right-bin_left, edgecolor='k')\n",
    "ax.set_xlabel(\"\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  \n",
    "title = (\"Difference between Cosine Similarity Between Target Image and Perturbation\")\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity Difference\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...] == 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(analyzer_list[analyzer_idx].all_adversarial_images[0][step_idx][batch_idx,...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
