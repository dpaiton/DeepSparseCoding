{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"mlp\"\n",
    "    self.model_name = \"mlp_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_deep_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_deep_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "params_list = [ae_deep_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)\n",
    "  \n",
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.setup_model(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name\n",
    "  analyzer.analysis_params.do_recon_adversaries = False\n",
    "  analyzer.analysis_params.do_class_adversaries = False\n",
    "  analyzer.analysis_params.do_neuron_visualization = True\n",
    "  analyzer.vis_data = np.random.normal(loc=0.0, scale=1e-2, size=analyzer.model.get_input_shape()[1:])\n",
    "  analyzer.vis_data /= np.linalg.norm(analyzer.vis_data)\n",
    "  analyzer.vis_data[analyzer.vis_data > 1.0] = 1.0\n",
    "  analyzer.vis_data[analyzer.vis_data < 0.0] = 0.0\n",
    "  analyzer.vis_data = analyzer.vis_data[None,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for params in params_list:\n",
    "  params.neuron_vis_num_steps = int(2e5)#int(7.5e5)\n",
    "  params.neuron_vis_step_size = 1e-4\n",
    "  params.neuron_vis_save_int = 100\n",
    "  params.neuron_vis_clip = True\n",
    "  params.neuron_vis_clip_range = [0.0, 1.0]\n",
    "  params.neuron_vis_method = \"erhan\"\n",
    "  params.neuron_vis_norm_magnitude = None#1.0\n",
    "  params.neuron_vis_l2_regularize_coeff = 0.001\n",
    "  params.neuron_vis_variation_coeff = 0.005\n",
    "  params.neuron_vis_optimizer = \"sgd\"\n",
    "  params.neuron_vis_target_layer_idx = 3\n",
    "  params.neuron_vis_target_neuron_idx = 2\n",
    "  params.neuron_vis_selection_vector = np.zeros(64)\n",
    "  params.neuron_vis_selection_vector[params.neuron_vis_target_neuron_idx] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.analysis_params.neuron_vis_num_steps = params.neuron_vis_num_steps\n",
    "  analyzer.analysis_params.neuron_vis_step_size = params.neuron_vis_step_size\n",
    "  analyzer.analysis_params.neuron_vis_save_int = params.neuron_vis_save_int\n",
    "  analyzer.analysis_params.neuron_vis_method = params.neuron_vis_method\n",
    "  analyzer.analysis_params.neuron_vis_clip = params.neuron_vis_clip\n",
    "  analyzer.analysis_params.neuron_vis_clip_range = params.neuron_vis_clip_range\n",
    "  analyzer.analysis_params.neuron_vis_norm_magnitude = params.neuron_vis_norm_magnitude\n",
    "  analyzer.analysis_params.neuron_vis_l2_regularize_coeff = params.neuron_vis_l2_regularize_coeff\n",
    "  analyzer.analysis_params.neuron_vis_variation_coeff = params.neuron_vis_variation_coeff\n",
    "  analyzer.analysis_params.neuron_vis_optimizer = params.neuron_vis_optimizer\n",
    "  analyzer.analysis_params.neuron_vis_target_neuron_id = params.neuron_vis_target_neuron_idx\n",
    "  analyzer.analysis_params.neuron_vis_target_layer_idx = params.neuron_vis_target_layer_idx\n",
    "  analyzer.analysis_params.neuron_vis_selection_vector = params.neuron_vis_selection_vector\n",
    "\n",
    "  analyzer.model.reset_graph()\n",
    "  analyzer.setup_model(analyzer.model_params) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.optimal_stim_output = analyzer.construct_optimal_stimulus(analyzer.vis_data)\n",
    "  bf0 = np.squeeze(analyzer.optimal_stim_output[\"images\"][-1][0,...])\n",
    "  analyzer.bf0 = bf0 / np.linalg.norm(bf0, ord=2, keepdims=False)\n",
    "  analyzer.bf_id0 = params_list[0].neuron_vis_target_neuron_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.setup_model(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  pre_images = np.stack([analyzer.neuron_vis_output[\"optimal_stims\"][target_id][-1].reshape(28,28)\n",
    "    for target_id in range(len(analyzer.analysis_params.neuron_vis_targets))], axis=0)\n",
    "  pre_image_fig = pf.plot_weights(pre_images, title=analyzer.model_name+\" pre-images\", figsize=(4,8))\n",
    "  pre_image_fig.savefig(analyzer.analysis_out_dir+\"/vis/pre_images.png\",\n",
    "      transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_neuron_idx = 0\n",
    "step_idx = -1\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_id0 = target_neuron_idx\n",
    "  analyzer.bf0 = analyzer.neuron_vis_output[\"optimal_stims\"][analyzer.bf_id0][step_idx]\n",
    "  analyzer.bf0 = analyzer.bf0.reshape(np.prod(analyzer.model.get_input_shape()[1:]))\n",
    "  analyzer.bf0 = analyzer.bf0 / np.linalg.norm(analyzer.bf0)\n",
    "  \n",
    "  fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "  \n",
    "  ax = pf.clear_axis(axes[0])\n",
    "  ax.imshow(analyzer.bf0.reshape(28, 28), cmap=\"Greys_r\")#, vmin=0.0, vmax=1.0)\n",
    "  ax.set_title(\"Optimal\\ninput image\")\n",
    "  \n",
    "  axes[1].plot(analyzer.neuron_vis_output[\"loss\"][analyzer.bf_id0])\n",
    "  axes[1].set_title(\"Optimization loss\")\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orth(matrix):\n",
    "  rand_vect = np.random.rand(matrix.shape[0], 1)\n",
    "  new_matrix = np.hstack((matrix, rand_vect))\n",
    "  candidate_vect = np.zeros(matrix.shape[1]+1)\n",
    "  candidate_vect[-1] = 1\n",
    "  orth_vect = np.linalg.lstsq(new_matrix.T, candidate_vect, rcond=None)[0]\n",
    "  orth_vect = np.squeeze((orth_vect  / np.linalg.norm(orth_vect)).T) \n",
    "  return orth_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.orth_col_matrix = analyzer.bf0.T[:,None]\n",
    "  analyzer.rand_num_orthogonal = np.prod(analyzer.model.get_input_shape()[1:])-1\n",
    "\n",
    "  for pop_idx in range(analyzer.rand_num_orthogonal):\n",
    "    v = find_orth(analyzer.orth_col_matrix)\n",
    "    analyzer.orth_col_matrix = np.append(analyzer.orth_col_matrix, v[:,None], axis=1)\n",
    "\n",
    "  if all(np.abs(np.dot(analyzer.bf0, col)) < 1e-9 for col in analyzer.orth_col_matrix[:,1:].T):\n",
    "    print(\"Success\")\n",
    "  else:\n",
    "    count = np.sum([int(np.abs(np.dot(analyzer.bf0, col)) < 1e-9) for col in analyzer.orth_col_matrix[:,1:].T])\n",
    "    print(\"Failure,\", count, \"were non-orthogonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_norm_activity(analyzer, target_neuron_idx, num_rand_orthogonal, orthogonal_idx, num_imgs):\n",
    "  # Get target neuron pre-image\n",
    "  analyzer.bf_id0 = target_neuron_idx\n",
    "  analyzer.bf0 = analyzer.neuron_vis_output[\"optimal_stims\"][analyzer.bf_id0][step_idx]\n",
    "  analyzer.bf0 = analyzer.bf0.reshape(np.prod(analyzer.model.get_input_shape()[1:]))\n",
    "  analyzer.bf0 = analyzer.bf0 / np.linalg.norm(analyzer.bf0)\n",
    "\n",
    "  # Get orthogonal vectors\n",
    "  orth_col_matrix = analyzer.bf0.T[:,None]\n",
    "  for pop_idx in range(num_rand_orthogonal):\n",
    "    v = find_orth(orth_col_matrix)\n",
    "    orth_col_matrix = np.append(orth_col_matrix, v[:,None], axis=1)\n",
    "\n",
    "  # Construct image dataset\n",
    "  x_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "  y_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "  X_mesh, Y_mesh = np.meshgrid(x_pts, y_pts)\n",
    "  analyzer.proj_datapoints = np.stack([X_mesh.reshape(num_imgs), Y_mesh.reshape(num_imgs)], axis=1)\n",
    "  \n",
    "  proj_matrix, v = analyzer.bf_projections(analyzer.bf0, np.squeeze(orth_col_matrix[:, orthogonal_idx]))\n",
    "  analyzer.proj_neuron0 = np.dot(proj_matrix, analyzer.bf0).T\n",
    "  analyzer.proj_neuron1 = np.dot(proj_matrix, np.squeeze(orth_col_matrix[:, orthogonal_idx])).T\n",
    "  \n",
    "  datapoints = np.stack([np.dot(proj_matrix.T, analyzer.proj_datapoints[data_id,:])\n",
    "    for data_id in range(num_imgs)]) #inject\n",
    "  datapoints, orig_shape = dp.reshape_data(datapoints, flatten=False)[:2]\n",
    "  datapoints = {\"test\": Dataset(datapoints, lbls=None,\n",
    "    ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "  params={\"whiten_data\":analyzer.model_params.whiten_data}\n",
    "  if params[\"whiten_data\"]:\n",
    "    params[\"whiten_method\"] = analyzer.model_params.whiten_method\n",
    "  datapoints = analyzer.model.preprocess_dataset(datapoints, params=params)\n",
    "  datapoints = analyzer.model.reshape_dataset(datapoints, analyzer.model_params)\n",
    "  datapoints[\"test\"].images /= np.max(np.abs(datapoints[\"test\"].images))\n",
    "  datapoints[\"test\"].images *= analyzer.analysis_params.input_scale\n",
    "  \n",
    "  activations = analyzer.compute_activations(datapoints[\"test\"].images)#, batch_size=num_imgs//16)\n",
    "  activity_max = np.amax(np.abs(activations))\n",
    "  analyzer.norm_activity = activations / (activity_max + 0.00001) # Rescale between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rand_orthogonal = np.prod(analyzer.model.get_input_shape()[1:])\n",
    "set_norm_activity(\n",
    "  analyzer=analyzer_list[0],\n",
    "  target_neuron_idx=0,#np.random.choice(range(analyzer.model.get_num_latent()), 1),\n",
    "  num_rand_orthogonal=num_rand_orthogonal,\n",
    "  orthogonal_idx=np.random.choice(range(1, num_rand_orthogonal), 1),\n",
    "  num_imgs=int(228**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  num_plots_y = 1\n",
    "  num_plots_x = 2\n",
    "  gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.3, width_ratios=[4, 1])\n",
    "  fig = plt.figure(figsize=(6,6))\n",
    "  curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "  #cmap = plt.get_cmap('tab20b')\n",
    "  cmap = plt.get_cmap('viridis')\n",
    "  vmin = np.floor(np.min(analyzer.norm_activity))#0.0\n",
    "  vmax = np.ceil(np.max(analyzer.norm_activity))#1.0\n",
    "  \n",
    "  #name_suffix = \"continuous\"\n",
    "  #pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1],\n",
    "  #  vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.5, c=analyzer.norm_activity[:, analyzer.bf_id0], s=5.0)\n",
    "  \n",
    "  norm_activity = analyzer.norm_activity[:, analyzer.bf_id0]\n",
    "  norm_activity = norm_activity.reshape(int(np.sqrt(num_imgs)), int(np.sqrt(num_imgs)))\n",
    "  \n",
    "  levels = 5\n",
    "  name_suffix = \"\"\n",
    "  contsf = curve_ax.contourf(X_mesh, Y_mesh, norm_activity,\n",
    "    levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "  \n",
    "  curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='r', ec='r')\n",
    "  curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(), analyzer.proj_neuron1[1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='w', ec='k')\n",
    "  \n",
    "  curve_ax.set_ylim([-2, 2.0])\n",
    "  curve_ax.set_xlim([-2, 2.0])\n",
    "  curve_ax.set_aspect(\"equal\")\n",
    "  curve_ax.set_title(\"Neuron ID \"+str(analyzer.bf_id0))\n",
    "  \n",
    "  gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], hspace=-0.5)\n",
    "  bf1_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "  bf1_ax.imshow(analyzer.neuron_vis_output[\"optimal_stims\"][analyzer.bf_id0][step_idx].reshape((28,28)),\n",
    "    cmap=\"Greys_r\")\n",
    "  bf1_ax.set_title(\"Primary\\n Stimulus\", color='r', fontsize=16)\n",
    "  \n",
    "  activity_ax = fig.add_subplot(gs2[1])\n",
    "  activity_ax.plot(norm_activity[0,:], color='k')\n",
    "  activity_ax.set_aspect(1.0/activity_ax.get_data_ratio())\n",
    "  activity_ax.set_title(\"Activity along\\nstimulus vector\")\n",
    "  \n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_response_contours_bf0id\"+str(analyzer.bf_id0)+name_suffix+\".png\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 5\n",
    "num_orth_directions = 8\n",
    "\n",
    "\n",
    "num_plots_y = 1\n",
    "num_plots_x = 2\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.3, width_ratios=[4, 1])\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "#cmap = plt.get_cmap('tab20b')\n",
    "cmap = plt.get_cmap('viridis')\n",
    "vmin = np.floor(np.min(analyzer.norm_activity))#0.0\n",
    "vmax = np.ceil(np.max(analyzer.norm_activity))#1.0\n",
    "\n",
    "#name_suffix = \"continuous\"\n",
    "#pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1],\n",
    "#  vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.5, c=analyzer.norm_activity[:, analyzer.bf_id0], s=5.0)\n",
    "\n",
    "norm_activity = analyzer.norm_activity[:, analyzer.bf_id0]\n",
    "norm_activity = norm_activity.reshape(int(np.sqrt(num_imgs)), int(np.sqrt(num_imgs)))\n",
    "\n",
    "levels = 5\n",
    "name_suffix = \"\"\n",
    "contsf = curve_ax.contourf(X_mesh, Y_mesh, norm_activity,\n",
    "  levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "\n",
    "curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(),\n",
    "  width=0.05, head_width=0.15, head_length=0.15, fc='r', ec='r')\n",
    "curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(), analyzer.proj_neuron1[1].item(),\n",
    "  width=0.05, head_width=0.15, head_length=0.15, fc='w', ec='k')\n",
    "\n",
    "curve_ax.set_ylim([-2, 2.0])\n",
    "curve_ax.set_xlim([-2, 2.0])\n",
    "curve_ax.set_aspect(\"equal\")\n",
    "curve_ax.set_title(\"Neuron ID \"+str(analyzer.bf_id0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Compute a unit vector that is in the same plane as a given basis function pair (B1,B2) and is orthogonal to B1, where B1 is the target basis for comparison and B2 is selected from all other bases.\n",
    "* Construct a line of data points in this plane\n",
    "* Project the data points into image space, compute activations, plot activations\n",
    "\"\"\"\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.pop_num_imgs = 100\n",
    "  \n",
    "  orthogonal_list = [idx for idx in range(analyzer.bf_stats[\"num_outputs\"])]\n",
    "  num_orthogonal = len(orthogonal_list)\n",
    "  \n",
    "  pop_x_pts = np.linspace(-2.0, 2.0, int(analyzer.pop_num_imgs))\n",
    "  pop_y_pts = np.linspace(-2.0, 2.0, int(analyzer.pop_num_imgs))\n",
    "  pop_X, pop_Y = np.meshgrid(pop_x_pts, pop_y_pts)\n",
    "  pop_proj_datapoints = np.stack([pop_X.reshape(analyzer.pop_num_imgs**2), pop_Y.reshape(analyzer.pop_num_imgs**2)], axis=1) # construct a grid\n",
    "  \n",
    "  #x_target = pop_x_pts[int(6*analyzer.pop_num_imgs/8)] # find a location to take a slice\n",
    "  x_target = pop_x_pts[int(0.25*analyzer.pop_num_imgs)] # find a location to take a slice\n",
    "  \n",
    "  slice_indices = np.where(pop_proj_datapoints[:,0]==x_target)[0]\n",
    "  analyzer.pop_proj_datapoints = pop_proj_datapoints[slice_indices,:] # slice grid\n",
    "  \n",
    "  pop_datapoints = [None,]*num_orthogonal\n",
    "  #pop_proj_neurons = [None,]*num_orthogonal\n",
    "  for pop_idx, tmp_bf_id1 in enumerate(orthogonal_list):\n",
    "    tmp_bf1 = analyzer.bf_stats[\"basis_functions\"][tmp_bf_id1].reshape((analyzer.model_params.num_pixels))\n",
    "    tmp_bf1 /= np.linalg.norm(tmp_bf1)\n",
    "    tmp_proj_matrix, v = analyzer.bf_projections(analyzer.bf0, tmp_bf1) \n",
    "    pop_datapoints[pop_idx] = np.dot(pop_proj_datapoints, tmp_proj_matrix)#[slice_indices,:]\n",
    "  \n",
    "  pop_datapoints = np.reshape(np.stack(pop_datapoints, axis=0),\n",
    "    [num_orthogonal*analyzer.pop_num_imgs, analyzer.model_params.num_pixels])\n",
    "  \n",
    "  pop_datapoints = dp.reshape_data(pop_datapoints, flatten=False)[0]\n",
    "  analyzer.pop_datapoints = {\"test\": Dataset(pop_datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "  analyzer.pop_datapoints = analyzer.model.preprocess_dataset(analyzer.pop_datapoints,\n",
    "    params={\"whiten_data\":analyzer.model_params.whiten_data,\n",
    "    \"whiten_method\":analyzer.model_params.whiten_method})\n",
    "  analyzer.pop_datapoints = analyzer.model.reshape_dataset(analyzer.pop_datapoints, analyzer.model_params)\n",
    "  analyzer.pop_datapoints[\"test\"].images /= np.max(np.abs(analyzer.pop_datapoints[\"test\"].images))\n",
    "  analyzer.pop_datapoints[\"test\"].images *= analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  pop_activations = analyzer.compute_activations(analyzer.pop_datapoints[\"test\"].images)[:, analyzer.bf_id0]\n",
    "  pop_activations = pop_activations.reshape([num_orthogonal, pop_num_imgs])\n",
    "  analyzer.pop_norm_activity = pop_activations / np.amax(np.abs(pop_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Construct the set of unit-length bases that are orthogonal to B0 (there should be B0.size-1 of them)\n",
    "* Construct a line of data points in each plane defined by B0 and a given orthogonal basis\n",
    "* Project the data points into image space, compute activations, plot activations\n",
    "\"\"\"\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.rand_pop_num_imgs = 100\n",
    "  analyzer.rand_num_orthogonal = analyzer.bf_stats[\"num_inputs\"]-1\n",
    "  \n",
    "  pop_x_pts = np.linspace(-2.0, 2.0, int(analyzer.rand_pop_num_imgs))\n",
    "  pop_y_pts = np.linspace(-2.0, 2.0, int(analyzer.rand_pop_num_imgs))\n",
    "  pop_X, pop_Y = np.meshgrid(pop_x_pts, pop_y_pts)\n",
    "  analyzer.rand_pop_proj_datapoints = np.stack([analyzer.pop_X.reshape(analyzer.rand_pop_num_imgs**2),\n",
    "    analyzer.pop_Y.reshape(analyzer.rand_pop_num_imgs**2)], axis=1) # construct a grid\n",
    "  \n",
    "  #x_target = pop_x_pts[int(6*analyzer.rand_pop_num_imgs/8)] # find a location to take a slice\n",
    "  x_target = pop_x_pts[int(0.25*analyzer.rand_pop_num_imgs)] # find a location to take a slice\n",
    "  \n",
    "  slice_indices = np.where(analyzer.rand_pop_proj_datapoints[:,0]==x_target)[0]\n",
    "  analyzer.rand_pop_proj_datapoints = analyzer.rand_pop_proj_datapoints[slice_indices,:] # slice grid\n",
    "  \n",
    "  analyzer.rand_pop_datapoints = [None,]*analyzer.rand_num_orthogonal\n",
    "  for pop_idx in range(analyzer.rand_num_orthogonal):\n",
    "    v = orth_col_matrix[:, pop_idx]\n",
    "    tmp_proj_matrix = np.stack([analyzer.bf0, v], axis=0)\n",
    "    analyzer.rand_pop_datapoints[pop_idx] = np.dot(analyzer.rand_pop_proj_datapoints,\n",
    "      tmp_proj_matrix)#[slice_indices,:]\n",
    "\n",
    "  analyzer.rand_pop_datapoints = np.reshape(np.stack(analyzer.rand_pop_datapoints, axis=0),\n",
    "    [analyzer.rand_num_orthogonal*analyzer.rand_pop_num_imgs, analyzer.model_params.num_pixels])\n",
    "\n",
    "  analyzer.rand_pop_datapoints = dp.reshape_data(analyzer.rand_pop_datapoints, flatten=False)[0]\n",
    "  analyzer.rand_pop_datapoints = {\"test\": Dataset(analyzer.rand_pop_datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "  analyzer.rand_pop_datapoints = analyzer.model.preprocess_dataset(analyzer.rand_pop_datapoints,\n",
    "    params={\"whiten_data\":False, \"whiten_method\":None})\n",
    "  analyzer.rand_pop_datapoints = analyzer.model.reshape_dataset(analyzer.rand_pop_datapoints, analyzer.model_params)\n",
    "  analyzer.rand_pop_datapoints[\"test\"].images /= np.max(np.abs(analyzer.rand_pop_datapoints[\"test\"].images))\n",
    "  analyzer.rand_pop_datapoints[\"test\"].images *= analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  rand_pop_activations = analyzer.compute_activations(analyzer.rand_pop_datapoints[\"test\"].images)[:, analyzer.bf_id0]\n",
    "  rand_pop_activations = rand_pop_activations.reshape([analyzer.rand_num_orthogonal, analyzer.rand_pop_num_imgs])\n",
    "  analyzer.rand_pop_norm_activity = rand_pop_activations / np.amax(np.abs(rand_pop_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(analyzer.norm_activity))\n",
    "print(np.max(analyzer.norm_activity))\n",
    "print(analyzer.norm_activity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_coeffs = [\n",
    "    np.polynomial.polynomial.polyfit(analyzer.pop_proj_datapoints[:,1], analyzer.pop_norm_activity[orthog_idx,:], deg=2)\n",
    "    for orthog_idx in range(num_orthogonal)]\n",
    "  analyzer.bf_fits = [\n",
    "    np.polynomial.polynomial.polyval(analyzer.pop_proj_datapoints[:,1], coeff)\n",
    "    for coeff in analyzer.bf_coeffs]\n",
    "  analyzer.bf_curvatures = [np.polyder(fit, m=2) for fit in analyzer.bf_fits]\n",
    "  \n",
    "  analyzer.rand_coeffs = [np.polynomial.polynomial.polyfit(analyzer.rand_pop_proj_datapoints[:,1],\n",
    "    analyzer.rand_pop_norm_activity[orthog_idx,:], deg=2) for orthog_idx in range(analyzer.rand_num_orthogonal)]\n",
    "  analyzer.rand_fits = [np.polynomial.polynomial.polyval(analyzer.rand_pop_proj_datapoints[:,1], coeff)\n",
    "    for coeff in analyzer.rand_coeffs]\n",
    "  analyzer.rand_curvatures = [np.polyder(fit, m=2) for fit in analyzer.rand_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_idx = 0\n",
    "\n",
    "bf_curvatures = np.stack(analyer_list[analyzer_idx].bf_coeffs, axis=0)[:,2]\n",
    "rand_curvatures = np.stack(analyzer_list[analyzer_idx].rand_coeffs, axis=0)[:,2]\n",
    "\n",
    "num_bins = 100\n",
    "bins = np.linspace(-0.2, 0.2, num_bins)\n",
    "bf_hist, bin_edges = np.histogram(bf_curvatures.flatten(), bins)\n",
    "rand_hist, _ = np.histogram(rand_curvatures.flatten(), bins)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16,9))\n",
    "\n",
    "ax.bar(bin_centers, rand_hist, width=0.0022, log=False, color=\"g\", alpha=0.5, align=\"center\", label=\"Random Projection\")\n",
    "ax.bar(bin_centers, bf_hist, width=0.0022, log=False, color=\"r\", alpha=0.5, align=\"center\", label=\"BF Projection\")\n",
    "\n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::15], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.3f\"))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(24) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(24) \n",
    "\n",
    "ax.set_title(\"Histogram of Curvatures\", fontsize=32)\n",
    "ax.set_xlabel(\"Curvature\", fontsize=32)\n",
    "ax.set_ylabel(\"Count\", fontsize=32)\n",
    "ax.legend(loc=2, fontsize=32)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/histogram_of_curvatures_bf0id\"+str(analyzer.bf_id0)+\".png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
