{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                              \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import scipy\n",
    "from skimage.measure import compare_psnr\n",
    "import tensorflow as tf                                                         \n",
    "import data.data_selector as ds                                                   \n",
    "import analysis.analysis_picker as ap\n",
    "import utils.plot_functions as pf                                               \n",
    "import utils.data_processing as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 12\n",
    "figsize = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analysis_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca_subspace\"\n",
    "    self.model_name = \"lca_subspace_vh\"\n",
    "    self.version = \"2.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "# Computed params\n",
    "analysis_params = analysis_params()\n",
    "analysis_params.project_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\")\n",
    "analysis_params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+analysis_params.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "analyzer.setup(analysis_params)\n",
    "analyzer.setup_model(analyzer.model_params)\n",
    "analyzer.load_analysis(save_info=analysis_params.save_info)\n",
    "analyzer.model_name = analysis_params.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group invariance reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def grid_angles(num_examples_per_dimension, num_neurons_per_group):\n",
    "  angles = [np.linspace(0, np.pi, num_examples_per_dimension) for _ in range(num_neurons_per_group-2)]\n",
    "  angles += [np.linspace(0, 2*np.pi, num_examples_per_dimension)]\n",
    "  angles = [angle for angle in itertools.product(*angles)]\n",
    "  return np.stack(angles, axis=0)\n",
    "\n",
    "def random_angles(init, num_steps, step_size, momentum_weight=0.0):\n",
    "  init = np.asarray(init)\n",
    "  prev_step = 0.0\n",
    "  angles = [init]\n",
    "  for step in range(1, num_steps):\n",
    "    delta = np.random.normal(0.0, 1.0, size=init.shape)\n",
    "    delta_angle = momentum_weight * prev_step + step_size * delta\n",
    "    new_angle = angles[step-1] + delta_angle\n",
    "    for dim in range(new_angle.ndim-1):\n",
    "      if new_angle[dim] > np.pi:\n",
    "        new_angle[dim] = new_angle[dim] - np.pi\n",
    "    if new_angle[-1] > 2*np.pi:\n",
    "      new_angle[-1] = new_angle[-1] - (2 * np.pi)\n",
    "    angles.append(new_angle)\n",
    "  return np.stack(angles, axis=0)\n",
    "\n",
    "def less_random_angles(init, steps_per_direction, num_directions, step_size):\n",
    "  init = np.asarray(init)\n",
    "  angles = [init]\n",
    "  for direction in range(num_directions):\n",
    "    delta = np.random.normal(0.0, 1.0, size=init.shape)\n",
    "    for step in range(steps_per_direction):\n",
    "      delta_angle = step_size * delta\n",
    "      new_angle = angles[step-1] + delta_angle\n",
    "      for dim in range(new_angle.ndim-1):\n",
    "        if new_angle[dim] > np.pi:\n",
    "          new_angle[dim] = new_angle[dim] - np.pi\n",
    "      if new_angle[-1] > 2*np.pi:\n",
    "        new_angle[-1] = new_angle[-1] - (2 *np.pi)\n",
    "      angles.append(new_angle)\n",
    "  return np.stack(angles, axis=0)\n",
    "\n",
    "def angles_to_vectors(angles, target_group, num_groups, num_neurons_per_group):\n",
    "  # https://en.wikipedia.org/wiki/N-sphere#Spherical_coordinates\n",
    "  zs = []\n",
    "  for angle in angles:\n",
    "    z = np.zeros((num_groups, num_neurons_per_group))\n",
    "    for group_neuron_idx in range(num_neurons_per_group):\n",
    "      if group_neuron_idx == 0:\n",
    "        z[target_group, group_neuron_idx] = np.cos(angle[group_neuron_idx])\n",
    "      elif group_neuron_idx > 0 and group_neuron_idx <= num_neurons_per_group-2:\n",
    "        prev_group_angles = [np.sin(angle[prev_group_neuron_idx])\n",
    "          for prev_group_neuron_idx in range(group_neuron_idx)]\n",
    "        z[target_group, group_neuron_idx] = np.prod(prev_group_angles)*np.cos(angle[group_neuron_idx])\n",
    "      else: # group_neuron_idx == num_neurons_per_group - 1\n",
    "        prev_group_angles = [np.sin(angle[prev_group_neuron_idx])\n",
    "          for prev_group_neuron_idx in range(group_neuron_idx)]\n",
    "        z[target_group, group_neuron_idx] = np.prod(prev_group_angles)\n",
    "    zs.append(z)\n",
    "  zs = np.stack(zs, axis=0)\n",
    "  return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_group = 1\n",
    "num_examples_per_dimension = 10\n",
    "step_size = np.pi/10\n",
    "momentum_weight = 2.0\n",
    "num_directions = 100\n",
    "steps_per_direction = 10\n",
    "num_steps = num_directions * steps_per_direction\n",
    "\n",
    "num_groups = analyzer.model_params.num_groups\n",
    "num_neurons = analyzer.model_params.num_neurons\n",
    "num_neurons_per_group = num_neurons // num_groups\n",
    "init = [0]*num_neurons_per_group\n",
    "\n",
    "# Traversal of the space one axis at a time\n",
    "#angles = grid_angles(num_examples_per_dimension, num_neurons_per_group)\n",
    "\n",
    "# Traversal of the space via random walk w/ momentum\n",
    "#angles = random_angles(init, num_steps, step_size, momentum_weight)\n",
    "\n",
    "# Traversal of the space via endpoint-finding\n",
    "angles = less_random_angles(init, steps_per_direction, num_directions, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_groups = [1, 2, 5, 12, 66, 141, 154, 230, 305] # 35, 45, 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = []\n",
    "for target_group in target_groups:\n",
    "  zs = angles_to_vectors(angles, target_group, num_groups, num_neurons_per_group)\n",
    "  sigmas = np.zeros((zs.shape[0], analyzer.model_params.num_groups))\n",
    "  sigmas[:, target_group] = 1\n",
    "  input_shape = [zs.shape[0]]+ analyzer.model.get_input_shape()[1:]\n",
    "  feed_dict = analyzer.model.get_feed_dict(np.zeros(input_shape), is_test=True)\n",
    "  feed_dict[analyzer.sigmas] = sigmas\n",
    "  feed_dict[analyzer.zs] = zs\n",
    "  recons.append(analyzer.evaluate_tf_tensor(analyzer.group_recons, feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots_y = len(recons)\n",
    "num_plots_x = len(recons)#len(angles)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(num_plots_y, num_plots_x+1, wspace=0.1, hspace=0.0)\n",
    "for recon_ax in range(num_plots_y):\n",
    "  y_ax = 0\n",
    "  #for angle_ax in range(0, len(angles), len(angles)//num_plots_x):\n",
    "  #for angle_ax in range(num_plots_x):\n",
    "  for angle_ax in range(0, 3*num_plots_x, 3):\n",
    "    ax = pf.clear_axis(fig.add_subplot(gs[recon_ax, y_ax]))\n",
    "    img = recons[recon_ax][angle_ax].reshape([analyzer.model_params.patch_edge_size]*2)\n",
    "    img = dp.normalize_data_with_max(img)[0]\n",
    "    ax.imshow(img, cmap=\"Greys_r\", vmin=-1, vmax=1)\n",
    "    y_ax += 1\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"group_invariance_tiled.png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recon_id in range(len(recons)):\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  ax = pf.clear_axis(fig.add_subplot())\n",
    "  ims = []\n",
    "  for i in range(recons[recon_id].shape[0]):\n",
    "    recon = recons[recon_id][i].reshape([analyzer.model_params.patch_edge_size]*2)\n",
    "    recon = dp.normalize_data_with_max(recon)[0]\n",
    "    im = ax.imshow(recon, animated=True, cmap=\"Greys_r\", vmin=-1, vmax=1)\n",
    "    ims.append([im])\n",
    "  ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
    "  ani.save(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_group_\"+str(target_groups[recon_id])+\"_recons.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_image = (\n",
    "  (analyzer.full_image - np.min(analyzer.full_image))\n",
    "  / (np.max(analyzer.full_image) - np.min(analyzer.full_image))).astype(np.float32)\n",
    "\n",
    "normed_recon = (\n",
    "  (analyzer.full_recon - np.min(analyzer.full_recon))\n",
    "  / (np.max(analyzer.full_recon) - np.min(analyzer.full_recon))).astype(np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "ax[0] = pf.clear_axis(ax[0])\n",
    "ax[0].imshow(np.squeeze(normed_image), cmap=\"Greys_r\")\n",
    "ax[0].set_title(\"Input Image\", fontsize=fontsize)\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(np.squeeze(normed_recon), cmap=\"Greys_r\")\n",
    "percent_active = \"{:.2f}\".format(analyzer.recon_frac_act*100)\n",
    "psnr = \"{:.2f}\".format(compare_psnr(normed_image, normed_recon, data_range=1))\n",
    "ax[1].set_title(\"Reconstruction\\n\"+percent_active+\" percent active\"+\"\\n\"+\"PSNR = \"+psnr, fontsize=fontsize)\n",
    "plt.show()\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_image_recon.png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VanHateren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group coactivation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.get_data(analyzer.model_params)\n",
    "data = analyzer.model.preprocess_dataset(data, analyzer.model_params)\n",
    "data = analyzer.model.reshape_dataset(data, analyzer.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 10000#data[\"train\"].images.shape[0]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config, graph=analyzer.model.graph) as sess:\n",
    "  feed_dict = analyzer.model.get_feed_dict(data[\"train\"].images[0:num_imgs,...])\n",
    "  sess.run(analyzer.model.init_op, feed_dict)\n",
    "  analyzer.model.load_full_model(sess, analyzer.analysis_params.cp_loc)\n",
    "  run_list = [analyzer.model.a, analyzer.model.module.group_activity, analyzer.model.module.group_angles]\n",
    "  neuron_activations, group_activations, group_angles = sess.run(run_list, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_group_activations = np.zeros_like(group_activations)\n",
    "for group_id in range(analyzer.model.module.num_groups):\n",
    "  cent_group_activations[:,group_id] = group_activations[:,group_id] - np.mean(group_activations[:,group_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cov = 1/num_imgs * np.dot(group_activations.T, group_activations)\n",
    "cov = 1/num_imgs * np.dot(np.squeeze(cent_group_activations).T, np.squeeze(cent_group_activations))\n",
    "np.fill_diagonal(cov, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figsize)\n",
    "ax = pf.clear_axis(fig.add_subplot())\n",
    "im = ax.imshow(cov, cmap=\"Greys_r\")\n",
    "vmin = np.min(cov)\n",
    "vmax = np.max(cov)\n",
    "vmean = vmax - ((vmax - vmin) / 2)\n",
    "pf.add_colorbar_to_im(im, aspect=20, ticks=[vmin, vmean, vmax], labelsize=fontsize)\n",
    "ax.set_title(\"Covariance matrix for group activations\", fontsize=fontsize)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_activity_covariance.png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_idx = 1\n",
    "num_bins = 1000\n",
    "indiv_group_act = group_activations[:, group_idx]\n",
    "bins = np.linspace(np.min(indiv_group_act), np.max(indiv_group_act), num_bins)\n",
    "hist, bin_edges = np.histogram(indiv_group_act.flatten(), bins)\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=figsize)\n",
    "ax.bar(bin_centers, hist, width=2.0, log=True, align=\"center\", color='k')\n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::10], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.0f\"))\n",
    "ax.set_xlim([np.min(indiv_group_act), np.max(indiv_group_act)])\n",
    "vmin = np.min(indiv_group_act)\n",
    "vmax = np.max(indiv_group_act)\n",
    "vmean = vmax - ((vmax - vmin)/2)\n",
    "ax.set_xticks([vmin, vmean, vmax])\n",
    "ax.set_title(\"Activity histogram of group \"+str(group_idx)+\" for \"+str(len(indiv_group_act))+\" images\", fontsize=fontsize)\n",
    "ax.set_xlabel(\"Activation\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Log Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "plt.show()\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_group\"+str(group_idx)+\"_activity_hist.png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 500\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot()\n",
    "for neuron_id in range(neuron_activations.shape[1]):\n",
    "  ax.scatter([neuron_id]*num_images, neuron_activations[:num_images, neuron_id], s=0.8, alpha=0.01, color='k')\n",
    "ax.set_title(\"Individual Neuron Activity\", fontsize=fontsize)\n",
    "ax.set_xlabel(\"Neuron Index\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Activity\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct analysis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pf.plot_loc_freq_summary(analyzer.bf_stats, figsize=[figsize[0], figsize[1]/3], fontsize=fontsize)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_location_frequency_centers.png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_angles = analyzer.get_neuron_angles(analyzer.bf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_hist_fig = pf.plot_weight_angle_histogram(neuron_angles[1], num_bins=50, angle_min=0, angle_max=180, figsize=(8,8))\n",
    "angle_hist_fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_angle_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = analyzer.evals[\"lca_subspace/weights/w:0\"]\n",
    "weight_indices = np.stack([np.array(id_list) for id_list in analyzer.model.module.group_ids], axis=0)\n",
    "pooling_weights = np.stack([weights[:, id_list] for id_list in analyzer.model.module.group_ids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits import axes_grid1\n",
    "import utils.data_processing as dp\n",
    "def plot_group_weights(weights, group_ids, title=\"\", figsize=None,  save_filename=None):\n",
    "  \"\"\"\n",
    "    weights: [np.ndarray] of shape [num_neurons, num_input_y, num_input_x]\n",
    "    group_ids: [list of lists] containing ids for each group [[,]*neurons_per_group,]*num_groups\n",
    "  \"\"\"\n",
    "  num_neurons = weights.shape[0]\n",
    "  for weight_id in range(num_neurons):\n",
    "    weights[weight_id,...] = weights[weight_id,...] - weights[weight_id,...].mean()\n",
    "    weights[weight_id,...] = weights[weight_id,...] / (weights[weight_id,...].max()-weights[weight_id,...].min())\n",
    "  vmin = np.min(weights)\n",
    "  vmax = np.max(weights)\n",
    "  indices = [idx for id_list in group_ids for idx in id_list]\n",
    "  num_groups = len(group_ids)\n",
    "  num_groups_x = int(np.floor(np.sqrt(num_groups)))\n",
    "  num_groups_y = int(np.ceil(np.sqrt(num_groups)))\n",
    "  num_neurons_per_group = len(group_ids[0])\n",
    "  num_neurons_x = int(np.floor(np.sqrt(num_neurons_per_group)))\n",
    "  num_neurons_y = int(np.ceil(np.sqrt(num_neurons_per_group)))\n",
    "  outer_spacing = 0.20\n",
    "  inner_spacing = 0.1\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  gs1 = gridspec.GridSpec(num_groups_y, num_groups_x,\n",
    "    hspace=outer_spacing*num_groups_y/(num_groups_x+num_groups_y),\n",
    "    wspace=outer_spacing*num_groups_x/(num_groups_x+num_groups_y))\n",
    "  neuron_index = 0\n",
    "  for group_plot_id in np.ndindex((num_groups_y, num_groups_x)):\n",
    "    gs_inner = gridspec.GridSpecFromSubplotSpec(num_neurons_y, num_neurons_x, gs1[group_plot_id],\n",
    "      hspace=inner_spacing*num_neurons_y/(num_neurons_x+num_neurons_y),\n",
    "      wspace=inner_spacing*num_neurons_x/(num_neurons_x+num_neurons_y))\n",
    "    for inner_plot_id in np.ndindex((num_neurons_y, num_neurons_x)):\n",
    "      ax = pf.clear_axis(fig.add_subplot(gs_inner[inner_plot_id]))\n",
    "      ax.set_aspect(\"equal\")\n",
    "      if neuron_index < num_neurons:\n",
    "        ax.imshow(weights[indices[neuron_index], ...], cmap=\"Greys_r\", vmin=vmin, vmax=vmax)\n",
    "        neuron_index += 1\n",
    "  fig.suptitle(title, y=0.9, x=0.5, fontsize=20)\n",
    "  if save_filename is not None:\n",
    "    fig.savefig(save_filename)\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.reshape(analyzer.evals[\"lca_subspace/weights/w:0\"].T, [analyzer.model.params.num_neurons,\n",
    "      int(np.sqrt(analyzer.model.params.num_pixels)), int(np.sqrt(analyzer.model.params.num_pixels))])\n",
    "weight_fig = plot_group_weights(np.squeeze(weights), analyzer.model.module.group_ids,\n",
    "  title=\"Dictionary\", figsize=(18,18))\n",
    "weight_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+\"group_phi.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = np.array([np.nonzero(data[\"train\"].labels[label_index,:])[0].item()\n",
    "  for label_index in range(data[\"train\"].labels.shape[0])]).T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# rank groupings by label category\n",
    "# grab input samples where labels match a category\n",
    "# sort activations of groups for those samples with the most active first\n",
    "# compute mode of top groups\n",
    "# repeat, excluding previous mode\n",
    "\n",
    "#np.argwhere(labels==0)\n",
    "\n",
    "#get_mode = lambda x : scipy.stats.mode(x)[0].item()\n",
    "\n",
    "# Need to exclude groups that were never active for this label\n",
    "\n",
    "#include_indices = np.arange(analyzer.model.num_groups, dtype=int) # startout looking across all groups\n",
    "#modes = []\n",
    "#for neuron_index in range(analyzer.model.num_groups):\n",
    "#  mode = get_mode([np.argsort(np.squeeze(group_activations)[batch_index, include_indices])[-1]\n",
    "#    for batch_index in np.argwhere(labels==0)])\n",
    "#  modes.append(mode)\n",
    "#  print(include_indices.size)\n",
    "#  include_indices = include_indices[include_indices!=mode]\n",
    "#print(modes)\n",
    "\n",
    "#get_mode([sorted_activations(group_activations[batch_index, include_indices])[0]\n",
    "#  for batch_index in np.argwhere(labels==0)])\n",
    "#[np.argsort(np.squeeze(group_activations[batch_index,:]))[::-1]\n",
    "#  for batch_index in np.argwhere(labels==0)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
