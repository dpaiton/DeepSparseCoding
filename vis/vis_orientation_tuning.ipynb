{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage.measure import compare_psnr\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lca_512_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_512_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_768_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_768_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class lca_1024_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_1024_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ica_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ica\"\n",
    "    self.model_name = \"ica_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "    \n",
    "class sae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "params_list = [lca_768_params(), ica_params(), sae_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations = np.linspace(0, np.pi, 10)\n",
    "\n",
    "bf_stats = analyzer_list[0].bf_stats\n",
    "neuron_idx = 4\n",
    "phase = 0.0\n",
    "contrast = 0.5\n",
    "diameter = -1\n",
    "grating = lambda neuron_idx,contrast,orientation,phase:dp.generate_grating(\n",
    "  *dp.get_grating_params(bf_stats, neuron_idx, orientation=orientation,\n",
    "  phase=phase, contrast=contrast, diameter=diameter))\n",
    "\n",
    "stims = [grating(neuron_idx, contrast, orientation, phase) for orientation in orientations]\n",
    "\n",
    "if not os.path.exists(analyzer_list[0].analysis_out_dir+\"/vis/orientation_stims/\"):\n",
    "  os.makedirs(analyzer_list[0].analysis_out_dir+\"/vis/orientation_stims/\")\n",
    "\n",
    "for idx, stim in enumerate(stims):\n",
    "  fig, ax = plt.subplots(1)\n",
    "  ax = pf.clear_axis(ax)\n",
    "  ax.imshow(stim, cmap=\"Greys_r\")\n",
    "  fig.savefig(analyzer_list[0].analysis_out_dir+\"/vis/orientation_stims/stim_\"+str(idx).zfill(3)+\".png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contrast_orientation_tuning(bf_indices, contrasts, orientations, activations, figsize=(32,32)):\n",
    "  \"\"\"\n",
    "  Generate contrast orientation tuning curves. Every subplot will have curves for each contrast.\n",
    "  Inputs:\n",
    "    bf_indices: [list or array] of neuron indices to use\n",
    "      all indices should be less than activations.shape[0]\n",
    "    contrasts: [list or array] of contrasts to use\n",
    "    orientations: [list or array] of orientations to use\n",
    "  \"\"\"\n",
    "  orientations = np.asarray(orientations)*(180/np.pi) #convert to degrees for plotting\n",
    "  num_bfs = np.asarray(bf_indices).size\n",
    "  cmap = plt.get_cmap('Greys')\n",
    "  cNorm = matplotlib.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "  scalarMap = matplotlib.cm.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  num_plots_y = np.int32(np.ceil(np.sqrt(num_bfs)))+1\n",
    "  num_plots_x = np.int32(np.ceil(np.sqrt(num_bfs)))\n",
    "  gs_widths = [1.0,]*num_plots_x\n",
    "  gs_heights = [1.0,]*num_plots_y\n",
    "  gs = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5, hspace=0.7,\n",
    "    width_ratios=gs_widths, height_ratios=gs_heights)\n",
    "  bf_idx = 0\n",
    "  for plot_id in np.ndindex((num_plots_y, num_plots_x)):\n",
    "    (y_id, x_id) = plot_id\n",
    "    if y_id == 0 and x_id == 0:\n",
    "      ax = fig.add_subplot(gs[plot_id])\n",
    "      #ax.set_ylabel(\"Activation\", fontsize=16)\n",
    "      #ax.set_xlabel(\"Orientation\", fontsize=16)\n",
    "      ax00 = ax\n",
    "    else:\n",
    "      ax = fig.add_subplot(gs[plot_id])#, sharey=ax00)\n",
    "    if bf_idx < num_bfs:\n",
    "      for co_idx, contrast in enumerate(contrasts):\n",
    "        co_idx = -1\n",
    "        contrast = 1.0#contrasts[co_idx]\n",
    "        activity = activations[bf_indices[bf_idx], co_idx, :]\n",
    "        color_val = scalarMap.to_rgba(contrast)\n",
    "        ax.plot(orientations, activity, linewidth=1, color=color_val)\n",
    "        ax.scatter(orientations, activity, s=4, c=[color_val])\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter('%0.2g'))\n",
    "        ax.set_yticks([0, np.max(activity)])\n",
    "        ax.set_xticks([0, 90, 180])\n",
    "      bf_idx += 1\n",
    "    else:\n",
    "      ax = pf.clear_axis(ax, spines=\"none\")\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.bf_indices = np.random.choice(analyzer.ot_grating_responses[\"neuron_indices\"], 12)\n",
    "  ot_fig = plot_contrast_orientation_tuning(analyzer.bf_indices,\n",
    "    analyzer.ot_grating_responses[\"contrasts\"],\n",
    "    analyzer.ot_grating_responses[\"orientations\"],\n",
    "    analyzer.ot_grating_responses[\"mean_responses\"], figsize=(8,8))\n",
    "  ot_fig.savefig(analyzer.analysis_out_dir+\"/vis/orientation_tuning_sm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleh=pf.plot_weights(np.stack(analyzer_list[0].bf_stats[\"basis_functions\"], axis=0)[analyzer_list[0].bf_indices, ...],\n",
    "  figsize=(5,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(weights, title=\"\", figsize=None, save_filename=None):\n",
    "  \"\"\"\n",
    "    weights: [np.ndarray] of shape [num_outputs, num_input_y, num_input_x]\n",
    "    The matrices are renormalized before plotting.\n",
    "  \"\"\"\n",
    "  weights = dp.norm_weights(weights)\n",
    "  vmin = np.min(weights)\n",
    "  vmax = np.max(weights)\n",
    "  num_plots = weights.shape[0]\n",
    "  num_plots_y = int(np.floor(np.sqrt(num_plots)))\n",
    "  num_plots_x = int(np.ceil(np.sqrt(num_plots)))\n",
    "  fig, sub_ax = plt.subplots(num_plots_y, num_plots_x, figsize=figsize)\n",
    "  filter_total = 0\n",
    "  for plot_id in  np.ndindex((num_plots_y, num_plots_x)):\n",
    "    if filter_total < num_plots:\n",
    "      sub_ax[plot_id].imshow(np.squeeze(weights[filter_total, ...]), vmin=vmin, vmax=vmax, cmap=\"Greys_r\")\n",
    "      filter_total += 1\n",
    "    pf.clear_axis(sub_ax[plot_id])\n",
    "    sub_ax[plot_id].set_aspect(\"equal\")\n",
    "  fig.suptitle(title, y=0.95, x=0.5, fontsize=20)\n",
    "  if save_filename is not None:\n",
    "      fig.savefig(save_filename)\n",
    "      plt.close(fig)\n",
    "      return None\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  bfs = np.stack(analyzer.bf_stats[\"basis_functions\"], axis=0)[analyzer.bf_indices, ...]\n",
    "  weights_fig = plot_weights(bfs, figsize=(7,5))\n",
    "  weights_fig.savefig(analyzer.analysis_out_dir+\"/vis/orientation_tuning_bfs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_curve(tuning_curve):\n",
    "  \"\"\"\n",
    "  Centers a curve about its preferred orientation\n",
    "  \"\"\"\n",
    "  return np.roll(tuning_curve, (len(tuning_curve) // 2) - np.argmax(tuning_curve))\n",
    "\n",
    "def compute_fwhm(centered_ot_curve, corresponding_angles_deg):\n",
    "  \"\"\"\n",
    "  Calculates the full width at half maximum of the tuning curve\n",
    "\n",
    "  Result is expressed in degrees to make it a little more intuitive. The curve\n",
    "  is often NOT symmetric about the maximum value so we don't do any fitting and\n",
    "  we return the FULL width\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  centered_ot_curve : ndarray\n",
    "      A 1d array of floats giving the value of the ot curve, at an orientation\n",
    "      relative to the *preferred orientation* which is given by the angles in\n",
    "      corresponding_angles_deg. This has the maximum orientation in the\n",
    "      center of the array which is nicer for visualization.\n",
    "  corresponding_angles_deg : ndarray\n",
    "      The orientations relative to preferred orientation that correspond to\n",
    "      the values in centered_ot_curve\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  half_max_left : float\n",
    "      The position of the intercept to the left of the max\n",
    "  half_max_right : float\n",
    "      The position of the intercept to the right of the max\n",
    "  half_max_value : float\n",
    "      Mainly for plotting purposes, the actual curve value that corresponds\n",
    "      to the left and right points\n",
    "  \"\"\"\n",
    "  max_idx = np.argmax(centered_ot_curve)\n",
    "  min_idx = np.argmin(centered_ot_curve)\n",
    "  max_val = centered_ot_curve[max_idx]\n",
    "  min_val = centered_ot_curve[min_idx]\n",
    "  midpoint = (max_val / 2) + (min_val / 2)\n",
    "  # find the left hand point\n",
    "  idx = max_idx\n",
    "  while centered_ot_curve[idx] > midpoint:\n",
    "    idx -= 1\n",
    "    if idx == -1:\n",
    "      # the width is *at least* 90 degrees\n",
    "      half_max_left = -90.\n",
    "      break\n",
    "  if idx > -1:\n",
    "    # we'll linearly interpolate between the two straddling points\n",
    "    # if (x2, y2) is the coordinate of the point below the half-max and\n",
    "    # (x1, y1) is the point above the half-max, then we can solve for x3, the\n",
    "    # x-position of the point that corresponds to the half-max on the line\n",
    "    # that connects (x1, y1) and (x2, y2)\n",
    "    half_max_left = (((midpoint - centered_ot_curve[idx])\n",
    "      * (corresponding_angles_deg[idx+1] - corresponding_angles_deg[idx])\n",
    "      / (centered_ot_curve[idx+1] - centered_ot_curve[idx]))\n",
    "      + corresponding_angles_deg[idx])\n",
    "  # find the right hand point\n",
    "  idx = max_idx\n",
    "  while centered_ot_curve[idx] > midpoint:\n",
    "    idx += 1\n",
    "    if idx == len(centered_ot_curve):\n",
    "      # the width is *at least* 90\n",
    "      half_max_right = 90.\n",
    "      break\n",
    "  if idx < len(centered_ot_curve):\n",
    "    # we'll linearly interpolate between the two straddling points again\n",
    "    half_max_right = (((midpoint - centered_ot_curve[idx-1])\n",
    "      * (corresponding_angles_deg[idx] - corresponding_angles_deg[idx-1])\n",
    "      / (centered_ot_curve[idx] - centered_ot_curve[idx-1]))\n",
    "      + corresponding_angles_deg[idx-1])\n",
    "  return half_max_left, half_max_right, midpoint\n",
    "\n",
    "def compute_circ_var(centered_ot_curve, corresponding_angles_rad):\n",
    "  \"\"\"\n",
    "  From\n",
    "  DL Ringach, RM Shapley, MJ Hawken (2002) - Orientation Selectivity in Macaque V1:\n",
    "  Diversity and Laminar Dependence\n",
    "  \n",
    "  Computes the circular variance of a tuning curve and returns vals for plotting\n",
    "\n",
    "  This is a scale-invariant measure of how 'oriented' a curve is in some\n",
    "  global sense. It wraps reponses around the unit circle and then sums their\n",
    "  vectors, resulting in an average vector, the magnitude of which indicates\n",
    "  the strength of the tuning. Circular variance is an index of 'orientedness'\n",
    "  that falls in the interval [0.0, 1.0], with 0.0 indicating a delta function\n",
    "  and 1.0 indicating a completely flat tuning curve.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  centered_ot_curve : ndarray\n",
    "      A 1d array of floats giving the value of the ot curve, at an orientation\n",
    "      relative to the *preferred orientation* which is given by the angles in\n",
    "      corresponding_angles_rad. This has the maximum orientation in the\n",
    "      center of the array which is nicer for visualization.\n",
    "  corresponding_angles_rad : ndarray\n",
    "      The orientations relative to preferred orientation that correspond to\n",
    "      the values in centered_ot_curve\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  numerator_sum_components : ndarray\n",
    "      The complex values the are produced from r * np.exp(j*2*theta). These\n",
    "      are the elements that get summed up in the numerator\n",
    "  direction_vector : complex64 or complex128\n",
    "      This is the vector that points in the direction of *aggregate* tuning.\n",
    "      its magnitude is upper bounded by 1.0 which is the case when only one\n",
    "      orientation has a nonzero value. We can plot it to get an idea of how\n",
    "      tuned a curve is\n",
    "  circular_variance : float\n",
    "      This is 1 minus the magnitude of the direction vector. It represents and\n",
    "      index of 'global selectivity'\n",
    "  \"\"\"\n",
    "  # in the original definition, angles are [0, 2*np.pi] so the factor of 2\n",
    "  # in the exponential wraps the phase twice around the complex circle,\n",
    "  # placing responses that correspond to angles pi degrees apart\n",
    "  # onto the same place. We know there's a redudancy in our responses at pi\n",
    "  # offsets so our responses get wrapped around the unit circle once.\n",
    "  numerator_sum_components = (centered_ot_curve\n",
    "    * np.exp(1j * 2 * corresponding_angles_rad))\n",
    "  direction_vector = (np.sum(numerator_sum_components)\n",
    "    / np.sum(centered_ot_curve))\n",
    "  circular_variance = 1 - np.abs(direction_vector)\n",
    "  return (numerator_sum_components, direction_vector, circular_variance)\n",
    "\n",
    "def compute_osi(centered_ot_curve):\n",
    "  \"\"\"\n",
    "  Compute the Orientation Selectivity Index.\n",
    "\n",
    "  This is the most coarse but popular measure of selectivity. It really\n",
    "  doesn't tell you much. It just measures the maximum response relative to\n",
    "  the minimum response.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  centered_ot_curve : ndarray\n",
    "      A 1d array of floats giving the value of the ot curve, at an orientation\n",
    "      relative to the *preferred orientation*\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  osi : float\n",
    "      This is (a_max - a_orth) / (a_max + a_orth) where a_max is the maximum\n",
    "      response across orientations when orientation responses are\n",
    "      *averages* over phase. a_orth is the orientation which is orthogonal to\n",
    "      the orientation which produces a_max.\n",
    "  \"\"\"\n",
    "  max_val = np.max(centered_ot_curve)\n",
    "  # Assume that orthogonal orientation is at either end of the curve modulo 1\n",
    "  # bin (if we had like an even number of orientation values)\n",
    "  orth_val = centered_ot_curve[0]\n",
    "  osi = (max_val - orth_val) / (max_val + orth_val)\n",
    "  return osi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def plot_circular_variance(cv_data, max_bfs_per_fig=400, title=\"\", save_filename=None):\n",
    "  assert np.sqrt(max_bfs_per_fig) % 1 == 0, \"Pick a square number for max_bfs_per_fig\"\n",
    "  orientations = (np.pi * np.arange(len(cv_data))\n",
    "    / len(cv_data)) - (np.pi/2) # relative to preferred\n",
    "  num_bfs = len(cv_data)\n",
    "  num_bf_figs = int(np.ceil(num_bfs / max_bfs_per_fig))\n",
    "  # this determines how many ot curves are aranged in a square grid within\n",
    "  # any given figure\n",
    "  if num_bf_figs > 1:\n",
    "    bfs_per_fig = max_bfs_per_fig\n",
    "  else:\n",
    "    squares = [x**2 for x in range(1, int(np.sqrt(max_bfs_per_fig))+1)]\n",
    "    bfs_per_fig = squares[bisect.bisect_left(squares, num_bfs)]\n",
    "  plot_sidelength = int(np.sqrt(bfs_per_fig))\n",
    "  bf_idx = 0\n",
    "  bf_figs = []\n",
    "  for in_bf_fig_idx in range(num_bf_figs):\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    plt.suptitle(title + ', fig {} of {}'.format(\n",
    "      in_bf_fig_idx+1, num_bf_figs), fontsize=20)\n",
    "    subplot_grid = gridspec.GridSpec(plot_sidelength, plot_sidelength,\n",
    "      wspace=0.4, hspace=0.4)\n",
    "    fig_bf_idx = bf_idx % bfs_per_fig\n",
    "    while fig_bf_idx < bfs_per_fig and bf_idx < num_bfs:\n",
    "      #if bf_idx % 100 == 0:\n",
    "      #  print(\"plotted \", bf_idx, \" of \", num_bfs, \" circular variance plots\")\n",
    "      ## print(\"sum vector: \", np.real(cv_data[bf_idx][1]), np.imag(cv_data[bf_idx][1]))\n",
    "      ax = plt.Subplot(fig, subplot_grid[fig_bf_idx])\n",
    "      ax.plot(np.real(cv_data[bf_idx][0]), np.imag(cv_data[bf_idx][0]),\n",
    "              c='g', linewidth=0.5)\n",
    "      ax.scatter(np.real(cv_data[bf_idx][0]), np.imag(cv_data[bf_idx][0]),\n",
    "                 c='g', s=4)\n",
    "      ax.quiver(np.real(cv_data[bf_idx][1]), np.imag(cv_data[bf_idx][1]),\n",
    "                angles='xy', scale_units='xy', scale=1.0, color='b',\n",
    "                width=0.01)\n",
    "      # ax.quiver(0.5, 0.5, color='b')\n",
    "      ax.axvline(x=0.0, color='k', linestyle='--', alpha=0.6, linewidth=0.3)\n",
    "      ax.axhline(y=0.0, color='k', linestyle='--', alpha=0.6, linewidth=0.3)\n",
    "      ax.yaxis.set_major_formatter(FormatStrFormatter('%0.2g'))\n",
    "      xaxis_size = max(np.max(np.real(cv_data[bf_idx][0])), 1.0)\n",
    "      yaxis_size = max(np.max(np.imag(cv_data[bf_idx][0])), 1.0)\n",
    "      ax.set_yticks([-1. * yaxis_size, yaxis_size])\n",
    "      ax.set_xticks([-1. * xaxis_size, xaxis_size])\n",
    "      # put the circular variance index in the upper left\n",
    "      ax.text(0.02, 0.97, 'CV: {:.2f}'.format(cv_data[bf_idx][2]),\n",
    "              horizontalalignment='left', verticalalignment='top',\n",
    "              transform=ax.transAxes, color='b', fontsize=10)\n",
    "      fig.add_subplot(ax)\n",
    "      fig_bf_idx += 1\n",
    "      bf_idx += 1\n",
    "    if save_filename is not None:\n",
    "      filename_split = os.path.split(save_filename)\n",
    "      save_filename = filename_split[0]+str(in_bf_fig_idx).zfill(2)+\"_\"+filename_split[1]\n",
    "      fig.savefig(save_filename)\n",
    "      plt.close(fig)\n",
    "      bf_figs.append(None)\n",
    "    else:\n",
    "      bf_figs.append(fig)\n",
    "  if save_filename is None:\n",
    "    plt.show()\n",
    "  return bf_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  contrast_idx = -1\n",
    "  num_orientation_samples = len(analyzer.ot_grating_responses['orientations'])\n",
    "  corresponding_angles_deg = (180 * np.arange(num_orientation_samples) / num_orientation_samples) - 90\n",
    "  corresponding_angles_rad = (np.pi * np.arange(num_orientation_samples) / num_orientation_samples) - (np.pi/2)\n",
    "  \n",
    "  analyzer.metrics_list = {\"fwhm\":[], \"circ_var\":[], \"osi\":[], \"skipped_indices\":[]}\n",
    "  for bf_idx in range(analyzer.bf_stats[\"num_outputs\"]):\n",
    "    ot_curve = center_curve(analyzer.ot_grating_responses[\"mean_responses\"][bf_idx, contrast_idx, :])\n",
    "    if np.max(ot_curve) - np.min(ot_curve) == 0:\n",
    "      analyzer.metrics_list[\"skipped_indices\"].append(bf_idx)\n",
    "    else:\n",
    "      fwhm = compute_fwhm(ot_curve, corresponding_angles_deg)\n",
    "      analyzer.metrics_list[\"fwhm\"].append(fwhm)\n",
    "      circ_var = compute_circ_var(ot_curve, corresponding_angles_rad)\n",
    "      analyzer.metrics_list[\"circ_var\"].append(circ_var)\n",
    "      osi = compute_osi(ot_curve)\n",
    "      analyzer.metrics_list[\"osi\"].append(osi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  circ_var_figs = plot_circular_variance(analyzer.metrics_list[\"circ_var\"],\n",
    "    max_bfs_per_fig=144, title=\"Circular Variance\")\n",
    "  for fig_idx, circ_fig in enumerate(circ_var_figs):\n",
    "    circ_fig.savefig(analyzer.analysis_out_dir+\"/vis/circular_variance_\"+str(fig_idx)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circular_variance_histogram(variances_list, label_list, num_bins=50, y_max=None,\n",
    "  figsize=None, save_filename=None):\n",
    "  variance_min = np.min([np.min(var) for var in variances_list])#0.0\n",
    "  variance_max = np.max([np.max(var) for var in variances_list])#1.0\n",
    "  bins = np.linspace(variance_min, variance_max, num_bins)\n",
    "  bar_width = np.diff(bins).min()\n",
    "  fig, ax = plt.subplots(1, figsize=figsize)\n",
    "  hist_list = []\n",
    "  handles = []\n",
    "  for variances, label in zip(variances_list, label_list):\n",
    "    hist, bin_edges = np.histogram(variances.flatten(), bins)\n",
    "    #hist = hist / np.max(hist)\n",
    "    hist_list.append(hist)\n",
    "    bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "    bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "    handles.append(ax.bar(bin_centers, hist, width=bar_width, log=True, align=\"center\", alpha=0.5, label=label))\n",
    "  ax.set_xticks(bin_left, minor=True)\n",
    "  ax.set_xticks(bin_left[::4], minor=False)\n",
    "  ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.0f\"))\n",
    "  ax.tick_params(\"both\", labelsize=16)\n",
    "  ax.set_xlim([variance_min, variance_max])\n",
    "  ax.set_xticks([variance_min, variance_max])\n",
    "  ax.set_xticklabels([\"More selective\", \"Less selective\"])\n",
    "  ticks = ax.xaxis.get_major_ticks()\n",
    "  ticks[0].label1.set_horizontalalignment(\"left\")\n",
    "  ticks[1].label1.set_horizontalalignment(\"right\")\n",
    "  if y_max is None:\n",
    "    # Round up to the nearest power of 10\n",
    "    y_max = 10**(np.ceil(np.log10(np.max([np.max(hist) for hist in hist_list]))))\n",
    "  ax.set_ylim([1, y_max])\n",
    "  ax.set_title(\"Circular Variance Histogram\", fontsize=18)\n",
    "  ax.set_xlabel(\"Selectivity\", fontsize=18)\n",
    "  ax.set_ylabel(\"Log Count\", fontsize=18)\n",
    "  legend = ax.legend(handles, label_list, fontsize=12, #ncol=len(label_list),\n",
    "    borderaxespad=0., bbox_to_anchor=[0.98, 0.98], fancybox=True, loc=\"upper right\")\n",
    "  if save_filename is not None:\n",
    "    fig.savefig(save_filename)\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "circ_var_list = []\n",
    "label_list = [\"LCA\", \"ICA\", \"SAE\"]\n",
    "for analyzer in analyzer_list:\n",
    "  circ_var_list.append(np.array([val[2] for val in analyzer.metrics_list[\"circ_var\"]]))\n",
    "circ_hist_fig = plot_circular_variance_histogram(circ_var_list, label_list, figsize=(8,8))\n",
    "for analyzer in analyzer_list:\n",
    "    circ_hist_fig.savefig(analyzer.analysis_out_dir+\"/vis/circular_variance_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_fig = pf.plot_masked_orientation_tuning(co_bf_indices, co_mask_orientations, co_base_mean_responses, analyzer.co_grating_responses[\"test_mean_responses\"])\n",
    "cross_fig = pf.plot_masked_orientation_tuning(co_bf_indices, co_mask_orientations, co_base_mean_responses, co_test_mean_responses)\n",
    "cross_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_cross_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_contrast_fig = pf.plot_plaid_contrast_tuning(co_bf_indices, co_contrasts, co_contrasts, co_base_orientations,\n",
    "  co_mask_orientations, co_test_mean_responses)\n",
    "cross_contrast_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_cross_contrast_orientation_tuning.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
