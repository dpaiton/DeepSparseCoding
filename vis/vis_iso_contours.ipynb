{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BF Analysis & Iso-Response Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lca_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca\"\n",
    "    self.model_name = \"lca_512_vh\"#\"lca_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    #self.save_info = \"analysis_sgd_rm-0.99-1.0_test_carlini_targeted\"\n",
    "    #self.save_info = \"analysis_test_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class ae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"ae\"\n",
    "    self.model_name = \"ae_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class rica_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"rica\"\n",
    "    self.model_name = \"rica_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class sae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"sae\"\n",
    "    self.model_name = \"sae_768_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    #self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    self.save_info = \"analysis_sgd_rm-0.99-1.0_test_carlini_targeted\"\n",
    "    #self.save_info = \"analysis_test_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class vae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"vae\"\n",
    "    self.model_name = \"vae_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_carlini_targeted\"\n",
    "    #self.save_info = \"analysis_test_kurakin_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class mlp_lca_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"mlp_lca\"\n",
    "    self.model_name = \"mlp_lca_768_latent_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_kurakin_untargeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "class mlp_sae_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"mlp_sae\"\n",
    "    self.model_name = \"mlp_sae_768_latent_mnist\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_test_kurakin_untargeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "\n",
    "params_list = [lca_params()]#, sae_params()]#mlp_lca_params(), mlp_sae_params()]\n",
    "for params in params_list:\n",
    "  params.model_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\"+params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_list = [ap.get_analyzer(params.model_type) for params in params_list]\n",
    "for analyzer, params in zip(analyzer_list, params_list):\n",
    "  analyzer.setup(params)\n",
    "  analyzer.model.setup(analyzer.model_params)\n",
    "  analyzer.load_analysis(save_info=params.save_info)\n",
    "  analyzer.model_name = params.model_name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "num_bins = 50\n",
    "min_dist = 0.0\n",
    "max_dist = 1.0\n",
    "fontsize = 18\n",
    "line_alpha = 0.7\n",
    "bins = np.linspace(min_dist, max_dist, num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  adv_images = analyzer.adversarial_images[0, -1, :, :]\n",
    "  input_images = analyzer.class_adversarial_input_images\n",
    "  cos_similarity = dp.cos_similarity(input_images, adv_images)\n",
    "  num_bins = 50\n",
    "  min_dist = np.minimum(0.0, np.min(cos_similarity))\n",
    "  max_dist = np.maximum(1.0, np.max(cos_similarity))\n",
    "  analyzer.dist_hist, bin_edges = np.histogram(cos_similarity, bins=bins)\n",
    "  analyzer.dist_hist = analyzer.dist_hist / np.max(analyzer.dist_hist)\n",
    "  analyzer.dist_mean = np.mean(cos_similarity)\n",
    "  analyzer.dist_std = np.std(cos_similarity)\n",
    "  bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "  bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "  ax.plot(bin_left, analyzer.dist_hist, alpha=line_alpha, linestyle=\"--\", #color = 'k',\n",
    "    drawstyle=\"steps-mid\", label=analyzer.model_params.model_type.upper())\n",
    "  ax.set_xlabel(\"\", fontsize=fontsize)\n",
    "  ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  \n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "title = (\"Cosine Similarity of Adversarial Perturbations to Dataset Images\")\n",
    "#sensitivity_index = (lca_dist_mean - sae_dist_mean) / np.sqrt(0.5 * (lca_dist_std**2 + sae_dist_std**2))\n",
    "#title = (\"Cosine Similarity of Adversarial Examples to Dataset Images\\n\"\n",
    "#         +\"Sensitivity Index = \"+str(np.round(sensitivity_index, decimals=2)))\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "ax.legend(fontsize=fontsize, fancybox=True, shadow=True, bbox_to_anchor=(0.5, 0.8))\n",
    "plt.show()\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/cosyne_similarity.png\", transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset = ds.get_data(analyzer_list[0].model_params)\n",
    "#dataset = analyzer_list[0].model.preprocess_dataset(dataset, analyzer_list[0].model_params)\n",
    "dataset = analyzer_list[0].model.reshape_dataset(dataset, analyzer_list[0].model_params)\n",
    "target_image = dataset[\"train\"].images[0,...]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get images that are adversarial\n",
    "adv_image_set = []\n",
    "prev_num_adv_images = None\n",
    "for analyzer in analyzer_list:\n",
    "  adv_images = analyzer.adversarial_images[0][-1]\n",
    "  num_model_adv_images = adv_images.shape[0]\n",
    "  if prev_num_adv_images is None:\n",
    "    prev_num_adv_images = num_model_adv_images\n",
    "  else:\n",
    "    assert num_model_adv_images == prev_num_adv_images, (\n",
    "      \"Each model must have the same number of adversarial images.\")\n",
    "  adv_images = adv_images / np.sqrt(np.sum(np.square(adv_images), axis=1, keepdims=True))\n",
    "  model_adv_image_set = []\n",
    "  for image_id in range(num_model_adv_images):\n",
    "    model_adv_image_set.append(target_image + adv_images[image_id, :])\n",
    "  adv_image_set.append(model_adv_image_set)\n",
    "\n",
    "num_adv_images = num_model_adv_images * len(analyzer_list)\n",
    "\n",
    "# Get images that are from the dataset\n",
    "num_dataset_images = num_model_adv_images\n",
    "image_set = dataset[\"train\"].images[1:num_dataset_images+1, ...]\n",
    "image_set /= np.sqrt(np.sum(np.square(image_set), axis=1, keepdims=True))\n",
    "image_set += target_image[None, ...]\n",
    "\n",
    "# Get random images\n",
    "num_rand_images = num_dataset_images\n",
    "noise_scale_mult = 1.0\n",
    "rand_image_set = []\n",
    "dimensionality = target_image.size\n",
    "rand_vect = np.random.multivariate_normal(mean=[0,]*dimensionality,\n",
    "  cov=np.identity(dimensionality), size=(num_rand_images))\n",
    "rand_vect /= np.sqrt(np.sum(np.square(rand_vect), axis=1, keepdims=True))\n",
    "rand_vect *= noise_scale_mult\n",
    "for datapoint in range(num_rand_images):\n",
    "  rand_image_set.append(target_image + rand_vect[datapoint, ...])\n",
    "rand_image_set = np.stack(rand_image_set) \n",
    "\n",
    "stimulus_set = np.concatenate([target_image[None,...]]+adv_image_set+[image_set, rand_image_set])\n",
    "\n",
    "mse = lambda x,y: np.mean(np.square(x-y))\n",
    "print(\"Testing on\", stimulus_set.shape[0]-1, \"images\")\n",
    "print(\"Mean MSE =\", np.mean([mse(stimulus_set[0, ...], stimulus_set[idx, ...])\n",
    "  for idx in range(1, stimulus_set.shape[0])]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for analyzer in analyzer_list:\n",
    "  evals = analyzer.evaluate_model(stimulus_set, [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "  analyzer.activations = evals[\"inference/activity:0\"]\n",
    "  analyzer.recons = evals[\"output/reconstruction:0\"]\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  print(analyzer.model_name, \"-> recon MSE\", mse(stimulus_set[0], analyzer.recons[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l2_dist = lambda x,y: np.sqrt(np.sum(np.square(x-y)))\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.enc_distances = [l2_dist(analyzer.activations[img_id, :], analyzer.activations[0,:])\n",
    "    for img_id in range(1, analyzer.activations.shape[0])]\n",
    "  analyzer.rec_distances = [l2_dist(analyzer.recons[img_id, :], analyzer.recons[0, :])\n",
    "    for img_id in range(1, analyzer.recons.shape[0])]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.model_adv_distances = {}\n",
    "  for name_index, slice_index in enumerate(range(0, len(analyzer_list)*num_model_adv_images, num_model_adv_images)):\n",
    "    analyzer.model_adv_distances[analyzer_list[name_index].model_name] = analyzer.rec_distances[slice_index:slice_index+num_model_adv_images]\n",
    "  analyzer.dataset_distances = analyzer.rec_distances[num_adv_images:num_adv_images+num_dataset_images]\n",
    "  analyzer.noise_distances = analyzer.rec_distances[num_adv_images+num_dataset_images:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "wspace = 0.4\n",
    "hspace = 0.3\n",
    "fontsize = 18\n",
    "line_alpha = 0.7\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "gs = gridspec.GridSpec(2, len(analyzer_list), hspace=hspace, wspace=wspace)\n",
    "\n",
    "ax_list = []\n",
    "for gs_idx, analyzer in enumerate(analyzer_list):\n",
    "  num_bins = 50\n",
    "  min_dist = np.minimum(0.0, np.min(analyzer.noise_distances))\n",
    "  max_dist = np.maximum(1.0, np.max(analyzer.noise_distances))\n",
    "  bins = np.linspace(min_dist, max_dist, num_bins)\n",
    "  ax_list.append(plt.subplot(gs[gs_idx]))\n",
    "  analyzer.adv_rec_hist = {}\n",
    "  for key in analyzer.model_adv_distances.keys():\n",
    "    analyzer.adv_rec_hist[key], bin_edges = np.histogram(analyzer.model_adv_distances[key], bins=bins)\n",
    "    analyzer.adv_rec_hist[key] = analyzer.adv_rec_hist[key] / np.max(analyzer.adv_rec_hist[key])\n",
    "    bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "    bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "    ax_list[-1].plot(bin_left, analyzer.adv_rec_hist[key], alpha=line_alpha, linestyle=\"--\",# color='k',\n",
    "      drawstyle=\"steps-mid\", label=key.upper()+\" Adversarial recon distances\")\n",
    "  analyzer.dataset_rec_hist = np.histogram(analyzer.dataset_distances, bins=bins)[0]\n",
    "  analyzer.dataset_rec_hist = analyzer.dataset_rec_hist / np.max(analyzer.dataset_rec_hist)\n",
    "  analyzer.noise_rec_hist = np.histogram(analyzer.noise_distances, bins=bins)[0]\n",
    "  analyzer.noise_rec_hist = analyzer.noise_rec_hist / np.max(analyzer.noise_rec_hist)\n",
    "\n",
    "  ax_list[-1].plot(bin_left, analyzer.dataset_rec_hist, alpha=line_alpha, linestyle=\"-.\",# color = 'r',\n",
    "    drawstyle=\"steps-mid\", label=\"Image recon distances\")\n",
    "  ax_list[-1].plot(bin_left, analyzer.noise_rec_hist, alpha=line_alpha, linestyle=\"-\",# color='b', \n",
    "    drawstyle=\"steps-mid\", label=\"Noise recon distances\")\n",
    "  #ax_list[-1].set_xticks(bin_left[::14], minor=False)\n",
    "  #ax_list[-1].set_xticks(bin_left[::7], minor=True)\n",
    "  ax_list[-1].xaxis.set_major_formatter(FormatStrFormatter(\"%0.2f\"))\n",
    "  ax_list[-1].set_xlabel(\"L2 Distance\", fontsize=fontsize)\n",
    "  ax_list[-1].set_ylabel(\"Count\", fontsize=fontsize)\n",
    "  ax_list[-1].set_title(analyzer.model_params.model_type.upper(), fontsize=fontsize)\n",
    "  ax_list[-1].tick_params(\"both\", labelsize=fontsize)\n",
    "\n",
    "bottom_row_ax = pf.clear_axis(plt.subplot(gs[gs_idx+1:]))\n",
    "h, l = ax_list[-1].get_legend_handles_labels()\n",
    "bottom_row_ax.legend(h, l, fontsize=fontsize, fancybox=True, shadow=True)#, bbox_to_anchor=(1, 0.8))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/network_noise_perturbation_hist.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "num_bins = 50\n",
    "similarities = []\n",
    "for analyzer in analyzer_list:\n",
    "  similarities.append(np.abs(analyzer.adversarial_input_pert_cos_similarities[0][-1]))\n",
    "  #similarities.append(np.abs(analyzer.adversarial_target_pert_cos_similarities[0][-1]))\n",
    "min_dist = np.minimum(0.0, np.min(similarities))\n",
    "max_dist = np.maximum(1.0, np.max(similarities))\n",
    "bins = np.linspace(min_dist, max_dist, num_bins)\n",
    "fontsize = 18\n",
    "line_alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,4))\n",
    "\n",
    "for analyzer_idx, analyzer in enumerate(analyzer_list):\n",
    "  #cos_similarity = analyzer.adversarial_target_pert_cos_similarities[0][-1]\n",
    "  #cos_similarity = analyzer.adversarial_target_adv_cos_similarities[0][-1]\n",
    "  #cos_similarity = analyzer.adversarial_input_pert_cos_similarities[0][-1]\n",
    "  #cos_similarity = analyzer.adversarial_input_adv_cos_similarities[0][-1]\n",
    "  cos_similarity = similarities[analyzer_idx]\n",
    "  analyzer.dist_hist, bin_edges = np.histogram(cos_similarity, bins=bins)\n",
    "  analyzer.dist_hist = analyzer.dist_hist / np.max(analyzer.dist_hist)\n",
    "  analyzer.dist_mean = np.mean(cos_similarity)\n",
    "  analyzer.dist_std = np.std(cos_similarity)\n",
    "  bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "  bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "  ax.plot(bin_left, analyzer.dist_hist, alpha=line_alpha, linestyle=\"--\", #color = 'k',\n",
    "    drawstyle=\"steps-mid\", label=analyzer.model_params.model_type.upper())\n",
    "  ax.set_xlabel(\"\", fontsize=fontsize)\n",
    "  ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "  \n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "title = (\"Cosine Similarity Between Target Image and Perturbation\")\n",
    "#sensitivity_index = (lca_dist_mean - sae_dist_mean) / np.sqrt(0.5 * (lca_dist_std**2 + sae_dist_std**2))\n",
    "#title = (\"Cosine Similarity of Adversarial Examples to Dataset Images\\n\"\n",
    "#         +\"Sensitivity Index = \"+str(np.round(sensitivity_index, decimals=2)))\n",
    "ax.set_title(title, fontsize=fontsize)\n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=fontsize)\n",
    "ax.tick_params(\"both\", labelsize=fontsize)\n",
    "ax.legend(fontsize=fontsize, fancybox=True, shadow=True, bbox_to_anchor=(0.8, 0.8))\n",
    "plt.show()\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/cosyne_similarity.png\", transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  analyzer.neuron_angles, analyzer.plot_matrix = analyzer.get_neuron_angles(analyzer.bf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_heatmap_fig = pf.plot_weight_angle_heatmap(analyzer.plot_matrix, angle_min=0, angle_max=180,\n",
    "  title=\"Angles Between Neurons\", figsize=(8,8))\n",
    "angle_heatmap_fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_angle_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  angle_hist_fig = pf.plot_weight_angle_histogram(analyzer.neuron_angles, num_bins=50, angle_min=0, angle_max=180,\n",
    "    y_max=1e6, figsize=(8,8))\n",
    "  angle_hist_fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_angle_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  angle_neighbor_fig = pf.plot_weight_nearest_neighbor_histogram(analyzer.plot_matrix, num_bins=40, angle_min=0,\n",
    "    angle_max=90, y_max=1e3, figsize=(8,8))\n",
    "  angle_neighbor_fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_neighbor_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 0\n",
    "analyzer = analyzer_list[model_index]\n",
    "\n",
    "#min_angle = 0.5\n",
    "#max_angle = 50\n",
    "\n",
    "min_angle = 20\n",
    "max_angle = 70\n",
    "\n",
    "#min_angle = 89\n",
    "#max_angle = 91\n",
    "\n",
    "#min_angle = 100\n",
    "#max_angle = 180\n",
    "\n",
    "vectors = np.argwhere(np.logical_and(analyzer.neuron_angles<max_angle,\n",
    "  analyzer.neuron_angles>min_angle))\n",
    "\n",
    "if vectors.shape[0] > 0:\n",
    "  vector_id = 9\n",
    "  analyzer.bf_id0 = vectors[vector_id, 0] # RICA 83, 85; vae 4, 72; lca 3, 588\n",
    "  analyzer.bf_id1 = vectors[vector_id, 1]\n",
    "  fig, ax = plt.subplots(2)\n",
    "  ax[0] = pf.clear_axis(ax[0])\n",
    "  ax[0].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "  ax[0].set_title(str(analyzer.bf_id0))\n",
    "  ax[1] = pf.clear_axis(ax[1])\n",
    "  ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "  ax[1].set_title(str(analyzer.bf_id1))\n",
    "  plt.show()\n",
    "\n",
    "  analyzer.bf0 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0].reshape(\n",
    "    (analyzer.model_params.num_pixels))\n",
    "  #analyzer.bf0 = (analyzer.bf0 - np.min(analyzer.bf0)) / (np.max(analyzer.bf0) - np.min(analyzer.bf0))\n",
    "  \n",
    "  analyzer.bf1 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1].reshape(\n",
    "    (analyzer.model_params.num_pixels))\n",
    "  #analyzer.bf1 = (analyzer.bf1 - np.min(analyzer.bf1)) / (np.max(analyzer.bf1) - np.min(analyzer.bf1))\n",
    "  \n",
    "  analyzer.bf0_norm = np.linalg.norm(analyzer.bf0)\n",
    "  analyzer.bf1_norm = np.linalg.norm(analyzer.bf1)\n",
    "  analyzer.bf0 = analyzer.bf0 / analyzer.bf0_norm\n",
    "  analyzer.bf1 = analyzer.bf1 / analyzer.bf1_norm\n",
    "  print(\"num vectors = \", vectors.shape[0])\n",
    "  print(\"min angle = \", np.min(analyzer.neuron_angles[vectors[:,0], vectors[:,1]]), \" rad\")\n",
    "  print(\"min angle is at index \", np.argmin(analyzer.neuron_angles[vectors[:,0], vectors[:,1]]))\n",
    "  print(\"BF indices = [\",analyzer.bf_id0,\", \",analyzer.bf_id1,\"]\")\n",
    "  print(\"vector angle\\t= \", analyzer.neuron_angles[analyzer.bf_id0, analyzer.bf_id1]*(np.pi/180),\n",
    "    \" rad\\n\\t\\t= \", analyzer.neuron_angles[analyzer.bf_id0, analyzer.bf_id1], \" deg\")\n",
    "  print(\"bf0 norm = \", analyzer.bf0_norm)\n",
    "  print(\"bf1 norm = \", analyzer.bf1_norm)\n",
    "else:\n",
    "  assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = int(228**2)\n",
    "#x_pts = np.linspace(-0.5, 5.0, int(np.sqrt(num_imgs)))\n",
    "x_pts = np.linspace(-0.5, 3.5, int(np.sqrt(num_imgs)))\n",
    "y_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "X_mesh, Y_mesh = np.meshgrid(x_pts, y_pts)\n",
    "proj_datapoints = np.stack([X_mesh.reshape(num_imgs), Y_mesh.reshape(num_imgs)], axis=1)\n",
    "\n",
    "for analyzer in analyzer_list:\n",
    "  analyzer.proj_datapoints = proj_datapoints\n",
    "  analyzer.proj_matrix, v = analyzer.bf_projections(analyzer.bf0, analyzer.bf1)\n",
    "  analyzer.proj_neuron0 = np.dot(analyzer.proj_matrix, analyzer.bf0).T\n",
    "  analyzer.proj_neuron1 = np.dot(analyzer.proj_matrix, analyzer.bf1).T\n",
    "  analyzer.proj_v = np.dot(analyzer.proj_matrix, v).T\n",
    "  \n",
    "  analyzer.datapoints = np.stack([np.dot(analyzer.proj_matrix.T, analyzer.proj_datapoints[data_id,:])\n",
    "    for data_id in range(num_imgs)]) #inject\n",
    "  analyzer.datapoints, orig_shape = dp.reshape_data(analyzer.datapoints, flatten=False)[:2]\n",
    "  analyzer.datapoints = {\"test\": Dataset(analyzer.datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "  \n",
    "  #params={\"whiten_data\":analyzer.model_params.whiten_data}\n",
    "  #if params[\"whiten_data\"]:\n",
    "  #  params[\"whiten_method\"] = analyzer.model_params.whiten_method\n",
    "  #analyzer.datapoints = analyzer.model.preprocess_dataset(analyzer.datapoints, params=params)\n",
    "  \n",
    "  #analyzer.datapoints = analyzer.model.preprocess_dataset(analyzer.datapoints, params=analyzer.model_params)\n",
    "  analyzer.datapoints = analyzer.model.reshape_dataset(analyzer.datapoints, analyzer.model_params)\n",
    "  \n",
    "  #analyzer.datapoints[\"test\"].images = (\n",
    "  #  (analyzer.datapoints[\"test\"].images - np.min(analyzer.datapoints[\"test\"].images, axis=1, keepdims=True))\n",
    "  #  / (np.max(analyzer.datapoints[\"test\"].images, axis=1, keepdims=True)\n",
    "  #  - np.min(analyzer.datapoints[\"test\"].images, axis=1, keepdims=True)))  \n",
    "  \n",
    "  #analyzer.datapoints[\"test\"].images /= np.max(np.abs(analyzer.datapoints[\"test\"].images))\n",
    "  #analyzer.datapoints[\"test\"].images *= analyzer.analysis_params.input_scale*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  activations = analyzer.compute_activations(analyzer.datapoints[\"test\"].images)\n",
    "  activity_max = np.amax(np.abs(activations)) # Rescale between -1 and 1\n",
    "  analyzer.norm_activity = activations / (activity_max + 0.00001)\n",
    "  #analyzer.norm_activity = activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  num_plots_y = 1\n",
    "  num_plots_x = 2\n",
    "  gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5, width_ratios=[4, 1])\n",
    "  fig = plt.figure(figsize=(6,6))\n",
    "  curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "  #cmap = plt.get_cmap('tab20b')\n",
    "  cmap = plt.get_cmap('viridis')\n",
    "  vmin = np.floor(np.min(analyzer.norm_activity))#0.0\n",
    "  vmax = np.ceil(np.max(analyzer.norm_activity))#1.0\n",
    "  \n",
    "  #name_suffix = \"continuous\"\n",
    "  #pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1],\n",
    "  #  vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.5, c=analyzer.norm_activity[:, analyzer.bf_id0], s=5.0)\n",
    "  \n",
    "  levels = 5\n",
    "  name_suffix = \"\"\n",
    "  contsf = curve_ax.contourf(X_mesh, Y_mesh,\n",
    "    analyzer.norm_activity[:, analyzer.bf_id0].reshape(int(np.sqrt(num_imgs)), int(np.sqrt(num_imgs))),\n",
    "    levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "  \n",
    "  curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(),\n",
    "    analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "    head_length=0.15, fc='r', ec='r')\n",
    "  curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(),\n",
    "    analyzer.proj_neuron1[1].item(), width=0.05, head_width=0.15,\n",
    "    head_length=0.15, fc='w', ec='w')\n",
    "  curve_ax.arrow(0, 0, analyzer.proj_v[0].item(), analyzer.proj_v[1].item(), width=0.05, head_width=0.15,\n",
    "   head_length=0.15, linestyle=\"-.\", fc='k', ec='k')\n",
    "  \n",
    "  #curve_ax.set_title(\"Angle = \"+\"{:.2f}\".format(analyzer.neuron_angles[bf_id0, bf_id1])+\" deg\", fontsize=16)\n",
    "  \n",
    "  curve_ax.set_ylim([-2, 2])\n",
    "  \n",
    "  curve_ax.set_xlim([-2, 2])\n",
    "  #curve_ax.set_xlim([-0.5, 5.0])\n",
    "  \n",
    "  curve_ax.set_aspect(\"equal\")\n",
    "  #cbar = pf.add_colorbar_to_im(pts, aspect=20, pad_fraction=0.5, labelsize=16, ticks=[vmin, vmax])\n",
    "  #cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "  \n",
    "  gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], wspace=2, hspace=-0.55)\n",
    "  bf1_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "  bf1_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "  bf1_ax.set_title(\"Primary\\nBasis Function\", color='r', fontsize=16)\n",
    "  bf2_ax = pf.clear_axis(fig.add_subplot(gs2[1]))\n",
    "  bf2_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "  bf2_ax.set_title(\"Comparison\\nBasis Function\", color='k', fontsize=16)\n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_response_contours_bf0id\"+str(analyzer.bf_id0)+\"_bf1id\"+str(analyzer.bf_id1)+name_suffix+\".png\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyzer in analyzer_list:\n",
    "  fig, ax = plt.subplots(1, figsize=(6,6))\n",
    "  cmap = plt.get_cmap('viridis')\n",
    "  vmin = np.floor(np.min(analyzer.norm_activity))\n",
    "  vmax = np.ceil(np.max(analyzer.norm_activity))\n",
    "  \n",
    "  act_resh = analyzer.norm_activity[:,analyzer.bf_id0].reshape(int(np.sqrt(num_imgs)), int(np.sqrt(num_imgs)))\n",
    "  levels = 0\n",
    "  contsf = ax.contour(X_mesh, Y_mesh, act_resh,\n",
    "    levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap, linestyles=\"dashed\")\n",
    "  \n",
    "  ax.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "    head_length=0.15, fc='k', ec='k')\n",
    "  \n",
    "  ax.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "    head_length=0.15, fc='k', ec='k')\n",
    "  \n",
    "  ax.set_ylim([-2.0, 2.0])\n",
    "  ax.set_xlim([0, 2.0])\n",
    "  ax.set_aspect(\"equal\")\n",
    "  ax.xaxis.grid(True, zorder=0)\n",
    "  ax.yaxis.grid(True, zorder=0)\n",
    "  \n",
    "  fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_single_response_contour_bf0id\"+str(analyzer.bf_id0)+\".png\",\n",
    "    transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = analyzer.datapoints[\"test\"].images.reshape([int(np.sqrt(num_imgs)), int(np.sqrt(num_imgs)),\n",
    "  int(np.sqrt(analyzer.model_params.num_pixels)), int(np.sqrt(analyzer.model_params.num_pixels))])\n",
    "\n",
    "num_plots_y = 3\n",
    "num_plots_x = 3\n",
    "gs = gridspec.GridSpec(num_plots_y, num_plots_x)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "half_sqrt_imgs = int(np.sqrt(num_imgs)/2)\n",
    "filter_indices = [(0,0), (0, half_sqrt_imgs), (0, -1),\n",
    "  (half_sqrt_imgs, 0), (half_sqrt_imgs, half_sqrt_imgs), (half_sqrt_imgs, -1),\n",
    "  (-1, 0), (-1, half_sqrt_imgs), (-1, -1)]\n",
    "filter_idx = 0\n",
    "for plot_id in  np.ndindex((num_plots_y, num_plots_x)):\n",
    "  ax = pf.clear_axis(fig.add_subplot(gs[plot_id]))\n",
    "  if filter_idx < num_imgs:\n",
    "    ax.imshow(test_imgs[filter_indices[filter_idx][0], filter_indices[filter_idx][1], ...], cmap=\"Greys_r\")\n",
    "  filter_idx += 1\n",
    "fig.suptitle(\"Basis Function Interpolation\", y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_names = [\"inference/activity:0\"]\n",
    "test_datapoints = analyzer.analysis_params.input_scale*np.squeeze(np.stack([analyzer.bf0, analyzer.bf1]))\n",
    "test_activations = analyzer.evaluate_model(test_datapoints, var_names)[\"inference/activity:0\"]\n",
    "print(\"num nonzero for bf1: \", np.count_nonzero(test_activations[0,:]))\n",
    "print(\"num nonzero for bf2: \", np.count_nonzero(test_activations[1,:]))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(test_activations[1,:], rwidth=0.5)\n",
    "ax.set_title(\"Activity histogram for a basis function as input\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#def plot_iso_response_contours(cmap, save_filename)\n",
    "num_plots_y = 1\n",
    "num_plots_x = 2\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5)#, width_ratios=[4, 1])\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "\n",
    "pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1], cmap=cmap, c=\"blue\", s=0.5)\n",
    "curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "  head_length=0.15, fc='k', ec='k')\n",
    "#curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(), analyzer.proj_neuron1[1].item(), width=0.05, head_width=0.15,\n",
    "#  head_length=0.15, fc='r', ec='r')\n",
    "curve_ax.arrow(0, 0, analyzer.proj_v[0].item(), analyzer.proj_v[1].item(), width=0.05, head_width=0.15,\n",
    "  head_length=0.15, fc='k', ec='k')\n",
    "curve_ax.set_ylim([-2.0, 2.0])\n",
    "curve_ax.set_xlim([-2.0, 2.0])\n",
    "curve_ax.set_aspect(\"equal\")\n",
    "\n",
    "#img_idx = -1\n",
    "#pts = curve_ax.scatter(proj_datapoints[img_idx, 0], proj_datapoints[img_idx, 1], cmap=cmap, c=\"red\", s=50.0)\n",
    "\n",
    "def plt_img(axis, img_idx):\n",
    "  axis.imshow(analyzer.datapoints[\"test\"].images[img_idx, ...].reshape((int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "    int(np.sqrt(analyzer.model_params.num_pixels)))), cmap=\"Greys_r\")\n",
    "  axis.set_title(\"Position \"+str(img_idx))\n",
    "  return axis\n",
    "\n",
    "img_idx = 0\n",
    "gs2 = gridspec.GridSpecFromSubplotSpec(3, 3, gs1[1])#, wspace=2, hspace=-0.2)\n",
    "bf1_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[0])), img_idx)\n",
    "\n",
    "img_idx = 49\n",
    "bf2_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[1])), img_idx)\n",
    "\n",
    "img_idx = 99\n",
    "bf3_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[2])), img_idx)\n",
    "\n",
    "img_idx = 5000\n",
    "bf4_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[3])), img_idx)\n",
    "\n",
    "img_idx = 5049\n",
    "bf5_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[4])), img_idx)\n",
    "\n",
    "img_idx = 5099\n",
    "bf6_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[5])), img_idx)\n",
    "\n",
    "img_idx = -99\n",
    "bf7_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[6])), img_idx)\n",
    "\n",
    "img_idx = -49\n",
    "bf8_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[7])), img_idx)\n",
    "\n",
    "img_idx = -1\n",
    "bf9_ax = plt_img(pf.clear_axis(fig.add_subplot(gs2[8])), img_idx)\n",
    "\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/projection_visualization\"+str(analyzer.bf_id0)+\"_bf1id\"+str(analyzer.bf_id1)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target = x_pts[int(6*np.sqrt(num_imgs)/8)] # find a location to take a slice\n",
    "slice_indices = np.where(analyzer.proj_datapoints[:,0]==x_target)[0]\n",
    "x_vals = analyzer.proj_datapoints[slice_indices,:][:,1] # slice grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparison_points = 8\n",
    "num_plots_y = 1\n",
    "num_plots_x = 1+num_comparison_points\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, hspace=0.6, wspace=0.6)\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for yid in range(num_plots_y):\n",
    "  ax1 = fig.add_subplot(gs1[yid, 0])\n",
    "\n",
    "  cmap = plt.get_cmap('viridis')\n",
    "  vmin = 0.0\n",
    "  vmax = 1.0\n",
    "  rank_indices = np.argsort(analyzer.norm_activity[slice_indices, analyzer.bf_id0])\n",
    "  slice_datapoints = analyzer.proj_datapoints[slice_indices,:]\n",
    "  pts = ax1.scatter(slice_datapoints[rank_indices,0],\n",
    "    slice_datapoints[rank_indices,1], vmin=vmin, vmax=vmax,\n",
    "    cmap=cmap, c=analyzer.norm_activity[slice_indices, analyzer.bf_id0][rank_indices], s=1.0)\n",
    "  ax1.arrow(0, 0, analyzer.proj_neuron0[0].item(), analyzer.proj_neuron0[1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='r', ec='r')\n",
    "  ax1.arrow(0, 0, analyzer.proj_neuron1[0].item(), analyzer.proj_neuron1[1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='k', ec='k')\n",
    "  ax1.set_xlim([-2,2])\n",
    "  ax1.set_ylim([-2,2])\n",
    "  ax1.set_aspect(\"equal\")\n",
    "  ax1.set_title(\"bf1id=\"+str(analyzer.bf_id1))\n",
    "\n",
    "  y_indices = np.arange(slice_indices.size)[::int(slice_indices.size/num_comparison_points)]\n",
    "  if y_indices.size < num_comparison_points:\n",
    "    y_indices.append(-1)\n",
    "  for pid, xid in enumerate(range(1, num_plots_x)):\n",
    "    ax = pf.clear_axis(fig.add_subplot(gs1[yid, xid]))\n",
    "    images = analyzer.datapoints[\"test\"].images[slice_indices, :]\n",
    "    ax.imshow(images[y_indices[pid], :].reshape([int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "      int(np.sqrt(analyzer.model_params.num_pixels))]), cmap=\"Greys_r\")\n",
    "    subfig_title = (\"({:.1f}, \".format(analyzer.proj_datapoints[slice_indices,:][y_indices[pid],0])\n",
    "      +\"{:.1f})\".format(analyzer.proj_datapoints[slice_indices,:][y_indices[pid],1]))\n",
    "    ax.set_title(subfig_title)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/single_slice_example_bf0id\"+str(analyzer.bf_id0)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(8,8))\n",
    "ax[0].plot(x_vals, analyzer.norm_activity[slice_indices, analyzer.bf_id0], color='b', alpha=0.3) # x_vals in the 2-D grid are plotted along the x axis\n",
    "ax[0].set_title(\"Normalized Responses to Orthogonal Inputs\", y=1.08)\n",
    "ax[0].set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax[0].set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax[0].grid(True)\n",
    "ax[0].set_ylim([0.0, 1.0])\n",
    "ax[0].set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "ax[0].set_aspect((np.max(x_vals)-np.min(x_vals)))\n",
    "ax[0].tick_params(labelsize=14)\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "ax[1].set_title(\"Basis Function\", y=1.08)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/bf_example_curvature_bf0id\"+str(analyzer.bf_id0)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Compute a unit vector that is in the same plane as a given basis function pair (B1,B2) and is orthogonal to B1, where B1 is the target basis for comparison and B2 is selected from all other bases.\n",
    "* Construct a line of data points in this plane\n",
    "* Project the data points into image space, compute activations, plot activations\n",
    "\"\"\"\n",
    "pop_num_imgs = 100\n",
    "\n",
    "orthogonal_list = [idx for idx in range(analyzer.bf_stats[\"num_outputs\"]) if idx != analyzer.bf_id0]\n",
    "num_orthogonal = len(orthogonal_list)\n",
    "\n",
    "pop_x_pts = np.linspace(-2.0, 2.0, int(pop_num_imgs))\n",
    "pop_y_pts = np.linspace(-2.0, 2.0, int(pop_num_imgs))\n",
    "pop_X, pop_Y = np.meshgrid(pop_x_pts, pop_y_pts)\n",
    "pop_proj_datapoints = np.stack([pop_X.reshape(pop_num_imgs**2),\n",
    "  pop_Y.reshape(pop_num_imgs**2)], axis=1) # construct a grid\n",
    "x_target = pop_x_pts[int(6*pop_num_imgs/8)] # find a location to take a slice\n",
    "slice_indices = np.where(pop_proj_datapoints[:,0]==x_target)[0]\n",
    "pop_proj_datapoints = pop_proj_datapoints[slice_indices,:] # slice grid\n",
    "\n",
    "pop_datapoints = [None,]*num_orthogonal\n",
    "pop_proj_neurons = [None,]*num_orthogonal\n",
    "#proj_matrix_list = []\n",
    "for pop_idx, tmp_bf_id1 in enumerate(orthogonal_list):\n",
    "  tmp_bf1 = analyzer.bf_stats[\"basis_functions\"][tmp_bf_id1].reshape((analyzer.model_params.num_pixels))\n",
    "  tmp_bf1 /= np.linalg.norm(tmp_bf1)\n",
    "  tmp_proj_matrix, v = analyzer.bf_projections(analyzer.bf0, tmp_bf1) \n",
    "  #if pop_idx > 0: # Check to make sure you're not duplicating any of the orth planes\n",
    "  #  for comp_proj_matrix in proj_matrix_list:\n",
    "  #    if np.allclose(tmp_proj_matrix, comp_proj_matrix):\n",
    "  #      assert False\n",
    "  #proj_matrix_list.append(tmp_proj_matrix)\n",
    "  pop_proj_neurons[pop_idx] = (np.dot(tmp_proj_matrix, analyzer.bf0).T, np.dot(tmp_proj_matrix, tmp_bf1).T)\n",
    "  pop_datapoints[pop_idx] = np.dot(pop_proj_datapoints, tmp_proj_matrix)#[slice_indices,:]\n",
    "\n",
    "pop_datapoints = np.reshape(np.stack(pop_datapoints, axis=0),\n",
    "  [num_orthogonal*pop_num_imgs, analyzer.model_params.num_pixels])\n",
    "\n",
    "pop_datapoints = dp.reshape_data(pop_datapoints, flatten=False)[0]\n",
    "pop_datapoints = {\"test\": Dataset(pop_datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "#pop_datapoints = analyzer.model.preprocess_dataset(pop_datapoints,\n",
    "#  params={\"whiten_data\":analyzer.model_params.whiten_data,\n",
    "#  \"whiten_method\":analyzer.model_params.whiten_method})\n",
    "pop_datapoints = analyzer.model.reshape_dataset(pop_datapoints, analyzer.model_params)\n",
    "#pop_datapoints[\"test\"].images /= np.max(np.abs(pop_datapoints[\"test\"].images))\n",
    "#pop_datapoints[\"test\"].images *= analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_activations = analyzer.compute_activations(pop_datapoints[\"test\"].images)[:, analyzer.bf_id0]\n",
    "pop_activations = pop_activations.reshape([num_orthogonal, pop_num_imgs])\n",
    "pop_norm_activity = pop_activations / np.amax(np.abs(pop_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparison_points = 8\n",
    "num_plots_y = 4\n",
    "num_plots_x = 1+num_comparison_points\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, hspace=0.6, wspace=0.3)\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for yid in range(num_plots_y):\n",
    "  orthog_idx = np.random.choice(np.arange(num_orthogonal), replace=False)\n",
    "  ax1 = fig.add_subplot(gs1[yid, 0])\n",
    "  pop_orthog_activity = pop_norm_activity[orthog_idx, :] \n",
    "\n",
    "  cmap = plt.get_cmap('viridis')\n",
    "  \n",
    "  vmin = np.floor(np.min(pop_orthog_activity))\n",
    "  vmax = np.ceil(np.max(pop_orthog_activity))\n",
    "  rank_indices = np.argsort(pop_orthog_activity)\n",
    "  pts = ax1.scatter(pop_proj_datapoints[rank_indices,0], pop_proj_datapoints[rank_indices,1],\n",
    "    vmin=vmin, vmax=vmax, cmap=cmap, c=pop_orthog_activity[rank_indices], s=1.0)\n",
    "  ax1.arrow(0, 0, pop_proj_neurons[orthog_idx][0][0].item(), pop_proj_neurons[orthog_idx][0][1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='r', ec='r')\n",
    "  ax1.arrow(0, 0, pop_proj_neurons[orthog_idx][1][0].item(), pop_proj_neurons[orthog_idx][1][1].item(),\n",
    "    width=0.05, head_width=0.15, head_length=0.15, fc='k', ec='k')\n",
    "  ax1.set_xlim([-2,2])\n",
    "  ax1.set_ylim([-2,2])\n",
    "  ax1.set_aspect(\"equal\")\n",
    "  ax1.set_title(\"bfid=\"+str(orthogonal_list[orthog_idx]))\n",
    "\n",
    "  y_indices = np.arange(pop_num_imgs)[::int(pop_num_imgs/num_comparison_points)]\n",
    "  if y_indices.size < num_comparison_points:\n",
    "    y_indices.append(-1)\n",
    "  for pid, xid in enumerate(range(1, num_plots_x)):\n",
    "    ax = pf.clear_axis(fig.add_subplot(gs1[yid, xid]))\n",
    "    imid = np.ravel_multi_index((orthog_idx, y_indices[pid]), (num_orthogonal, pop_num_imgs))\n",
    "    ax.imshow(pop_datapoints[\"test\"].images[imid, ...].reshape([int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "      int(np.sqrt(analyzer.model_params.num_pixels))]), cmap=\"Greys_r\")\n",
    "    subfig_title = (\"({:.1f}, \".format(pop_proj_datapoints[y_indices[pid],0])\n",
    "      +\"{:.1f})\".format(pop_proj_datapoints[y_indices[pid],1]))\n",
    "    ax.set_title(subfig_title)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/orthogonal_slice_examples_bf0id\"+str(analyzer.bf_id0)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Construct the set of unit-length bases that are orthogonal to B1 (there should be B1.size-1 of them)\n",
    "* Construct a line of data points in each plane defined by B1 and a given orthogonal basis\n",
    "* Project the data points into image space, compute activations, plot activations\n",
    "\"\"\"\n",
    "def find_orth(matrix):\n",
    "  \"\"\"\n",
    "  https://stackoverflow.com/questions/50660389/generate-a-vector-that-is-orthogonal-to-a-set-of-other-vectors-in-any-dimension\n",
    "  \"\"\"\n",
    "  rand_vect = np.random.rand(matrix.shape[0], 1)\n",
    "  new_matrix = np.hstack((matrix, rand_vect))\n",
    "  candidate_vect = np.zeros(matrix.shape[1]+1)\n",
    "  candidate_vect[-1] = 1\n",
    "  orth_vect = np.linalg.lstsq(new_matrix.T, candidate_vect, rcond=None)[0]\n",
    "  orth_vect = np.squeeze((orth_vect  / np.linalg.norm(orth_vect)).T) \n",
    "  return orth_vect\n",
    "\n",
    "rand_pop_num_imgs = 100\n",
    "\n",
    "rand_num_orthogonal = analyzer.bf_stats[\"num_inputs\"]-1\n",
    "\n",
    "pop_x_pts = np.linspace(-2.0, 2.0, int(rand_pop_num_imgs))\n",
    "pop_y_pts = np.linspace(-2.0, 2.0, int(rand_pop_num_imgs))\n",
    "pop_X, pop_Y = np.meshgrid(pop_x_pts, pop_y_pts)\n",
    "rand_pop_proj_datapoints = np.stack([pop_X.reshape(rand_pop_num_imgs**2),\n",
    "  pop_Y.reshape(rand_pop_num_imgs**2)], axis=1) # construct a grid\n",
    "x_target = pop_x_pts[int(6*rand_pop_num_imgs/8)] # find a location to take a slice\n",
    "slice_indices = np.where(rand_pop_proj_datapoints[:,0]==x_target)[0]\n",
    "rand_pop_proj_datapoints = rand_pop_proj_datapoints[slice_indices,:] # slice grid\n",
    "\n",
    "orth_col_matrix = analyzer.bf0.T[:,None]\n",
    "rand_pop_datapoints = [None,]*rand_num_orthogonal\n",
    "pop_proj_neurons = [None,]*rand_num_orthogonal\n",
    "for pop_idx in range(rand_num_orthogonal):\n",
    "  v = find_orth(orth_col_matrix)\n",
    "  tmp_proj_matrix = np.stack([analyzer.bf0, v], axis=0)\n",
    "  orth_col_matrix = np.append(orth_col_matrix, v[:,None], axis=1)\n",
    "  pop_proj_neurons[pop_idx] = (np.dot(tmp_proj_matrix, analyzer.bf0).T, np.dot(tmp_proj_matrix, tmp_bf1).T)\n",
    "  rand_pop_datapoints[pop_idx] = np.dot(rand_pop_proj_datapoints, tmp_proj_matrix)#[slice_indices,:]\n",
    "\n",
    "rand_pop_datapoints = np.reshape(np.stack(rand_pop_datapoints, axis=0),\n",
    "  [rand_num_orthogonal*rand_pop_num_imgs, analyzer.model_params.num_pixels])\n",
    "\n",
    "rand_pop_datapoints = dp.reshape_data(rand_pop_datapoints, flatten=False)[0]\n",
    "rand_pop_datapoints = {\"test\": Dataset(rand_pop_datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "#rand_pop_datapoints = analyzer.model.preprocess_dataset(rand_pop_datapoints,\n",
    "#  params={\"whiten_data\":analyzer.model_params.whiten_data,\n",
    "#  \"whiten_method\":analyzer.model_params.whiten_method})\n",
    "rand_pop_datapoints = analyzer.model.reshape_dataset(rand_pop_datapoints, analyzer.model_params)\n",
    "#rand_pop_datapoints[\"test\"].images /= np.max(np.abs(rand_pop_datapoints[\"test\"].images))\n",
    "#rand_pop_datapoints[\"test\"].images *= analyzer.analysis_params.input_scale\n",
    "\n",
    "if all(np.abs(np.dot(analyzer.bf0, col)) < 1e-9 for col in orth_col_matrix[:,1:].T):\n",
    "  print(\"Success\")\n",
    "else:\n",
    "  count = np.sum([int(np.abs(np.dot(analyzer.bf0, col)) < 1e-9) for col in orth_col_matrix[:,1:].T])\n",
    "  print(\"Failure,\", count, \"were non-orthogonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_pop_activations = analyzer.compute_activations(rand_pop_datapoints[\"test\"].images)[:, analyzer.bf_id0]\n",
    "rand_pop_activations = rand_pop_activations.reshape([rand_num_orthogonal, rand_pop_num_imgs])\n",
    "rand_pop_norm_activity = rand_pop_activations / np.amax(np.abs(rand_pop_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6,6))\n",
    "for orthog_idx in range(num_orthogonal):\n",
    " ax.plot(pop_proj_datapoints[:,1], pop_norm_activity[orthog_idx, :], color='b', alpha=0.05)\n",
    "ax.set_title(\"Normalized Responses\\nto Orthogonal Inputs\", y=1.08, fontsize=16)\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=16)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=16)\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlim([np.min(x_vals), np.max(x_vals)])\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(14) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(14) \n",
    "ax.set_aspect((np.max(x_vals)-np.min(x_vals)))#/(np.max(pop_norm_activity)-np.min(pop_norm_activity)))\n",
    "ax.tick_params(labelsize=14)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/bf_curvatures_bf0id\"+str(analyzer.bf_id0)+\".png\", transparent=True,\n",
    "  bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = [np.polynomial.polynomial.polyfit(pop_proj_datapoints[:,1], pop_norm_activity[orthog_idx,:], deg=2)\n",
    "  for orthog_idx in range(num_orthogonal)]\n",
    "fits = [np.polynomial.polynomial.polyval(pop_proj_datapoints[:,1], coeff) for coeff in coeffs]\n",
    "curvatures = [np.polyder(fit, m=2) for fit in fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_coeffs = [np.polynomial.polynomial.polyfit(rand_pop_proj_datapoints[:,1], rand_pop_norm_activity[orthog_idx,:],\n",
    "  deg=2) for orthog_idx in range(rand_num_orthogonal)]\n",
    "rand_fits = [np.polynomial.polynomial.polyval(rand_pop_proj_datapoints[:,1], coeff) for coeff in rand_coeffs]\n",
    "rand_curvatures = [np.polyder(fit, m=2) for fit in rand_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(8,8))\n",
    "for orthog_idx in range(num_orthogonal):\n",
    "  ax[0].plot(pop_proj_datapoints[:,1], fits[orthog_idx], color='r', alpha=0.05)\n",
    "ax[0].set_title(\"Polynomial Fit Responses\\nto Orthogonal Inputs\", y=1.08, fontsize=16)\n",
    "ax[0].set_ylabel(\"Normalized Activation\", fontsize=16)\n",
    "ax[0].set_xlabel(\"Distance from Basis Function\", fontsize=16)\n",
    "for tick in ax[0].xaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(14) \n",
    "for tick in ax[0].yaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(14) \n",
    "ax[0].grid(True)\n",
    "ax[0].set_ylim([0.0, 1.1])\n",
    "ax[0].set_xlim([np.min(pop_proj_datapoints[:,1]), np.max(pop_proj_datapoints[:,1])])\n",
    "ax[0].set_aspect((np.max(pop_proj_datapoints[:,1])-np.min(pop_proj_datapoints[:,1])))\n",
    "ax[0].tick_params(labelsize=14)\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "ax[1].set_title(\"Basis Function\", y=1.08)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/fit_curvatures_bf0id\"+str(analyzer.bf_id0)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "bf_curvatures = np.stack(coeffs, axis=0)[:,2]\n",
    "rand_curvatures = np.stack(rand_coeffs, axis=0)[:,2]\n",
    "\n",
    "num_bins = 50\n",
    "#bins = np.linspace(np.amin([np.amin(bf_curvatures), np.amin(bf_curvatures), np.amin(rand_curvatures), np.amin(rand_curvatures)]),\n",
    "#  np.amax([np.amax(bf_curvatures), np.amax(bf_curvatures), np.amax(rand_curvatures), np.amax(rand_curvatures)]), num_bins)\n",
    "bins = np.linspace(-0.1,#np.amin([np.amin(bf_curvatures), np.amin(bf_curvatures), np.amin(rand_curvatures), np.amin(rand_curvatures)]),\n",
    "  0.0, num_bins)\n",
    "\n",
    "pop_hist, bin_edges = np.histogram(bf_curvatures.flatten(), bins)\n",
    "pop_hist = pop_hist / np.max(pop_hist) # sum to 1\n",
    "\n",
    "rand_hist, _ = np.histogram(rand_curvatures.flatten(), bins)\n",
    "rand_hist = rand_hist / np.max(rand_hist) # sum to 1\n",
    "\n",
    "bin_left, bin_right = bin_edges[:-1], bin_edges[1:]\n",
    "bin_centers = bin_left + (bin_right - bin_left)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16,9))\n",
    "\n",
    "#ax.bar(bin_centers, hist_1568, width=0.002, log=False, color=\"r\", alpha=0.5, align=\"center\", label=\"LCA-1568 Basis Projections\")\n",
    "#ax.bar(bin_centers, rand_hist_1568, width=0.002, log=False, color=\"g\", alpha=0.5, align=\"center\", label=\"LCA-1568 Random Projections\")\n",
    "ax.bar(bin_centers, pop_hist, width=0.0022, log=False, color=\"r\", alpha=0.5, align=\"center\", label=\"Basis Projection\")#LCA-768 Basis Projections\")\n",
    "ax.bar(bin_centers, rand_hist, width=0.0022, log=False, color=\"g\", alpha=0.5, align=\"center\", label=\"Random Projection\")#LCA-768 Random Projections\")\n",
    "\n",
    "#ax.plot(bin_centers, hist, color=\"r\", alpha=0.5, linestyle=\"--\", drawstyle=\"steps-mid\", label=\"LCA-1568 Basis Projections\")\n",
    "#ax.plot(bin_centers, rand_hist, color=\"g\", alpha=0.5, linestyle=\"--\", drawstyle=\"steps-mid\", label=\"LCA-1568 Random Projections\")\n",
    "#ax.plot(bin_centers, pop_hist, color=\"b\", alpha=0.5, linestyle=\"--\", drawstyle=\"steps-mid\", label=\"LCA-768 Basis Projections\")\n",
    "#ax.plot(bin_centers, rand_hist, color=\"k\", alpha=0.5, linestyle=\"--\", drawstyle=\"steps-mid\", label=\"LCA-768 Random Projections\")\n",
    "\n",
    "ax.set_xticks(bin_left, minor=True)\n",
    "ax.set_xticks(bin_left[::15], minor=False)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.3f\"))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(24) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(24) \n",
    "\n",
    "ax.set_title(\"Histogram of Curvatures\", fontsize=32)\n",
    "#ax.set_xlabel(\"Second Order Polyfit Coefficient\\n(Negative Indicates Exo-Origin)\", fontsize=32)\n",
    "ax.set_xlabel(\"Curvature\", fontsize=32)\n",
    "ax.set_ylabel(\"Count\", fontsize=32)\n",
    "ax.legend(loc=2, fontsize=32)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/histogram_of_curvatures_bf0id\"+str(analyzer.bf_id0)+\".png\",\n",
    "  transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.logical_and(np.greater_equal(curvatures, -0.07), np.less_equal(curvatures, -0.061)))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concavity = np.asarray([np.sign(coeffs[idx][2]) for idx in range(len(coeffs))])\n",
    "num_endo = np.sum(concavity>0)\n",
    "endo_indices = np.where(concavity>0)[0]\n",
    "num_exo = np.sum(concavity<0)\n",
    "exo_indices = np.where(concavity<0)[0]\n",
    "print(\"num >0 (tolerant/invariant/endo-origin):\", num_endo,\n",
    "  \"\\nnum <0 (selective/equivariant/exo-origin):\", num_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "for idx in endo_indices:\n",
    "  ax.plot(pop_proj_datapoints[:,1], fits[idx], color=\"g\", alpha=0.3)\n",
    "ax.set_title(\"Normalized Responses to Invariant Inputs\")\n",
    "ax.set_ylabel(\"Normalized Activation\", fontsize=14)\n",
    "ax.set_xlabel(\"Distance from Basis Function\", fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlim([np.min(pop_proj_datapoints[:,1]), np.max(pop_proj_datapoints[:,1])])\n",
    "ax.set_aspect((np.max(pop_proj_datapoints[:,1])-np.min(pop_proj_datapoints[:,1])))\n",
    "ax.tick_params(labelsize=14)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/fit_invariant_curvatures.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_exo_index = np.argmin(concavity) # image index with the maximum exo-origin curviture\n",
    "max_endo_index = np.argmax(concavity) # image index with the maximum endo-origin curviture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparison_points = 20\n",
    "num_plots_y = 1\n",
    "num_plots_x = num_comparison_points\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, hspace=0.6, wspace=0.3)\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "y_indices = np.arange(pop_num_imgs)[::int(pop_num_imgs/num_comparison_points)]\n",
    "if y_indices.size < num_comparison_points:\n",
    "  y_indices.append(-1)\n",
    "for pid, xid in enumerate(range(num_plots_x)):\n",
    "  ax = pf.clear_axis(fig.add_subplot(gs1[0, xid]))\n",
    "  imid = np.ravel_multi_index((max_endo_index, y_indices[pid]), (num_orthogonal, pop_num_imgs))\n",
    "  ax.imshow(pop_datapoints[\"test\"].images[imid, ...].reshape([int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "    int(np.sqrt(analyzer.model_params.num_pixels))]), cmap=\"Greys_r\")\n",
    "  subfig_title = (\"({:.1f}, \".format(pop_proj_datapoints[y_indices[pid],0])\n",
    "    +\"{:.1f})\".format(pop_proj_datapoints[y_indices[pid],1]))\n",
    "  ax.set_title(subfig_title)\n",
    "fig.suptitle(\"Images with Maximum Endo-Origin (Tolerant) Curvature\", fontsize=24, y=0.7)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/max_endo_images.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparison_points = 20\n",
    "num_plots_y = 1\n",
    "num_plots_x = num_comparison_points\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, hspace=0.6, wspace=0.3)\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "y_indices = np.arange(pop_num_imgs)[::int(pop_num_imgs/num_comparison_points)]\n",
    "if y_indices.size < num_comparison_points:\n",
    "  y_indices.append(-1)\n",
    "for pid, xid in enumerate(range(num_plots_x)):\n",
    "  ax = pf.clear_axis(fig.add_subplot(gs1[0, xid]))\n",
    "  imid = np.ravel_multi_index((max_exo_index, y_indices[pid]), (num_orthogonal, pop_num_imgs))\n",
    "  ax.imshow(pop_datapoints[\"test\"].images[imid, ...].reshape([int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "    int(np.sqrt(analyzer.model_params.num_pixels))]), cmap=\"Greys_r\")\n",
    "  subfig_title = (\"({:.1f}, \".format(pop_proj_datapoints[y_indices[pid],0])\n",
    "    +\"{:.1f})\".format(pop_proj_datapoints[y_indices[pid],1]))\n",
    "  ax.set_title(subfig_title)\n",
    "fig.suptitle(\"Images with Maximum Exo-Origin (Selective) Curvature\", fontsize=24, y=0.7)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/max_exo_images.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
