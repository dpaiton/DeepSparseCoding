{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage.measure import compare_psnr\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params(object):\n",
    "  def __init__(self):\n",
    "    self.model_type = \"lca_subspace\"\n",
    "    self.model_name = \"lca_subspace_vh\"\n",
    "    #self.model_name = \"lca_512_vh\"\n",
    "    #self.model_name = \"lca_768_vh\"\n",
    "    #self.model_name = \"lca_1024_vh\"\n",
    "    self.version = \"0.0\"\n",
    "    self.save_info = \"analysis_train_carlini_targeted\"\n",
    "    self.overwrite_analysis_log = False\n",
    "\n",
    "# Computed params\n",
    "analysis_params = params()\n",
    "analysis_params.project_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\")\n",
    "analysis_params.model_dir = (analysis_params.project_dir+analysis_params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "analyzer.setup(analysis_params)\n",
    "analyzer.load_analysis(save_info=analysis_params.save_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normed_image = (\n",
    "  (analyzer.full_image - np.min(analyzer.full_image))\n",
    "  / (np.max(analyzer.full_image) - np.min(analyzer.full_image))).astype(np.float32)\n",
    "\n",
    "normed_recon = (\n",
    "  (analyzer.full_recon - np.min(analyzer.full_recon))\n",
    "  / (np.max(analyzer.full_recon) - np.min(analyzer.full_recon))).astype(np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0] = pf.clear_axis(ax[0])\n",
    "ax[0].imshow(np.squeeze(normed_image), cmap=\"Greys_r\")\n",
    "ax[0].set_title(\"Input Image\", fontsize=16)\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(np.squeeze(normed_recon), cmap=\"Greys_r\")\n",
    "percent_active = \"{:.2f}\".format(analyzer.recon_frac_act*100)\n",
    "psnr = \"{:.2f}\".format(compare_psnr(normed_image, normed_recon, data_range=1))\n",
    "ax[1].set_title(\"Reconstruction\\n\"+percent_active+\" percent active\"+\"\\n\"+\"PSNR = \"+psnr, fontsize=16)\n",
    "plt.show()\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_image_recon.png\", transparent=True,\n",
    "  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not os.path.exists(analyzer.analysis_out_dir+\"/vis/adversarial_recons/\"):\n",
    "  os.makedirs(analyzer.analysis_out_dir+\"/vis/adversarial_recons/\")\n",
    "if not os.path.exists(analyzer.analysis_out_dir+\"/vis/adversarial_stims/\"):\n",
    "  os.makedirs(analyzer.analysis_out_dir+\"/vis/adversarial_stims/\")\n",
    "  \n",
    "pf.plot_image(analyzer.adversarial_input_image.reshape(int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "  int(np.sqrt(analyzer.model_params.num_pixels))), title=\"Input Image\",\n",
    "  save_filename=analyzer.analysis_out_dir+\"/vis/adversarial_input.png\")\n",
    "\n",
    "pf.plot_image(analyzer.adversarial_target_image.reshape(int(np.sqrt(analyzer.model_params.num_pixels)),\n",
    "  int(np.sqrt(analyzer.model_params.num_pixels))), title=\"Input Image\",\n",
    "  save_filename=analyzer.analysis_out_dir+\"/vis/adversarial_target.png\")\n",
    "  \n",
    "for step, recon in enumerate(analyzer.adversarial_recons):\n",
    "  pf.plot_image(recon.reshape(int(np.sqrt(analyzer.model_params.num_pixels)),int(np.sqrt(analyzer.model_params.num_pixels))), title=\"step_\"+str(step),\n",
    "    save_filename=analyzer.analysis_out_dir+\"/vis/adversarial_recons/recon_step_\"+str(step)+\".png\")\n",
    "  \n",
    "for step, stim in enumerate(analyzer.adversarial_images):\n",
    "  pf.plot_image(stim.reshape(int(np.sqrt(analyzer.model_params.num_pixels)),int(np.sqrt(analyzer.model_params.num_pixels))), title=\"step_\"+str(step),\n",
    "    save_filename=analyzer.analysis_out_dir+\"/vis/adversarial_stims/stim_step_\"+str(step)+\".png\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: Add input, target & perturbed images.\n",
    "fig, ax1 = plt.subplots()\n",
    "#line1 = ax1.plot(analyzer.adversarial_input_adv_mses, 'r', label=\"input to perturbed\")\n",
    "#ax1.set_ylim([0, np.max(analyzer.adversarial_input_adv_mses+analyzer.adversarial_target_recon_mses+analyzer.adversarial_target_adv_mses+analyzer.adversarial_adv_recon_mses)])\n",
    "#ax1.tick_params('y', colors='k')\n",
    "ax1.set_xlabel(\"Step\", fontsize=16)\n",
    "ax1.set_ylabel(\"MSE\", fontsize=16)\n",
    "ax1.set_ylim([0, np.max(analyzer.adversarial_target_recon_mses+analyzer.adversarial_target_adv_mses+analyzer.adversarial_adv_recon_mses)])\n",
    "\n",
    "#ax2 = ax1.twinx()\n",
    "line2 = ax1.plot(analyzer.adversarial_target_adv_mses, 'b', label=\"target to perturbed\")\n",
    "#ax2.tick_params('y', colors='k')\n",
    "#ax2.set_ylim(ax1.get_ylim())\n",
    "\n",
    "#ax3 = ax1.twinx()\n",
    "line3 = ax1.plot(analyzer.adversarial_target_recon_mses, 'g', label=\"target to recon\")\n",
    "#ax3.tick_params('y', colors='k')\n",
    "#ax3.set_ylim(ax1.get_ylim())\n",
    "\n",
    "line4 = ax1.plot(analyzer.adversarial_adv_recon_mses, 'k', label=\"perturbed to recon\")\n",
    "\n",
    "#lines = line1+line2+line3+line4\n",
    "lines = line2+line3+line4\n",
    "line_labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, line_labels)#, loc=9)\n",
    "\n",
    "ax1.set_title(analysis_params.model_name, fontsize=16)\n",
    "\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/adversarial_losses.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[\"a_fraction_active\", \"recon_loss\", \"sparse_loss\", \"total_loss\"]\n",
    "labels=[\"activity\", \"recon loss\", \"sparse loss\", \"total loss\"]\n",
    "stats_fig = pf.plot_stats(analyzer.run_stats, keys=keys, labels=labels, start_index=100, figsize=(10,10))\n",
    "stats_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_train_stats.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "atas_fig = pf.plot_data_tiled(analyzer.atas.T, normalize=False, title=\"Activity triggered averages on image data\")\n",
    "atas_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_img_atas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_noise_images = analyzer.num_noise_images\n",
    "if hasattr(analyzer, \"noise_activity\"):\n",
    "  noise_activity = analyzer.noise_activity\n",
    "  noise_atas = analyzer.noise_atas\n",
    "  noise_atcs = analyzer.noise_atcs\n",
    "  noise_atas_fig = pf.plot_data_tiled(noise_atas.T, normalize=False, title=\"Activity triggered averages on standard normal noise data\")\n",
    "  noise_atas_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_noise_atas.png\")\n",
    "  neuron_idx=0\n",
    "  evals, evecs = np.linalg.eigh(noise_atcs[neuron_idx,...]) \n",
    "  top_indices = np.argsort(evals)[::-1]\n",
    "  fig = pf.plot_weights(evecs.T.reshape(256,16,16)[top_indices,:,:])\n",
    "  fig2 = pf.plot_eigenvalues(evals[::-1], ylim=[np.min(evals), np.max(evals)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weight_shape = [analyzer.bf_stats[\"num_outputs\"], analyzer.bf_stats[\"patch_edge_size\"], analyzer.bf_stats[\"patch_edge_size\"]]\n",
    "dict_fig = pf.plot_weights(analyzer.evals[\"lca/weights/w:0\"].T.reshape(weight_shape), title=\"Weights\", figsize=(24,24))\n",
    "dict_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_dict.png\", transparent=True,\n",
    "  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pf.plot_loc_freq_summary(analyzer.bf_stats, figsize=(12, 4), fontsize=16)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/fig_location_frequency_centers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inference_traces(data, activation_threshold, img_idx=None, act_indicator_threshold=None, num_plot_neurons=None):\n",
    "  \"\"\"\n",
    "  Plot of model neurons' inputs over time\n",
    "  Args:\n",
    "    data: [dict] with each trace, with keys [b, u, a, ga, images]\n",
    "      Dictionary is created by analyze_lca.evaluate_inference()\n",
    "    activation_threshold: [float] value of the sparse multiplier, lambda\n",
    "    img_idx: [int] which image in data[\"images\"] to run analysis on\n",
    "    act_indicator_threshold: [float] sets the threshold for when a neuron is marked as \"recently active\"\n",
    "      Recently active neurons are those that became active towards the end of the inference process\n",
    "      Recency is computed as any time step that is greater than num_inference_steps * act_indicator_threshold\n",
    "      Recently active neurons are indicated by a dotted magenta border\n",
    "      This input must be between 0.0 and 1.0\n",
    "    num_plt_neurons: [int] number of neurons to plot. If None, then plot all neurons\n",
    "  \"\"\"\n",
    "  plt.rc('text', usetex=True)\n",
    "  (num_images, num_time_steps, num_neurons) = data[\"b\"].shape\n",
    "  if num_plot_neurons is None:\n",
    "    sqrt_nn = int(np.sqrt(num_neurons))\n",
    "  else:\n",
    "    sqrt_nn = int(np.sqrt(num_plot_neurons))\n",
    "  if img_idx is None:\n",
    "    img_idx = np.random.choice(num_images)\n",
    "  global_max_val = float(np.max(np.abs([data[\"b\"][img_idx,...],\n",
    "    data[\"u\"][img_idx,...], data[\"ga\"][img_idx,...], data[\"a\"][img_idx,...],\n",
    "    np.ones_like(data[\"b\"][img_idx,...])*activation_threshold])))\n",
    "  fig, sub_axes = plt.subplots(sqrt_nn+2, sqrt_nn+1, figsize=(20, 20))\n",
    "  fig.subplots_adjust(hspace=0.20, wspace=0.20)\n",
    "  lines = []\n",
    "  for (axis_idx, axis) in enumerate(fig.axes): # one axis per neuron\n",
    "    if axis_idx < num_neurons:\n",
    "      t = np.arange(data[\"b\"].shape[1])\n",
    "      b = data[\"b\"][img_idx, :, axis_idx]\n",
    "      u = data[\"u\"][img_idx, :, axis_idx]\n",
    "      ga = data[\"ga\"][img_idx, :, axis_idx]\n",
    "      a = data[\"a\"][img_idx, :, axis_idx]\n",
    "      line, = axis.plot(t, b, linewidth=0.25, color=\"g\", label=\"b\")\n",
    "      lines.append(line)\n",
    "      line, = axis.plot(t, u, linewidth=0.25, color=\"b\", label=\"u\")\n",
    "      lines.append(line)\n",
    "      line, = axis.plot(t, ga, linewidth=0.25, color=\"r\", label=\"Ga\")\n",
    "      lines.append(line)\n",
    "      line, = axis.plot(t, [activation_threshold for _ in t], linewidth=0.25, color=\"k\",\n",
    "        linestyle=\":\", dashes=(1,1), label=r\"$\\lambda$\")\n",
    "      lines.append(line)\n",
    "      line, = axis.plot(t, a, linewidth=0.25, color=\"darkorange\", label=\"a\")\n",
    "      lines.append(line)\n",
    "      line, = axis.plot(t, [0 for _ in t], linewidth=0.25, color=\"k\", linestyle=\"-\",\n",
    "        label=\"zero\")\n",
    "      lines.append(line)\n",
    "      if \"fb\" in data.keys():\n",
    "        fb = data[\"fb\"][img_idx,:,axis_idx]\n",
    "        line, = axis.plot(t, fb, linewidth=0.25, color=\"darkgreen\", label=\"fb\")\n",
    "        lines.append(line)\n",
    "        \n",
    "      max_val = np.max(np.abs([b, ga, u, a]))\n",
    "      scale_ratio = max_val / global_max_val\n",
    "      transFigure = fig.transFigure.inverted()\n",
    "      axis_height = axis.get_window_extent().transformed(transFigure).height\n",
    "      line_length = axis_height * scale_ratio\n",
    "      x_offset = 0.002\n",
    "      axis_origin = transFigure.transform(axis.transAxes.transform([0,0]))\n",
    "      coord1 = [axis_origin[0] - x_offset, axis_origin[1]]\n",
    "      coord2 = [coord1[0], coord1[1] + line_length]\n",
    "      line = matplotlib.lines.Line2D((coord1[0], coord2[0]), (coord1[1],\n",
    "        coord2[1]), transform=fig.transFigure, color=\"0.3\")\n",
    "      fig.lines.append(line)\n",
    "      if (a[-1] > 0):\n",
    "        pf.clear_axis(axis, spines=\"magenta\")\n",
    "        if act_indicator_threshold is not None:\n",
    "          assert act_indicator_threshold > 0.0 and act_indicator_threshold < 1.0, (\n",
    "            \"act_indicator_threshold must be between 0.0 and 1.0\")\n",
    "          thresh_index = int(num_time_steps * act_indicator_threshold)\n",
    "          if np.all([a[idx] == 0 for idx in range(0, thresh_index)]): # neuron has recently become active\n",
    "             for ax_loc in [\"top\", \"bottom\", \"left\", \"right\"]:\n",
    "              axis.spines[ax_loc].set_linestyle((1, (1, 3))) #length, spacing (on, off)\n",
    "      else:\n",
    "        pf.clear_axis(axis, spines=\"black\")\n",
    "        if act_indicator_threshold is not None:\n",
    "          thresh_index = int(num_time_steps * act_indicator_threshold)\n",
    "          if np.any([a[idx] > 0 for idx in range(thresh_index, num_time_steps)]): # neuron has recently become inactive\n",
    "             for ax_loc in [\"top\", \"bottom\", \"left\", \"right\"]:\n",
    "              axis.spines[ax_loc].set_linestyle((1, (1, 3))) #length, spacing (on, off)\n",
    "    else:\n",
    "      pf.clear_axis(axis)\n",
    "  num_pixels = np.size(data[\"images\"][img_idx])\n",
    "  image = data[\"images\"][img_idx,...].reshape(int(np.sqrt(num_pixels)), int(np.sqrt(num_pixels)))\n",
    "  sub_axes[sqrt_nn+1, 0].imshow(image, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "  for plot_col in range(sqrt_nn):\n",
    "    pf.clear_axis(sub_axes[sqrt_nn+1, plot_col])\n",
    "  fig.suptitle(\"LCA Activity\", y=0.9, fontsize=20)\n",
    "  handles, labels = sub_axes[0,0].get_legend_handles_labels()\n",
    "  legend = sub_axes[sqrt_nn+1, 1].legend(handles, labels, fontsize=12, ncol=3,\n",
    "    borderaxespad=0., bbox_to_anchor=[0, 0], fancybox=True, loc=\"upper left\")\n",
    "  for line in legend.get_lines():\n",
    "    line.set_linewidth(3)\n",
    "  plt.show()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "act_indicator_threshold = 0.80\n",
    "inf_trace_fig = plot_inference_traces(analyzer.inference_stats, analyzer.model_schedule[0][\"sparse_mult\"],\n",
    "  act_indicator_threshold=act_indicator_threshold)\n",
    "inf_trace_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_inference_traces_dot_thresh-\"+str(act_indicator_threshold)+\"_\"+analysis_params.save_info+\".pdf\",\n",
    "                     transparent=True, bbox_inches=\"tight\", pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inf_stats_fig = pf.plot_inference_stats(analyzer.inference_stats, title=\"Loss During Inference\")\n",
    "inf_stats_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_inference_loss_50_\"+analysis_params.save_info+\".png\",\n",
    "                     transparent=True, bbox_inches=\"tight\", pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ot_fig = pf.plot_contrast_orientation_tuning(analyzer.ot_grating_responses[\"neuron_indices\"],\n",
    "  analyzer.ot_grating_responses[\"contrasts\"],\n",
    "  analyzer.ot_grating_responses[\"orientations\"],\n",
    "  analyzer.ot_grating_responses[\"mean_responses\"])\n",
    "ot_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_fig = pf.plot_masked_orientation_tuning(co_bf_indices, co_mask_orientations, co_base_mean_responses, analyzer.co_grating_responses[\"test_mean_responses\"])\n",
    "cross_fig = pf.plot_masked_orientation_tuning(co_bf_indices, co_mask_orientations, co_base_mean_responses, co_test_mean_responses)\n",
    "cross_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_cross_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_contrast_fig = pf.plot_plaid_contrast_tuning(co_bf_indices, co_contrasts, co_contrasts, co_base_orientations,\n",
    "  co_mask_orientations, co_test_mean_responses)\n",
    "cross_contrast_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_cross_contrast_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grating = lambda bf_idx,orientation,phase,contrast:dp.generate_grating(\n",
    "#  *dp.get_grating_params(bf_stats=analyzer.bf_stats, bf_idx=bf_idx, orientation=orientation,\n",
    "#  phase=phase, contrast=contrast, diameter=-1)).reshape(16,16)\n",
    "#\n",
    "#bf_idx = 29\n",
    "#bf = analyzer.evals[\"weights/phi:0\"].T[co_bf_indices[bf_idx],:].reshape(16,16)\n",
    "#base_stim = grating(co_bf_indices[bf_idx], co_base_orientations[bf_idx], co_phases[0], 0.5)\n",
    "#mask_stim = grating(co_bf_indices[bf_idx], orthogonal_orientations[bf_idx], co_phases[5], 0.5)\n",
    "#test_stim = base_stim + mask_stim\n",
    "#\n",
    "#all_min = np.min(np.stack([base_stim, mask_stim, test_stim]))\n",
    "#all_max = np.max(np.stack([base_stim, mask_stim, test_stim]))\n",
    "#\n",
    "#fig, axes = plt.subplots(4)\n",
    "#axes[0] = pf.clear_axis(axes[0])\n",
    "#axes[1] = pf.clear_axis(axes[1])\n",
    "#axes[2] = pf.clear_axis(axes[2])\n",
    "#axes[3] = pf.clear_axis(axes[3])\n",
    "#axes[0].imshow(bf, cmap=\"Greys_r\")\n",
    "#axes[1].imshow(base_stim, cmap=\"Greys_r\", vmin=all_min, vmax=all_max)\n",
    "#axes[2].imshow(mask_stim, cmap=\"Greys_r\", vmin=all_min, vmax=all_max)\n",
    "#axes[3].imshow(test_stim, cmap=\"Greys_r\", vmin=all_min, vmax=all_max)\n",
    "#plt.show()\n",
    "#fig.savefig(\"/home/dpaiton/tmp_figs/\"+analysis_params.model_name+\"_ex_cross_stim.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructed_bfs = np.zeros_like(analyzer.evals[\"weights/phi:0\"].T)\n",
    "#for bf_idx in range(constructed_bfs.shape[0]):\n",
    "#  params = dp.get_grating_params(analyzer.bf_stats, bf_idx)\n",
    "#  grating = dp.generate_grating(*params)\n",
    "#  constructed_bfs[bf_idx,...] = grating.reshape(256)\n",
    "#fig = pf.plot_data_tiled(constructed_bfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute iso_response_contrast curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = analyzer.iso_response_contrasts(analyzer.bf_stats, base_contrast=0.5, contrast_resolution=0.01,\n",
    "  closeness=0.01, num_alt_orientations=4, orientations=np.linspace(0.0, np.pi, 16),\n",
    "  phases = np.linspace(-np.pi, np.pi, 12), neuron_indices=[52,53,54], diameter=-1,\n",
    "  scale=analyzer.analysis_params.input_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"iso_response_parameters\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
