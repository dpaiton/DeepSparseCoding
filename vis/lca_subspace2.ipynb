{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ryanchan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage.measure import compare_psnr\n",
    "import tensorflow as tf\n",
    "from data.dataset import Dataset\n",
    "import data.data_selector as ds\n",
    "import utils.data_processing as dp\n",
    "import utils.plot_functions as pf\n",
    "import analysis.analysis_picker as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5x_3_2.0_0.2',\n",
       " '5x_4_2.0_0.2',\n",
       " '8_3.0_0.3',\n",
       " '5x_5_1.0_0.2',\n",
       " '4_3.0_0.5',\n",
       " '8_4.0_0.3',\n",
       " '5x_4_1.5_0.2',\n",
       " '4_3.0_0.3',\n",
       " '4_3.0_0.4',\n",
       " '4_3.0_0.2',\n",
       " '8_3.0_0.4',\n",
       " '5x_3_1.0_0.2',\n",
       " '5x_2_1.5_0.2',\n",
       " '5x_2_2.0_0.2',\n",
       " '4_5.0_0.3',\n",
       " '8_5.0_0.3',\n",
       " '8_4.0_0.5',\n",
       " '8_5.0_0.2',\n",
       " '4_5.0_0.2',\n",
       " '5x_4_1.75_0.2',\n",
       " '5x_2_1.0_0.2',\n",
       " '5x_4_2.0_0.3',\n",
       " '5x_4_1.0_0.2',\n",
       " '5x_4_3.0_0.3',\n",
       " '5x_4_1.25_0.2',\n",
       " '5x_5_1.5_0.2',\n",
       " '10x_4_3.0_0.3',\n",
       " '5x_4_1.0_0.1',\n",
       " '5x_3_1.5_0.2',\n",
       " '8_4.0_0.2',\n",
       " '8_3.0_0.5',\n",
       " '8_3.0_0.2',\n",
       " '5x_4_0.5.0_0.2',\n",
       " '8_4.0_0.4',\n",
       " '4_3.0_0.3_5x',\n",
       " '5x_4_2.0_0.1',\n",
       " '4_4.0_0.4',\n",
       " '16_5.0_0.4',\n",
       " '8_5.0_0.4',\n",
       " '4_4.0_0.3',\n",
       " '5x_5_2.0_0.2',\n",
       " '4_4.0_0.2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name[17:-4] for name in os.listdir(os.path.expanduser(\"~/Work/Projects/lca_subspace_vh/logfiles\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params:\n",
    "    def __init__(self):\n",
    "        self.model_type = \"lca_subspace\"\n",
    "        self.model_name = \"lca_subspace_vh\"\n",
    "        self.version = \"5x_4_1.0_0.2\"\n",
    "        self.save_info = \"analysis_train\"\n",
    "        self.overwrite_analysis_log = False\n",
    "        \n",
    "analysis_params = params()\n",
    "analysis_params.project_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\")\n",
    "analysis_params.model_dir = (analysis_params.project_dir+analysis_params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ryanchan/Work/Projects/lca_subspace_vh/analysis/5x_4_1.0_0.2/savefiles/co_responses_analysis_train.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f3006b7967b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalysis_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepSparseCoding/analysis/lca_analyzer.py\u001b[0m in \u001b[0;36mload_analysis\u001b[0;34m(self, save_info)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mco_file_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis_out_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"savefiles/co_responses_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_info\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot_file_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_grating_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco_file_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_time_varied_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ryanchan/Work/Projects/lca_subspace_vh/analysis/5x_4_1.0_0.2/savefiles/co_responses_analysis_train.npz'"
     ]
    }
   ],
   "source": [
    "analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "analyzer.setup(analysis_params)\n",
    "analyzer.setup_model(analyzer.model_params)\n",
    "analyzer.load_analysis(save_info=analysis_params.save_info)\n",
    "analyzer.model_name = analysis_params.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.get_data(analyzer.model_params)\n",
    "dataset = analyzer.model.preprocess_dataset(dataset, analyzer.model_params)\n",
    "dataset = analyzer.model.reshape_dataset(dataset, analyzer.model_params)\n",
    "target_image = dataset[\"train\"].images[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 100#data[\"train\"].images.shape[0]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config, graph=analyzer.model.graph) as sess:\n",
    "  feed_dict = analyzer.model.get_feed_dict(dataset[\"train\"].images[0:num_imgs,...])\n",
    "  sess.run(analyzer.model.init_op, feed_dict)\n",
    "  analyzer.model.load_full_model(sess, analyzer.analysis_params.cp_loc)\n",
    "  run_list = [analyzer.model.module.w, analyzer.model.a, analyzer.model.module.group_activity, analyzer.model.module.group_angles]\n",
    "  weights, neuron_activations, group_activations, group_angles = sess.run(run_list, feed_dict)\n",
    "  weights_reshaped = weights.T.reshape(analyzer.model_params.num_neurons, analyzer.model_params.patch_edge_size, analyzer.model_params.patch_edge_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## population statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_ids = list(range(16))\n",
    "contrast = 1.0\n",
    "gauss_sigma = 1.0\n",
    "orientation = None # None uses the BF fit\n",
    "diameter = 0\n",
    "phases = np.linspace(-np.pi, np.pi, 32) \n",
    "#phases = [np.pi/2]\n",
    "\n",
    "grating = lambda neuron_idx, contrast, orientation,phase: dp.generate_grating(\n",
    "  *dp.get_grating_params(analyzer.bf_stats, neuron_idx, orientation=orientation,\n",
    "  phase=phase, contrast=contrast, diameter=diameter), gauss_sigma)\n",
    "\n",
    "phase_gratings = np.stack([grating(neuron_idx, contrast, orientation, phase)\n",
    "  for neuron_idx in neuron_ids\n",
    "  for phase in phases], axis=0)\n",
    "\n",
    "\n",
    "#phase_gratings.shape\n",
    "grating_fig = pf.plot_weights(phase_gratings, figsize=(8,8))\n",
    "weights = analyzer.evals[\"lca_subspace/weights/w:0\"].T\n",
    "weights_fig = pf.plot_weights(weights[:16, :].reshape((16, 16, 16)), figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = analyzer.evaluate_model(phase_gratings.reshape(len(phase_gratings), 256),\n",
    "  [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "a_vals = model_eval[\"inference/activity:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=analyzer.model.graph) as sess:\n",
    "    sess.run(analyzer.model.init_op)\n",
    "    feed_dict = analyzer.model.get_feed_dict(phase_gratings.reshape(len(phase_gratings), 256), is_test=True)\n",
    "    group_act, group_angle, group_encodings = sess.run([analyzer.model.get_group_activity(), \n",
    "                                                        analyzer.model.get_group_angle(), \n",
    "                                                        analyzer.model.get_group_encodings()], feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Weights (Phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_weights(W, group_size, figsize=(10, 10)):\n",
    "    num_groups = W.shape[0] // group_size\n",
    "    assert isinstance(num_groups, int), \"number of groups should have type int\"\n",
    "    fig, ax = plt.subplots(ncols=group_size, nrows=num_groups ,figsize=figsize)\n",
    "    w_i = 0\n",
    "    for r in range(group_size):\n",
    "        for c in range(group_size):\n",
    "            ax[r, c].imshow(W[w_i])\n",
    "            break\n",
    "            w_i += 1\n",
    "        break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "fig = plt.figure(figsize=(1, 1))\n",
    "big_gs = GridSpec(1, 2, figure=fig)\n",
    "\n",
    "gs00 = big_gs[0].subgridspec(2, 2) #gridspec.GridSpecFromSubplotSpec(2, 2, subplot_spec=big_gs[0])\n",
    "big_gs[0].update(wspace=0.025, hspace=0.05)\n",
    "ax00_00 = fig.add_subplot(gs00[0, 0])\n",
    "ax00_01 = fig.add_subplot(gs00[0, 1])\n",
    "ax00_10 = fig.add_subplot(gs00[1, 0])\n",
    "ax00_11 = fig.add_subplot(gs00[1, 1])\n",
    "\n",
    "gs01 = big_gs[1].subgridspec(2, 2)\n",
    "ax01_00 = fig.add_subplot(gs01[0, 0])\n",
    "ax01_01 = fig.add_subplot(gs01[0, 1])\n",
    "ax01_10 = fig.add_subplot(gs01[1, 0])\n",
    "ax01_11 = fig.add_subplot(gs01[1, 1])\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.imshow(weights_reshaped[i])\n",
    "    ax.tick_params(\"both\",\n",
    "                   bottom=False,\n",
    "                   left=False,\n",
    "                   labelbottom=False,\n",
    "                   labelleft=False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [[j+i for i in range(4)] for j in np.arange(0, analyzer.model_params.num_neurons, 4)]\n",
    "pf.plot_group_weights(weights, group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = weights_reshaped[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = analyzer.model_params.num_neurons // analyzer.model_params.num_groups\n",
    "fig, ax = plt.subplots(nrows=9, ncols=128//8, figsize=(4, 8))\n",
    "k = 0\n",
    "for i in range(9):\n",
    "    for j in range(128//8):\n",
    "        if i == 4:\n",
    "            ax[i, j].imshow(np.zeros(shape=(16, 1)), cmap=\"binary\")\n",
    "            ax[i, j].axis(\"off\")\n",
    "        else:\n",
    "            ax[i, j].imshow(weights_reshaped[k], cmap=\"gray\")\n",
    "            ax[i, j].axis(\"off\")\n",
    "            k += 1\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.ones(shape=(5, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4*10*256).reshape(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = analyzer.model_params.num_neurons // analyzer.model_params.num_groups\n",
    "plot_group_weights(weights_reshaped, group_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of Full Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_names = [name[17:-4] for name in os.listdir(os.path.expanduser(\"~/Work/Projects/lca_subspace_vh/logfiles\"))]\n",
    "log_names.sort()\n",
    "log_names = log_names[1:]\n",
    "log_names.pop(2)\n",
    "filtered_log_names = log_names\n",
    "print(filtered_log_names)\n",
    "\n",
    "class params:\n",
    "    def __init__(self, version):\n",
    "        self.model_type = \"lca_subspace\"\n",
    "        self.model_name = \"lca_subspace_vh\"\n",
    "#         self.version = \"4_3.0_0.3\"\n",
    "        self.version = version\n",
    "        self.save_info = \"analysis_train\"\n",
    "        self.overwrite_analysis_log = False\n",
    "        \n",
    "for v in filtered_log_names[13:]:\n",
    "    print(v)\n",
    "    analysis_params = params(v)\n",
    "    analysis_params.project_dir = (os.path.expanduser(\"~\")+\"/Work/Projects/\")\n",
    "    analysis_params.model_dir = (analysis_params.project_dir+analysis_params.model_name)\n",
    "    \n",
    "    analyzer = ap.get_analyzer(analysis_params.model_type)\n",
    "    analyzer.setup(analysis_params)\n",
    "    analyzer.setup_model(analyzer.model_params)\n",
    "    analyzer.load_analysis(save_info=analysis_params.save_info)\n",
    "    analyzer.model_name = analysis_params.model_name\n",
    "\n",
    "#     dataset = ds.get_data(analyzer.model_params)\n",
    "#     dataset = analyzer.model.preprocess_dataset(dataset, analyzer.model_params)\n",
    "#     dataset = analyzer.model.reshape_dataset(dataset, analyzer.model_params)\n",
    "\n",
    "#     analyzer.model.num_groups = int(v[0])\n",
    "    \n",
    "#     keys=[\"a_fraction_active\", \"recon_loss\", \"sparse_loss\", \"total_loss\"]\n",
    "#     labels=[\"activity\", \"recon loss\", \"sparse loss\", \"total loss\"]\n",
    "#     stats_fig = pf.plot_stats(analyzer.run_stats, keys=keys, labels=labels, start_index=100, figsize=(10,10))\n",
    "#     stats_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_train_stats.png\")\n",
    "\n",
    "    try:\n",
    "        normed_image = (\n",
    "          (analyzer.full_image - np.min(analyzer.full_image))\n",
    "          / (np.max(analyzer.full_image) - np.min(analyzer.full_image))).astype(np.float32)\n",
    "\n",
    "        normed_recon = (\n",
    "          (analyzer.full_recon - np.min(analyzer.full_recon))\n",
    "          / (np.max(analyzer.full_recon) - np.min(analyzer.full_recon))).astype(np.float32)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "        ax[0] = pf.clear_axis(ax[0])\n",
    "        ax[0].imshow(np.squeeze(normed_image), cmap=\"Greys_r\")\n",
    "        ax[0].set_title(\"Input Image\", fontsize=16)\n",
    "        ax[1] = pf.clear_axis(ax[1])\n",
    "        ax[1].imshow(np.squeeze(normed_recon), cmap=\"Greys_r\")\n",
    "        percent_active = \"{:.2f}\".format(analyzer.recon_frac_act*100)\n",
    "        psnr = \"{:.2f}\".format(compare_psnr(normed_image, normed_recon, data_range=1))\n",
    "        ax[1].set_title(\"Reconstruction\\n\"+percent_active+\" percent active\"+\"\\n\"+\"PSNR = \"+psnr, fontsize=16)\n",
    "        plt.show()\n",
    "        fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_image_recon.png\", transparent=True,\n",
    "          bbox_inches=\"tight\")\n",
    "    except:\n",
    "        print(v, \"error\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyzer.model_params.whiten_data:\n",
    "  # FT method is the only one that works on full images\n",
    "  wht_img, img_mean, ft_filter = dp.whiten_data(full_image,\n",
    "    method=\"FT\", lpf_cutoff=analyzer.model_params.lpf_cutoff)\n",
    "else:\n",
    "  wht_img = full_image\n",
    "img_patches = dp.extract_patches(wht_img,\n",
    "  out_shape=(1, analyzer.model_params.patch_edge_size, analyzer.model_params.patch_edge_size, 1),\n",
    "  overlapping=False, randomize=False, var_thresh=0.0)\n",
    "img_patches, orig_shape = dp.reshape_data(img_patches, flatten=True)[:2]\n",
    "model_eval = analyzer.evaluate_model(img_patches,\n",
    "  [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "a_vals = model_eval[\"inference/activity:0\"]\n",
    "recon_patches = dp.reshape_data(recon_patches, flatten=False, out_shape=orig_shape)[0]\n",
    "full_recon = dp.patches_to_image(recon_patches, full_image.shape).astype(np.float32)\n",
    "if analyzer.model_params.whiten_data:\n",
    "    full_recon = dp.unwhiten_data(full_recon, img_mean, ft_filter, method=\"FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_image = (\n",
    "  (analyzer.full_image - np.min(analyzer.full_image))\n",
    "  / (np.max(analyzer.full_image) - np.min(analyzer.full_image))).astype(np.float32)\n",
    "\n",
    "normed_recon = (\n",
    "  (analyzer.full_recon - np.min(analyzer.full_recon))\n",
    "  / (np.max(analyzer.full_recon) - np.min(analyzer.full_recon))).astype(np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0] = pf.clear_axis(ax[0])\n",
    "ax[0].imshow(np.squeeze(normed_image), cmap=\"Greys_r\")\n",
    "ax[0].set_title(\"Input Image\", fontsize=16)\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(np.squeeze(normed_recon), cmap=\"Greys_r\")\n",
    "percent_active = \"{:.2f}\".format(analyzer.recon_frac_act*100)\n",
    "psnr = \"{:.2f}\".format(compare_psnr(normed_image, normed_recon, data_range=1))\n",
    "ax[1].set_title(\"Reconstruction\\n\"+percent_active+\" percent active\"+\"\\n\"+\"PSNR = \"+psnr, fontsize=16)\n",
    "plt.show()\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_image_recon.png\", transparent=True,\n",
    "  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Frequency Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pf.plot_loc_freq_summary(analyzer.bf_stats, figsize=(12, 4), fontsize=16)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/fig_location_frequency_centers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[\"a_fraction_active\", \"recon_loss\", \"sparse_loss\", \"total_loss\"]\n",
    "labels=[\"activity\", \"recon loss\", \"sparse loss\", \"total loss\"]\n",
    "stats_fig = pf.plot_stats(analyzer.run_stats, keys=keys, labels=labels, start_index=100, figsize=(10,10))\n",
    "stats_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_train_stats.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ot_fig = pf.plot_contrast_orientation_tuning(analyzer.ot_grating_responses[\"neuron_indices\"],\n",
    "  analyzer.ot_grating_responses[\"contrasts\"],\n",
    "  analyzer.ot_grating_responses[\"orientations\"],\n",
    "  analyzer.ot_grating_responses[\"mean_responses\"])\n",
    "ot_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iso-response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_id = 4\n",
    "analyzer.bf_id0 = 50#vectors[vector_id, 0] # RICA 83, 85; vae 4, 72; lca 3, 588\n",
    "analyzer.bf_id1 = 10#vectors[vector_id, 1]\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0] = pf.clear_axis(ax[0])\n",
    "ax[0].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "ax[0].set_title(str(analyzer.bf_id0))\n",
    "ax[1] = pf.clear_axis(ax[1])\n",
    "ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "ax[1].set_title(str(analyzer.bf_id1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.bf0 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0].reshape(\n",
    "(analyzer.model_params.num_pixels))\n",
    "analyzer.bf1 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1].reshape(\n",
    "(analyzer.model_params.num_pixels))\n",
    "analyzer.bf0_norm = np.linalg.norm(analyzer.bf0)\n",
    "analyzer.bf1_norm = np.linalg.norm(analyzer.bf1)\n",
    "analyzer.bf0 = analyzer.bf0 / analyzer.bf0_norm\n",
    "analyzer.bf1 = analyzer.bf1 / analyzer.bf1_norm\n",
    "\n",
    "print(\"BF indices = [\",analyzer.bf_id0,\", \",analyzer.bf_id1,\"]\")\n",
    "print(\"bf0 norm = \", analyzer.bf0_norm)\n",
    "print(\"bf1 norm = \", analyzer.bf1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = int(228**2)\n",
    "x_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "y_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "X_mesh, Y_mesh = np.meshgrid(x_pts, y_pts)\n",
    "proj_datapoints = np.stack([X_mesh.reshape(num_imgs), Y_mesh.reshape(num_imgs)], axis=1)\n",
    "\n",
    "analyzer.proj_datapoints = proj_datapoints\n",
    "analyzer.proj_matrix, v = analyzer.bf_projections(analyzer.bf0, analyzer.bf1)\n",
    "analyzer.proj_neuron0 = np.dot(analyzer.proj_matrix, analyzer.bf0).T\n",
    "analyzer.proj_neuron1 = np.dot(analyzer.proj_matrix, analyzer.bf1).T\n",
    "analyzer.proj_v = np.dot(analyzer.proj_matrix, v).T\n",
    "\n",
    "analyzer.datapoints = np.stack([np.dot(analyzer.proj_matrix.T, analyzer.proj_datapoints[data_id,:])\n",
    "for data_id in range(num_imgs)]) #inject\n",
    "analyzer.datapoints, orig_shape = dp.reshape_data(analyzer.datapoints, flatten=False)[:2]\n",
    "analyzer.datapoints = {\"test\": Dataset(analyzer.datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "params={\"whiten_data\":analyzer.model_params.whiten_data}\n",
    "if params[\"whiten_data\"]:\n",
    "    params[\"whiten_method\"] = analyzer.model_params.whiten_method\n",
    "analyzer.datapoints = analyzer.model.preprocess_dataset(analyzer.datapoints, params=params)\n",
    "analyzer.datapoints = analyzer.model.reshape_dataset(analyzer.datapoints, analyzer.model_params)\n",
    "analyzer.datapoints[\"test\"].images /= np.max(np.abs(analyzer.datapoints[\"test\"].images))\n",
    "analyzer.datapoints[\"test\"].images *= 3*analyzer.analysis_params.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = analyzer.compute_activations(analyzer.datapoints[\"test\"].images)\n",
    "#activations = analyzer.evaluate_model(analyzer.datapoints[\"test\"].images, [analyzer.model.module.u_list[1].name])[analyzer.model.module.u_list[1].name]\n",
    "activity_max = np.amax(np.abs(activations)) # Rescale between -1 and 1\n",
    "analyzer.norm_activity = activations / (activity_max + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots_y = 1\n",
    "num_plots_x = 2\n",
    "gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5, width_ratios=[4, 1])\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "#cmap = plt.get_cmap('tab20b')\n",
    "cmap = plt.get_cmap('viridis')\n",
    "vmin = np.floor(np.min(analyzer.norm_activity))#0.0\n",
    "vmax = np.ceil(np.max(analyzer.norm_activity))#1.0\n",
    "\n",
    "#name_suffix = \"continuous\"\n",
    "#pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1],\n",
    "#  vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.5, c=analyzer.norm_activity[:, analyzer.bf_id0], s=5.0)\n",
    "\n",
    "levels = 5\n",
    "name_suffix = \"\"\n",
    "contsf = curve_ax.contourf(X_mesh, Y_mesh,\n",
    "analyzer.norm_activity[:,analyzer.bf_id0].reshape(int(np.sqrt(num_imgs)),\n",
    "int(np.sqrt(num_imgs))), levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "\n",
    "curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(),\n",
    "analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "head_length=0.15, fc='r', ec='r')\n",
    "curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(),\n",
    "analyzer.proj_neuron1[1].item(), width=0.05, head_width=0.15,\n",
    "head_length=0.15, fc='w', ec='w')\n",
    "#curve_ax.arrow(0, 0, analyzer.proj_v[0].item(), analyzer.proj_v[1].item(), width=0.05, head_width=0.15,\n",
    "# head_length=0.15, linestyle=\"-.\", fc='k', ec='k')\n",
    "\n",
    "#curve_ax.set_title(\"Angle = \"+\"{:.2f}\".format(analyzer.neuron_angles[bf_id0, bf_id1])+\" deg\", fontsize=16)\n",
    "curve_ax.set_ylim([-2, 2.0])\n",
    "curve_ax.set_xlim([-2, 2.0])\n",
    "curve_ax.set_aspect(\"equal\")\n",
    "#cbar = pf.add_colorbar_to_im(pts, aspect=20, pad_fraction=0.5, labelsize=16, ticks=[vmin, vmax])\n",
    "#cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "\n",
    "gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], wspace=2, hspace=-0.55)\n",
    "bf1_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "bf1_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "bf1_ax.set_title(\"Primary\\nBasis Function\", color='r', fontsize=16)\n",
    "bf2_ax = pf.clear_axis(fig.add_subplot(gs2[1]))\n",
    "bf2_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "bf2_ax.set_title(\"Comparison\\nBasis Function\", color='k', fontsize=16)\n",
    "fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_response_contours_bf0id\"+str(analyzer.bf_id0)+\"_bf1id\"+str(analyzer.bf_id1)+name_suffix+\".png\",\n",
    "transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = np.arange(10)*10\n",
    "for i in np.arange(0, 100, 4):\n",
    "    for j in np.arange(4):\n",
    "        if i == j:\n",
    "            continue\n",
    "        try:\n",
    "            print(\"working on \", i, i+j)\n",
    "            vector_id = 4\n",
    "            analyzer.bf_id0 = i#50#vectors[vector_id, 0] # RICA 83, 85; vae 4, 72; lca 3, 588\n",
    "            analyzer.bf_id1 = i+j#10#vectors[vector_id, 1]\n",
    "        #     fig, ax = plt.subplots(2)\n",
    "        #     ax[0] = pf.clear_axis(ax[0])\n",
    "        #     ax[0].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "        #     ax[0].set_title(str(analyzer.bf_id0))\n",
    "        #     ax[1] = pf.clear_axis(ax[1])\n",
    "        #     ax[1].imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "        #     ax[1].set_title(str(analyzer.bf_id1))\n",
    "        #     plt.show()\n",
    "\n",
    "            analyzer.bf0 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0].reshape(\n",
    "            (analyzer.model_params.num_pixels))\n",
    "            analyzer.bf1 = analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1].reshape(\n",
    "            (analyzer.model_params.num_pixels))\n",
    "            analyzer.bf0_norm = np.linalg.norm(analyzer.bf0)\n",
    "            analyzer.bf1_norm = np.linalg.norm(analyzer.bf1)\n",
    "            analyzer.bf0 = analyzer.bf0 / analyzer.bf0_norm\n",
    "            analyzer.bf1 = analyzer.bf1 / analyzer.bf1_norm\n",
    "\n",
    "            print(\"BF indices = [\",analyzer.bf_id0,\", \",analyzer.bf_id1,\"]\")\n",
    "            print(\"bf0 norm = \", analyzer.bf0_norm)\n",
    "            print(\"bf1 norm = \", analyzer.bf1_norm)\n",
    "\n",
    "            num_imgs = int(228**2)\n",
    "            x_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "            y_pts = np.linspace(-2.0, 2.0, int(np.sqrt(num_imgs)))\n",
    "            X_mesh, Y_mesh = np.meshgrid(x_pts, y_pts)\n",
    "            proj_datapoints = np.stack([X_mesh.reshape(num_imgs), Y_mesh.reshape(num_imgs)], axis=1)\n",
    "\n",
    "            analyzer.proj_datapoints = proj_datapoints\n",
    "            analyzer.proj_matrix, v = analyzer.bf_projections(analyzer.bf0, analyzer.bf1)\n",
    "            analyzer.proj_neuron0 = np.dot(analyzer.proj_matrix, analyzer.bf0).T\n",
    "            analyzer.proj_neuron1 = np.dot(analyzer.proj_matrix, analyzer.bf1).T\n",
    "            analyzer.proj_v = np.dot(analyzer.proj_matrix, v).T\n",
    "\n",
    "            analyzer.datapoints = np.stack([np.dot(analyzer.proj_matrix.T, analyzer.proj_datapoints[data_id,:])\n",
    "            for data_id in range(num_imgs)]) #inject\n",
    "            analyzer.datapoints, orig_shape = dp.reshape_data(analyzer.datapoints, flatten=False)[:2]\n",
    "            analyzer.datapoints = {\"test\": Dataset(analyzer.datapoints, lbls=None, ignore_lbls=None, rand_state=analyzer.rand_state)}\n",
    "            params={\"whiten_data\":analyzer.model_params.whiten_data}\n",
    "            if params[\"whiten_data\"]:\n",
    "                params[\"whiten_method\"] = analyzer.model_params.whiten_method\n",
    "            analyzer.datapoints = analyzer.model.preprocess_dataset(analyzer.datapoints, params=params)\n",
    "            analyzer.datapoints = analyzer.model.reshape_dataset(analyzer.datapoints, analyzer.model_params)\n",
    "            analyzer.datapoints[\"test\"].images /= np.max(np.abs(analyzer.datapoints[\"test\"].images))\n",
    "            analyzer.datapoints[\"test\"].images *= 3*analyzer.analysis_params.input_scale\n",
    "\n",
    "            activations = analyzer.compute_activations(analyzer.datapoints[\"test\"].images)\n",
    "            #activations = analyzer.evaluate_model(analyzer.datapoints[\"test\"].images, [analyzer.model.module.u_list[1].name])[analyzer.model.module.u_list[1].name]\n",
    "            activity_max = np.amax(np.abs(activations)) # Rescale between -1 and 1\n",
    "            analyzer.norm_activity = activations / (activity_max + 0.00001)\n",
    "\n",
    "            num_plots_y = 1\n",
    "            num_plots_x = 2\n",
    "            gs1 = gridspec.GridSpec(num_plots_y, num_plots_x, wspace=0.5, width_ratios=[4, 1])\n",
    "            fig = plt.figure(figsize=(6,6))\n",
    "            curve_ax = pf.clear_axis(fig.add_subplot(gs1[0]))\n",
    "            #cmap = plt.get_cmap('tab20b')\n",
    "            cmap = plt.get_cmap('viridis')\n",
    "            vmin = np.floor(np.min(analyzer.norm_activity))#0.0\n",
    "            vmax = np.ceil(np.max(analyzer.norm_activity))#1.0\n",
    "\n",
    "            #name_suffix = \"continuous\"\n",
    "            #pts = curve_ax.scatter(analyzer.proj_datapoints[:,0], analyzer.proj_datapoints[:,1],\n",
    "            #  vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.5, c=analyzer.norm_activity[:, analyzer.bf_id0], s=5.0)\n",
    "\n",
    "            levels = 5\n",
    "            name_suffix = \"\"\n",
    "            contsf = curve_ax.contourf(X_mesh, Y_mesh,\n",
    "            analyzer.norm_activity[:,analyzer.bf_id0].reshape(int(np.sqrt(num_imgs)),\n",
    "            int(np.sqrt(num_imgs))), levels=levels, vmin=vmin, vmax=vmax, alpha=1.0, antialiased=True, cmap=cmap)\n",
    "\n",
    "            curve_ax.arrow(0, 0, analyzer.proj_neuron0[0].item(),\n",
    "            analyzer.proj_neuron0[1].item(), width=0.05, head_width=0.15,\n",
    "            head_length=0.15, fc='r', ec='r')\n",
    "            curve_ax.arrow(0, 0, analyzer.proj_neuron1[0].item(),\n",
    "            analyzer.proj_neuron1[1].item(), width=0.05, head_width=0.15,\n",
    "            head_length=0.15, fc='w', ec='w')\n",
    "            #curve_ax.arrow(0, 0, analyzer.proj_v[0].item(), analyzer.proj_v[1].item(), width=0.05, head_width=0.15,\n",
    "            # head_length=0.15, linestyle=\"-.\", fc='k', ec='k')\n",
    "\n",
    "            #curve_ax.set_title(\"Angle = \"+\"{:.2f}\".format(analyzer.neuron_angles[bf_id0, bf_id1])+\" deg\", fontsize=16)\n",
    "            curve_ax.set_ylim([-2, 2.0])\n",
    "            curve_ax.set_xlim([-2, 2.0])\n",
    "            curve_ax.set_aspect(\"equal\")\n",
    "            #cbar = pf.add_colorbar_to_im(pts, aspect=20, pad_fraction=0.5, labelsize=16, ticks=[vmin, vmax])\n",
    "            #cbar.ax.set_yticklabels([\"{:.0f}\".format(vmin), \"{:.0f}\".format(vmax)])\n",
    "\n",
    "            gs2 = gridspec.GridSpecFromSubplotSpec(2, 1, gs1[1], wspace=2, hspace=-0.55)\n",
    "            bf1_ax = pf.clear_axis(fig.add_subplot(gs2[0]))\n",
    "            bf1_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id0], cmap=\"Greys_r\")\n",
    "            bf1_ax.set_title(\"Primary\\nBasis Function\", color='r', fontsize=16)\n",
    "            bf2_ax = pf.clear_axis(fig.add_subplot(gs2[1]))\n",
    "            bf2_ax.imshow(analyzer.bf_stats[\"basis_functions\"][analyzer.bf_id1], cmap=\"Greys_r\")\n",
    "            bf2_ax.set_title(\"Comparison\\nBasis Function\", color='k', fontsize=16)\n",
    "            fig.savefig(analyzer.analysis_out_dir+\"/vis/neuron_response_contours_bf0id\"+str(analyzer.bf_id0)+\"_bf1id\"+str(analyzer.bf_id1)+name_suffix+\".png\",\n",
    "            transparent=True, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "            plt.show()\n",
    "            \n",
    "        except:\n",
    "            print(i, j, \"failed to show iso-contour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class img_params():\n",
    "    data_type = analysis_params.data_type\n",
    "    num_images = 2\n",
    "    extract_patches = False\n",
    "    image_edge_size = analysis_params.image_edge_size\n",
    "    data_dir = os.path.expanduser(\"~\")+\"/Work/Datasets/\"\n",
    "    rand_seed = analysis_params.rand_seed\n",
    "    rand_state = np.random.RandomState(analysis_params.rand_seed)\n",
    "full_img = dp.reshape_data(ds.get_data(img_params)[\"train\"].images[0], flatten=False)[0]\n",
    "analyzer.run_patch_recon_analysis(full_img, save_info=analysis_params.save_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_patch_recon_analysis(self, full_image, save_info):\n",
    "    \"\"\"\n",
    "    Break image into patches, compute recons, reassemble recons back into a full image\n",
    "    \"\"\"\n",
    "    self.full_image = full_image\n",
    "    if self.model_params.whiten_data:\n",
    "      # FT method is the only one that works on full images\n",
    "      wht_img, img_mean, ft_filter = dp.whiten_data(full_image,\n",
    "        method=\"FT\", lpf_cutoff=self.model_params.lpf_cutoff)\n",
    "    else:\n",
    "      wht_img = full_image\n",
    "    img_patches = dp.extract_patches(wht_img,\n",
    "      out_shape=(1, self.model_params.patch_edge_size, self.model_params.patch_edge_size, 1),\n",
    "      overlapping=False, randomize=False, var_thresh=0.0)\n",
    "    img_patches, orig_shape = dp.reshape_data(img_patches, flatten=True)[:2]\n",
    "    model_eval = self.evaluate_model(img_patches,\n",
    "      [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "    recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "    a_vals = model_eval[\"inference/activity:0\"]\n",
    "    self.recon_frac_act = np.array(np.count_nonzero(a_vals) / float(a_vals.size))\n",
    "    recon_patches = dp.reshape_data(recon_patches, flatten=False, out_shape=orig_shape)[0]\n",
    "    self.full_recon = dp.patches_to_image(recon_patches, full_image.shape).astype(np.float32)\n",
    "    if self.model_params.whiten_data:\n",
    "      self.full_recon = dp.unwhiten_data(self.full_recon, img_mean, ft_filter, method=\"FT\")\n",
    "    np.savez(self.analysis_out_dir+\"savefiles/full_recon_\"+save_info+\".npz\",\n",
    "      data={\"full_image\":self.full_image, \"full_recon\":self.full_recon,\n",
    "      \"recon_frac_act\":self.recon_frac_act})\n",
    "    self.analysis_logger.log_info(\"Patch recon analysis is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_images(analyzer, full_images):\n",
    "    \"\"\"\n",
    "    Paramters: \n",
    "        full_images [np.ndarray]: list of images\n",
    "    \"\"\"\n",
    "    model_params = analyzer.model_params\n",
    "    wht_imgs, img_means, ft_filters = dp.whiten_data(full_image, method=\"FT\", \n",
    "                                                  lpf_cutoff=model_params.lpf_cutoff)\n",
    "    img_patches = dp.extract_patches(wht_imgs, \n",
    "                                     out_shape=(1, model_params.patch_edge_size, \n",
    "                                                model_params.patch_edge_size, 1),\n",
    "                                     overlapping=False, randomize=False, var_thresh=0.0)\n",
    "    img_patches, orig_shape = dp.reshape_data(img_patches, flatten=True)[:2]\n",
    "    model_eval = analyzer.evaluate_model(img_patches,\n",
    "      [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "    recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "    a_vals = model_eval[\"inference/activity:0\"]\n",
    "    recon_frac_act = np.array(np.count_nonzero(a_vals) / float(a_vals.size))\n",
    "    recon_patches = dp.reshape_data(recon_patches, flatten=False, out_shape=orig_shape)[0]\n",
    "    full_recon = dp.patches_to_image(recon_patches, full_image.shape).astype(np.float32)\n",
    "    if model_params.whiten_data:\n",
    "          full_recon = dp.unwhiten_data(full_recon, img_mean, ft_filter, method=\"FT\")\n",
    "    return full_recon, recon_frac_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.model_params.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image = np.repeat(analyzer.full_image, 3, axis=0)\n",
    "full_recon = recon_images(analyzer, full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = analyzer.model_params\n",
    "wht_imgs, img_mean, ft_filter = dp.whiten_data(full_image, method=\"FT\", \n",
    "                                              lpf_cutoff=model_params.lpf_cutoff)\n",
    "img_patches = dp.extract_patches(wht_imgs, \n",
    "                                 out_shape=(1, model_params.patch_edge_size, \n",
    "                                            model_params.patch_edge_size, 1),\n",
    "                                 overlapping=False, randomize=False, var_thresh=0.0)\n",
    "img_patches, orig_shape = dp.reshape_data(img_patches, flatten=True)[:2]\n",
    "model_eval = analyzer.evaluate_model(img_patches,\n",
    "  [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "a_vals = model_eval[\"inference/activity:0\"]\n",
    "recon_frac_act = np.array(np.count_nonzero(a_vals) / float(a_vals.size))\n",
    "recon_patches = dp.reshape_data(recon_patches, flatten=False, out_shape=orig_shape)[0]\n",
    "full_recon = dp.patches_to_image(recon_patches, full_image.shape).astype(np.float32)\n",
    "if model_params.whiten_data:\n",
    "  full_recon = dp.unwhiten_data(full_recon, img_mean, ft_filter, method=\"FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_images(analyzer, full_images):\n",
    "    if analyzer.model_params.whiten_data:\n",
    "      # FT method is the only one that works on full images\n",
    "      wht_img, img_mean, ft_filter = dp.whiten_data(full_image,\n",
    "        method=\"FT\", lpf_cutoff=analyzer.model_params.lpf_cutoff)\n",
    "    else:\n",
    "      wht_img = full_image\n",
    "    img_patches = dp.extract_patches(wht_img,\n",
    "      out_shape=(1, analyzer.model_params.patch_edge_size, analyzer.model_params.patch_edge_size, 1),\n",
    "      overlapping=False, randomize=False, var_thresh=0.0)\n",
    "    img_patches, orig_shape = dp.reshape_data(img_patches, flatten=True)[:2]\n",
    "    model_eval = analyzer.evaluate_model(img_patches,\n",
    "      [\"inference/activity:0\", \"output/reconstruction:0\"])\n",
    "    recon_patches = model_eval[\"output/reconstruction:0\"]\n",
    "    a_vals = model_eval[\"inference/activity:0\"]\n",
    "    recon_frac_act = np.array(np.count_nonzero(a_vals) / float(a_vals.size))\n",
    "    recon_patches = dp.reshape_data(recon_patches, flatten=False, out_shape=orig_shape)[0]\n",
    "    full_recon = dp.patches_to_image(recon_patches, full_image.shape).astype(np.float32)\n",
    "    if analyzer.model_params.whiten_data:\n",
    "      full_recon = dp.unwhiten_data(full_recon, img_mean, ft_filter, method=\"FT\")\n",
    "    return full_recon, recon_frac_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_image = (\n",
    "  (full_image - np.min(full_image))\n",
    "  / (np.max(full_image) - np.min(full_image))).astype(np.float32)\n",
    "\n",
    "normed_recon = (\n",
    "  (full_recon - np.min(full_recon))\n",
    "  / (np.max(full_recon) - np.min(full_recon))).astype(np.float32)\n",
    "\n",
    "group_size = analyzer.model_params.num_neurons // analyzer.model_params.num_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer.model_params.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x = np.arange(50).reshape(5, 10)\n",
    "    print(x)\n",
    "    I = tf.slice(x, [3, 0], [1, 10])\n",
    "    print(sess.run(tf.transpose(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(shape=(256, 64))\n",
    "for i in range(64):\n",
    "    x[i:(i+1)*4, i] = 1.\n",
    "x[:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 100)\n",
    "with tf.Session() as sess:\n",
    "    y = tf.matmul(tf.real(tf.linalg.inv(tf.sqrt(tf.matmul(x, tf.transpose(x))))), x)\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(50, 50)\n",
    "np.all(x @ x.T > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_fig = pf.plot_contrast_orientation_tuning(analyzer.ot_grating_responses[\"neuron_indices\"],\n",
    "  analyzer.ot_grating_responses[\"contrasts\"],\n",
    "  analyzer.ot_grating_responses[\"orientations\"],\n",
    "  analyzer.ot_grating_responses[\"mean_responses\"],\n",
    "  figsize=(32,32))\n",
    "ot_fig.savefig(analyzer.analysis_out_dir+\"/vis/\"+analysis_params.model_name+\"_orientation_tuning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
