{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function for data code.\n",
    "### Note that this must be run from the root repository directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import data.data_selector as ds\n",
    "import utils.plot_functions as pf\n",
    "import utils.data_processing as dp\n",
    "import models.model_picker as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_type = \"conv_lca\"\n",
    "\n",
    "class general_params(object):\n",
    "  def __init__(self):\n",
    "    self.model_name = \"data_test\"\n",
    "    self.model_type = model_type\n",
    "    self.version = \"\"\n",
    "    self.optimizer = \"sgd\"\n",
    "    self.cp_int = 10\n",
    "    self.max_cp_to_keep = 1\n",
    "    self.cp_load = False\n",
    "    self.log_int = 1\n",
    "    self.log_to_file = True\n",
    "    self.gen_plot_int = 1\n",
    "    self.save_plots = True\n",
    "    self.eps = 1e-12\n",
    "    self.device = \"/gpu:0\"\n",
    "    self.rand_seed = 1234567890\n",
    "    self.out_dir = os.path.expanduser(\"~\")+\"/Work/Projects/\"\n",
    "    self.stride_y = 2\n",
    "    self.stride_x = 2\n",
    "    self.patch_size_y = 12 # weight receptive field\n",
    "    self.patch_size_x = 12\n",
    "    self.num_neurons = 256 # pixel-overcompleteness is num_neurons/(stride_y * stride_x)\n",
    "    self.num_steps = 120\n",
    "    self.dt = 0.001\n",
    "    self.tau = 0.03\n",
    "    self.rectify_a = True\n",
    "    self.norm_weights = True\n",
    "    self.thresh_type = \"soft\"}\n",
    "\n",
    "class cifar_params(object):\n",
    "  def __init__(self):\n",
    "    self.data_type = \"cifar10\"\n",
    "    self.batch_size = 10\n",
    "    self.center_data = False\n",
    "    self.contrast_normalize = False\n",
    "    self.extract_patches = False\n",
    "    self.norm_data = False\n",
    "    self.whiten_data = False\n",
    "    self.standardize_data = True\n",
    "    self.norm_data_to_one = False\n",
    "    self.data_dir = os.path.expanduser(\"~\")+\"/Work/Datasets/CIFAR/\"\n",
    "cifar_params.update(general_params)\n",
    "\n",
    "class vh_params(object):\n",
    "  def __init__(self):\n",
    "    self.data_type = \"vanhateren\"\n",
    "    self.batch_size = 10\n",
    "    self.num_images = 300\n",
    "    self.image_edge_size = 512\n",
    "    self.center_data = False\n",
    "    self.contrast_normalize = False\n",
    "    self.extract_patches = True\n",
    "    self.norm_data = False\n",
    "    self.whiten_data = True\n",
    "    self.standardize_data = True\n",
    "    self.norm_data_to_one = False\n",
    "    self.whiten_method = \"FT\"\n",
    "    self.num_patches = 1e6\n",
    "    self.patch_edge_size = 32\n",
    "    self.overlapping_patches = True\n",
    "    self.randomize_patches = True\n",
    "    self.patch_variance_threshold = 1e-6\n",
    "    self.data_dir = os.path.expanduser(\"~\")+\"/Work/Datasets/vanHateren/\"\n",
    "\n",
    "vh_params.update(general_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_data = ds.get_data(cifar_params)\n",
    "vh_data = ds.get_data(vh_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_params.update({\n",
    "  \"num_pixels\": cifar_data[\"train\"].num_pixels,\n",
    "  \"data_shape\": list(cifar_data[\"train\"].shape[1:])})\n",
    "vh_params.update({\n",
    "  \"num_pixels\": vh_data[\"train\"].num_pixels,\n",
    "  \"data_shape\": list(vh_data[\"train\"].shape[1:])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar_shape:  (40000, 32, 32, 3) cifar_min:  0.0 cifar_max:  1.0 cifar_mean:  0.473007 \n",
      " vh_shape:  (300, 512, 512, 1) vh_min:  0.550049 vh_max:  1.03223 vh_mean:  0.473007\n"
     ]
    }
   ],
   "source": [
    "cifar_shape = cifar_data[\"train\"].shape\n",
    "cifar_min = np.min(cifar_data[\"train\"].images)\n",
    "cifar_max = np.max(cifar_data[\"train\"].images)\n",
    "cifar_mean = np.mean(cifar_data[\"train\"].images)\n",
    "vh_shape = vh_data[\"train\"].shape\n",
    "vh_min = np.min(vh_data[\"train\"].images)\n",
    "vh_max = np.max(vh_data[\"train\"].images)\n",
    "vh_mean = np.mean(cifar_data[\"train\"].images)\n",
    "print(\"cifar_shape: \", cifar_shape, \"cifar_min: \", cifar_min, \"cifar_max: \", cifar_max, \"cifar_mean: \", cifar_mean,\n",
    "  \"\\n\",\n",
    "  \"vh_shape: \", vh_shape, \"vh_min: \", vh_min, \"vh_max: \", vh_max, \"vh_mean: \", vh_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar_model = mp.get_model(model_type)\n",
    "cifar_data = cifar_model.preprocess_dataset(cifar_data, cifar_params)\n",
    "cifar_data = cifar_model.reshape_dataset(cifar_data, cifar_params)\n",
    "\n",
    "vh_model = mp.get_model(model_type)\n",
    "vh_data = vh_model.preprocess_dataset(vh_data, vh_params)\n",
    "vh_data = vh_model.reshape_dataset(vh_data, vh_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_shape = cifar_data[\"train\"].shape\n",
    "cifar_min = np.min(cifar_data[\"train\"].images)\n",
    "cifar_max = np.max(cifar_data[\"train\"].images)\n",
    "cifar_mean = np.mean(cifar_data[\"train\"].images)\n",
    "vh_shape = vh_data[\"train\"].shape\n",
    "vh_min = np.min(vh_data[\"train\"].images)\n",
    "vh_max = np.max(vh_data[\"train\"].images)\n",
    "vh_mean = np.mean(cifar_data[\"train\"].images)\n",
    "print(\"cifar_shape: \", cifar_shape, \"cifar_min: \", cifar_min, \"cifar_max: \", cifar_max, \"cifar_mean: \", cifar_mean,\n",
    "  \"\\n\",\n",
    "  \"vh_shape: \", vh_shape, \"vh_min: \", vh_min, \"vh_max: \", vh_max, \"vh_mean: \", vh_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
